{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "### imports\n",
    "import numpy as np\n",
    "#import tensorflow.keras as keras\n",
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import os, sys\n",
    "import copy\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "layers:  bidirectional rnn\n",
    "         merge with different sizes\n",
    "         conv3d\n",
    "         pool3d\n",
    "         seperable conv\n",
    "         conv transpose\n",
    "         depthwise conv\n",
    "         crop3d\n",
    "         pad3d\n",
    "         upsampling1d\n",
    "         upsampling2d\n",
    "         upsampling3d\n",
    "         locally connected 1d\n",
    "         locally connected 2d\n",
    "         time distributed\n",
    "         \n",
    "         \n",
    " im2col for convolution?\n",
    " static or const?\n",
    " broadcasting sizes for merge layers\n",
    " find the common dimension and add them that way?\n",
    " \n",
    " \n",
    " \n",
    " common API for all function calls\n",
    " figure out max array sizes?\n",
    " figure out keras h5 file format\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# layer tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### average pooling 1d test\n",
    "\n",
    "def arravg(array,numels,offset):\n",
    "    avg=0\n",
    "    ct = 0\n",
    "    for i in range(numels):\n",
    "        if array[i*offset] > -np.inf:\n",
    "            avg += array[i*offset]\n",
    "            ct += 1\n",
    "    avg = avg/ct\n",
    "    return avg\n",
    "\n",
    "def avgpool1d(inputs,pool_size,stride,out_height,in_width):\n",
    "    k=0\n",
    "    outputs = np.zeros(out_height*in_width)\n",
    "    inputs = inputs.flatten(order='C')\n",
    "    for i in range(out_height):\n",
    "        inrowidx = k*in_width;\n",
    "        outrowidx = i*in_width;\n",
    "        for j in range(in_width):\n",
    "            outputs[outrowidx+j] = arravg(inputs[inrowidx+j:],pool_size,in_width)\n",
    "        k += stride\n",
    "    return outputs\n",
    "\n",
    "inshape = (10,10)\n",
    "pool_size=3\n",
    "stride=1\n",
    "pad = 'same'\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.AveragePooling1D(pool_size=pool_size, strides=stride, padding=pad)(a)\n",
    "model = keras.models.Model(inputs=[a], outputs=[b])\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "(in_height,in_width) = model.layers[1].input_shape[1:]\n",
    "(out_height, out_width) = model.layers[1].output_shape[1:]\n",
    "\n",
    "if pad is 'same':\n",
    "    pad_along_height = max((out_height - 1) * stride +\n",
    "                        pool_size - in_height, 0)\n",
    "    pad_top = int(pad_along_height // 2)\n",
    "    pad_bottom = int(pad_along_height - pad_top)\n",
    "elif pad is 'valid':\n",
    "    pad_top=0\n",
    "    pad_bottom=0\n",
    "padded_in_height = in_height + pad_top + pad_bottom\n",
    "\n",
    "\n",
    "y1 = np.concatenate((-np.inf*np.ones((pad_top,in_width)),x,-np.inf*np.ones((pad_bottom,in_width))),0)\n",
    "y2 = avgpool1d(y1,pool_size,stride,out_height,in_width)\n",
    "np.mean(np.abs(y.flatten(order='C')-y2.flatten(order='C')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "### max pooling 1d test\n",
    "def arrmax(array,numels,offset):\n",
    "    maxval=array[0];\n",
    "    for i in range(numels):\n",
    "        if array[i*offset]>maxval:\n",
    "            maxval = array[i*offset]\n",
    "    return maxval  \n",
    "\n",
    "def maxpool1d(inputs,pool_size,stride,out_height,in_width):\n",
    "    k=0\n",
    "    outputs = np.zeros(out_height*in_width)\n",
    "    inputs = inputs.flatten(order='C')\n",
    "    for i in range(out_height):\n",
    "        inrowidx = k*in_width;\n",
    "        outrowidx = i*in_width;\n",
    "        for j in range(in_width):\n",
    "            outputs[outrowidx+j] = arrmax(inputs[inrowidx+j:],pool_size,in_width)\n",
    "        k += stride\n",
    "    return outputs\n",
    "\n",
    "inshape = (8,23)\n",
    "pool_size=2\n",
    "stride=1\n",
    "pad = 'same'\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.MaxPooling1D(pool_size=pool_size, strides=stride, padding=pad)(a)\n",
    "model = keras.models.Model(inputs=[a], outputs=[b])\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "(in_height,in_width) = model.layers[1].input_shape[1:]\n",
    "(out_height, out_width) = model.layers[1].output_shape[1:]\n",
    "\n",
    "if pad is 'same':\n",
    "    pad_along_height = max((out_height - 1) * stride +\n",
    "                        pool_size - in_height, 0)\n",
    "    pad_top = int(pad_along_height // 2)\n",
    "    pad_bottom = int(pad_along_height - pad_top)\n",
    "elif pad is 'valid':\n",
    "    pad_top=0\n",
    "    pad_bottom=0\n",
    "padded_in_height = in_height + pad_top + pad_bottom\n",
    "\n",
    "y1 = np.concatenate((-np.inf*np.ones((pad_top,in_width)),x,-np.inf*np.ones((pad_bottom,in_width))),0)\n",
    "y2 = maxpool1d(y1,pool_size,stride,out_height,in_width)\n",
    "np.mean(np.abs(y.flatten(order='C')-y2.flatten(order='C')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### conv1d test\n",
    "\n",
    "def conv1d(x,kernel,bias,out_height,out_width,kernel_size,in_width,padded_in_height,stride,dilation):\n",
    "    x = x.flatten(order='C')\n",
    "    kernel = kernel.flatten(order='C')\n",
    "    out_size = out_height*out_width\n",
    "    output = np.zeros(out_size)\n",
    "   \n",
    "    for p in range(out_height):\n",
    "        outrowidx = p*out_width\n",
    "        for k in range(out_width):\n",
    "            for z in range(kernel_size):\n",
    "                kernelidx = z*in_width*out_width\n",
    "                for q in range(in_width):\n",
    "                    inheightidx = q*out_width\n",
    "                    output[outrowidx+k] += kernel[kernelidx+ inheightidx+ k]*x[(p*stride+ z*dilation)*in_width+q];\n",
    "            output[outrowidx+k] += bias[k]\n",
    "    \n",
    "    return output\n",
    "\n",
    "inshape = (10,15)\n",
    "pool_size=3\n",
    "stride=1\n",
    "dilation = 1\n",
    "kernel_size = 4\n",
    "num_filters = 9\n",
    "pad = 'same'\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.Conv1D(filters=num_filters, dilation_rate=dilation, kernel_size=kernel_size, strides=stride, padding=pad)(a)\n",
    "model = keras.models.Model(inputs=[a], outputs=[b])\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "(in_height,in_width) = model.layers[1].input_shape[1:]\n",
    "(out_height, out_width) = model.layers[1].output_shape[1:]\n",
    "\n",
    "if pad is 'causal':\n",
    "    pad_along_height = dilation*(kernel_size-1)\n",
    "    pad_top = pad_along_height\n",
    "    pad_bottom = 0\n",
    "elif pad is 'same':\n",
    "    pad_along_height = max((out_height - 1) * stride +\n",
    "                        kernel_size - in_height, 0)\n",
    "    pad_top = int(pad_along_height // 2)\n",
    "    pad_bottom = int(pad_along_height - pad_top)\n",
    "elif pad is 'valid':\n",
    "    pad_top=0\n",
    "    pad_bottom=0\n",
    "padded_in_height = in_height + pad_top + pad_bottom\n",
    "\n",
    "kernel = model.layers[1].get_weights()[0]\n",
    "bias = model.layers[1].get_weights()[1]\n",
    "y1 = np.concatenate((np.zeros((pad_top,in_width)),x,np.zeros((pad_bottom,in_width))),0)\n",
    "y2 = conv1d(y1,kernel,bias,out_height,out_width,kernel_size,in_width,padded_in_height,stride,dilation)\n",
    "print(np.mean(np.abs(y.flatten(order='C')-y2.flatten(order='C'))))\n",
    "print(model.layers[1].get_weights()[0].shape)\n",
    "print(model.layers[1].get_weights()[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### simple RNN test\n",
    "def rnn(inputs,weights,recurrent_weights,bias):\n",
    "    state = np.zeros(bias.shape[0])\n",
    "    for i in range(inputs.shape[0]):\n",
    "        state = rnncell(inputs[i,:],state,weights,recurrent_weights,bias)\n",
    "    return state\n",
    "   \n",
    "def rnncell(inputs,state,weights,recurrent_weights,bias):\n",
    "    prev = state\n",
    "    h = inputs@weights+bias\n",
    "    output = h + prev@recurrent_weights\n",
    "    output = np.tanh(output)\n",
    "    \n",
    "    return output\n",
    "\n",
    "insize = (10,33)\n",
    "a = keras.layers.Input(insize)\n",
    "b = keras.layers.SimpleRNN(12, dropout=.5, recurrent_dropout=.5)(a)\n",
    "\n",
    "model = keras.models.Model(inputs=[a], outputs=[b])\n",
    "x = np.random.random(insize)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "model.layers[1].output_shape\n",
    "\n",
    "weights = model.layers[1].get_weights()[0]\n",
    "recurrent_weights = model.layers[1].get_weights()[1]\n",
    "bias = model.layers[1].get_weights()[2]\n",
    "a = rnn(x,weights,recurrent_weights,bias)\n",
    "np.max(np.abs(a-y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### GRU test\n",
    "\n",
    "def gru(inputs, kernel, recurrent_kernel, input_bias, recurrent_bias, reset_after, units, go_backwards, return_sequences):\n",
    "    inp = inputs.flatten()\n",
    "    state = np.zeros(units)\n",
    "    output = np.zeros((inputs.shape[0]*units))\n",
    "    if go_backwards:\n",
    "        for i in range(inputs.shape[0]-1,-1,-1):\n",
    "            state = grucell(inp[i*inputs.shape[1]:(i+1)*inputs.shape[1]], state, kernel, recurrent_kernel, input_bias, recurrent_bias, reset_after, units)\n",
    "            if return_sequences:\n",
    "                for j in range(units):\n",
    "                    output[(inputs.shape[0]-1-i)*units+j] = state.flatten()[j]\n",
    "                \n",
    "    else:\n",
    "        for i in range(inputs.shape[0]):\n",
    "            state = grucell(inp[i*inputs.shape[1]:(i+1)*inputs.shape[1]], state, kernel, recurrent_kernel, input_bias, recurrent_bias, reset_after, units)\n",
    "            if return_sequences:\n",
    "                for j in range(units):\n",
    "                    output[i*units+j] = state.flatten()[j]\n",
    "    if return_sequences:\n",
    "        return output\n",
    "    else:\n",
    "        return output\n",
    "    \n",
    "\n",
    "def grucell(inputs, state, kernel, recurrent_kernel, input_bias, recurrent_bias, reset_after, units):\n",
    "    kernel_z = kernel[:, :units]\n",
    "    recurrent_kernel_z = recurrent_kernel[:, :units]\n",
    "    # reset gate\n",
    "    kernel_r = kernel[:, units: units * 2]\n",
    "    recurrent_kernel_r = recurrent_kernel[:,units:units * 2]\n",
    "    # new gate\n",
    "    kernel_h = kernel[:, units * 2:]\n",
    "    recurrent_kernel_h = recurrent_kernel[:, units * 2:]\n",
    "    \n",
    "    input_bias_z = input_bias[:units]\n",
    "    input_bias_r = input_bias[units: units * 2]\n",
    "    input_bias_h = input_bias[units * 2:]\n",
    "        \n",
    "    recurrent_bias_z = recurrent_bias[:units]\n",
    "    recurrent_bias_r = recurrent_bias[units: units * 2]\n",
    "    recurrent_bias_h = recurrent_bias[units * 2:]\n",
    "    \n",
    "    \n",
    "    x_z = inputs@kernel_z + input_bias_z\n",
    "    x_r = inputs@kernel_r + input_bias_r\n",
    "    x_h = inputs@kernel_h + input_bias_h\n",
    "    \n",
    "    h_tm1 = state\n",
    "\n",
    "            \n",
    "    recurrent_z = h_tm1@recurrent_kernel_z\n",
    "    recurrent_r = h_tm1@recurrent_kernel_r\n",
    "    recurrent_z = recurrent_z + recurrent_bias_z\n",
    "    recurrent_r = recurrent_r + recurrent_bias_r\n",
    "\n",
    "    recurrent_z = np.tanh(x_z + recurrent_z)\n",
    "    recurrent_r = np.tanh(x_r + recurrent_r)\n",
    "\n",
    "    # reset gate applied after/before matrix multiplication\n",
    "    if reset_after:\n",
    "        recurrent_h = h_tm1@recurrent_kernel_h + recurrent_bias_h\n",
    "        recurrent_h = recurrent_r * recurrent_h\n",
    "    else:\n",
    "        recurrent_h = (recurrent_r * h_tm1)@recurrent_kernel_h\n",
    "    hh = np.tanh(x_h + recurrent_h)\n",
    "    h = recurrent_z * h_tm1 + (1 - recurrent_z) * hh\n",
    "    return h\n",
    "\n",
    "reset_after = True\n",
    "go_backwards = True\n",
    "return_sequences = True\n",
    "units=12\n",
    "insize = (10,33)\n",
    "a = keras.layers.Input(insize)\n",
    "b = keras.layers.GRU(units, reset_after=reset_after, activation='tanh', recurrent_activation='tanh',\\\n",
    "                    bias_initializer='zeros', go_backwards=go_backwards, return_sequences=return_sequences)(a)\n",
    "\n",
    "model = keras.models.Model(inputs=[a], outputs=[b])\n",
    "x = np.random.random(insize)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "kernel = model.layers[1].get_weights()[0]\n",
    "recurrent_kernel = model.layers[1].get_weights()[1]\n",
    "bias = model.layers[1].get_weights()[2]\n",
    "if reset_after:\n",
    "    input_bias = bias[0,:]\n",
    "    recurrent_bias = bias[1,:]\n",
    "else:\n",
    "    recurrent_bias = np.zeros(3*units)\n",
    "    input_bias = bias\n",
    "\n",
    "y2 = gru(x, kernel, recurrent_kernel, input_bias, recurrent_bias, reset_after, units, go_backwards, return_sequences)\n",
    "np.max(np.abs(y2.flatten()-y.flatten())) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### dropout test\n",
    "inshape = (10,20)\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.Dense(40, use_bias=False)(a)\n",
    "c = keras.layers.Dropout(.9)(b)\n",
    "d = keras.layers.Dense(40, use_bias=False)(c)\n",
    "model = keras.models.Model(inputs=a, outputs=d)\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "y2 = (x@model.layers[1].get_weights()[0])@model.layers[3].get_weights()[0]\n",
    "\n",
    "np.max(np.abs(y2-y)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### flatten / reshape test\n",
    "x = np.array(range(12)).reshape((3,4))\n",
    "x1 = np.reshape(x, (1, -1))\n",
    "np.max(np.abs(x1.flatten() - x.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### reshape test\n",
    "inshape = (20,16)\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.Reshape((8,2,2,10))(a)\n",
    "\n",
    "model = keras.models.Model(inputs=a, outputs=b)\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "\n",
    "np.max(np.abs(x.flatten()-y.flatten()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     13,
     24
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "### transpose testing\n",
    "def transp(a,ndim,olddim,permute):\n",
    "    a = a.flatten()\n",
    "    b = np.zeros(a.shape)\n",
    "    oldidx2d = np.array([0,0])\n",
    "    oldidx3d = np.array([0,0,0])\n",
    "    newidx2d = np.array([0,0])\n",
    "    newidx3d = np.array([0,0,0])\n",
    "\n",
    "#    b[i,j,k] = a[i * (dim2 * dim3) + (j * dim3) + k]\n",
    "#    b[i,j] = a[i*dim2 + j]\n",
    "    if ndim==1:\n",
    "        return a # no need to transpose a 1d array\n",
    "    if ndim==2:\n",
    "        oldrows = olddim[0]\n",
    "        oldcols = olddim[1]\n",
    "        newrows = olddim[permute[0]]\n",
    "        newcols = olddim[permute[1]]\n",
    "        for i in range(oldrows):\n",
    "            for j in range(oldcols):\n",
    "                oldidx2d = [i,j]\n",
    "                newidx2d = [oldidx2d[permute[0]],oldidx2d[permute[1]]]\n",
    "                b[newidx2d[0]*newcols + newidx2d[1]] = a[oldidx2d[0]*oldcols + oldidx2d[1]]\n",
    "        return b\n",
    "    if ndim==3:\n",
    "        oldrows = olddim[0]\n",
    "        oldcols = olddim[1]\n",
    "        oldchan = olddim[2]\n",
    "        newrows = olddim[permute[0]]\n",
    "        newcols = olddim[permute[1]]\n",
    "        newchan = olddim[permute[2]]\n",
    "        for i in range(oldrows):\n",
    "            for j in range(oldcols):\n",
    "                for k in range(oldchan):\n",
    "                    oldidx3d = [i,j,k]\n",
    "                    newidx3d = [oldidx3d[permute[0]],oldidx3d[permute[1]],oldidx3d[permute[2]]]\n",
    "                    b[newidx3d[0]*newcols*newchan + newidx3d[1]*newchan + newidx3d[2]] =\\\n",
    "                        a[oldidx3d[0]*oldcols*oldchan + oldidx3d[1]*oldchan + oldidx3d[2]]\n",
    "        return b\n",
    "    if ndim==4:\n",
    "        oldrows = olddim[0]\n",
    "        oldcols = olddim[1]\n",
    "        oldchan = olddim[2]\n",
    "        oldtime = olddim[3]\n",
    "        newrows = olddim[permute[0]]\n",
    "        newcols = olddim[permute[1]]\n",
    "        newchan = olddim[permute[2]]\n",
    "        newtime = olddim[permute[3]]\n",
    "        for i in range(oldrows):\n",
    "            for j in range(oldcols):\n",
    "                for k in range(oldchan):\n",
    "                    for l in range(oldtime):\n",
    "                        oldidx4d = [i,j,k,l]\n",
    "                        newidx4d = [oldidx4d[permute[0]],oldidx4d[permute[1]],oldidx4d[permute[2]],oldidx4d[permute[3]]]\n",
    "                        b[newidx4d[0]*newcols*newchan*newtime + newidx4d[1]*newchan*newtime + newidx4d[2]*newtime + newidx4d[3]] =\\\n",
    "                            a[oldidx4d[0]*oldcols*oldchan*oldtime + oldidx4d[1]*oldchan*oldtime + oldidx4d[2]*oldtime + oldidx4d[3]]\n",
    "        return b\n",
    "\n",
    "inshape = (5,7,8,12)\n",
    "permute = np.array((3,2,1,4))\n",
    "ndim = 4\n",
    "l1 = keras.layers.Input(inshape)\n",
    "l2 = keras.layers.Permute(permute)(l1)\n",
    "model = keras.models.Model(inputs=l1, outputs=l2)\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "xt = transp(x,ndim,inshape,permute-1)\n",
    "\n",
    "np.max(np.abs(xt-y.flatten()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inshape = (4,5)\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.Dense(10)(a)\n",
    "model = keras.models.Model(inputs=a, outputs=b)\n",
    "model.layers[1].get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# misc testing and notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### indexing testing\n",
    "dim0=9\n",
    "dim1=48\n",
    "dim2=19\n",
    "b = np.random.random((dim0,dim1,dim2))\n",
    "a = b.flatten(order='C')\n",
    "idx = (7,21,5)\n",
    "b[idx] - a[idx[0] * (dim1 * dim2) + (idx[1] * dim2) + idx[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### input/output sizing with filters/padding\n",
    "#out_height = ceil(float(in_height) / float(strides[1]))\n",
    "#out_width  = ceil(float(in_width) / float(strides[2]))\n",
    "\n",
    "#pad_along_height = max((out_height - 1) * strides[1] +\n",
    "#                    filter_height - in_height, 0)\n",
    "#pad_along_width = max((out_width - 1) * strides[2] +\n",
    "#                   filter_width - in_width, 0)\n",
    "#pad_top = pad_along_height // 2\n",
    "#pad_bottom = pad_along_height - pad_top\n",
    "#pad_left = pad_along_width // 2\n",
    "#pad_right = pad_along_width - pad_left\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### pydot graph testing\n",
    "#graph = pydot.graph_from_dot_data(str())\n",
    "graph = keras.utils.vis_utils.model_to_dot(model)\n",
    "nodes = graph.get_nodes()\n",
    "edges = graph.get_edges()\n",
    "# for edge in edges:\n",
    "#     print(edge)\n",
    "# for node in nodes:\n",
    "#     print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     2,
     19,
     25,
     26,
     68,
     82
    ]
   },
   "outputs": [],
   "source": [
    "### kgraph stuff\n",
    "\n",
    "class keras_node():\n",
    "    def __init__(self, pydot_node):\n",
    "        self.pydot_node = pydot_node\n",
    "        self.ID = pydot_node.to_string().split()[0]\n",
    "        self.type = pydot_node.to_string().split()[2][:-3]\n",
    "        self.name = pydot_node.to_string().split()[1][8:-1]\n",
    "        self.inputs = []\n",
    "        self.outputs = []\n",
    "    \n",
    "    def find_layer_idx(self,model):\n",
    "        \"\"\"finds the index into model.layers corresponding to the node\"\"\"\n",
    "        for i, layer in enumerate(model.layers):\n",
    "            if layer.name == self.name:\n",
    "                self.layer_idx = i\n",
    "                return\n",
    "        self.layer_idx = None\n",
    "            \n",
    "class keras_edge():\n",
    "    def __init__(self, pydot_edge):\n",
    "        self.pydot_edge = pydot_edge\n",
    "        self.start_id = pydot_edge.to_string().split()[0]\n",
    "        self.end_id = pydot_edge.to_string().split()[2][:-1]\n",
    "\n",
    "class keras_graph():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.pydot_graph = keras.utils.vis_utils.model_to_dot(model)\n",
    "        self.edges = self.parse_edges(self.pydot_graph)\n",
    "        self.nodes = self.parse_nodes(self.pydot_graph)\n",
    "        self.input_nodes = []\n",
    "        self.output_nodes = []\n",
    "        \n",
    "    def parse_edges(self,pydot_graph):\n",
    "        \"\"\"converts pydot edges to keras_graph edges\"\"\"\n",
    "        edges = []\n",
    "        for edge in pydot_graph.get_edges():\n",
    "            edges += [keras_edge(edge)]\n",
    "        return edges\n",
    "    \n",
    "    def parse_nodes(self,pydot_graph):\n",
    "        \"\"\"converts pydot nodes to keras_graph nodes\"\"\"\n",
    "        nodes = []\n",
    "        for i, node in enumerate(pydot_graph.get_nodes()[1:]):\n",
    "            nodes += [keras_node(node)]\n",
    "            nodes[i].find_layer_idx(self.model)\n",
    "        return nodes\n",
    "    \n",
    "    def parse_connections(self):\n",
    "        for edge in self.edges:\n",
    "            self.find_node_from_id(edge.start_id).outputs += [self.find_node_from_id(edge.end_id)]\n",
    "            self.find_node_from_id(edge.end_id).inputs += [self.find_node_from_id(edge.start_id)]\n",
    "\n",
    "    def find_node_from_id(self,ID):\n",
    "        \"\"\"finds the node associated with a given ID\"\"\"\n",
    "        for node in self.nodes:\n",
    "            if node.ID == ID:\n",
    "                return node\n",
    "        return None\n",
    "    \n",
    "    def find_io_nodes(self):\n",
    "        for node in self.nodes:\n",
    "            if len(node.inputs) == 0:\n",
    "                self.input_nodes += [node]\n",
    "            if len(node.outputs) == 0:\n",
    "                self.output_nodes += [node]\n",
    "            \n",
    "def write_model(model):\n",
    "    kgraph = keras_graph(model)\n",
    "    kgraph.parse_connections()\n",
    "    kgraph.find_io_nodes()\n",
    "\n",
    "    written_nodes = []\n",
    "    unwritten_nodes = copy.deepcopy(kgraph.nodes)\n",
    "    while len(unwritten_nodes)>0:\n",
    "        for node in unwritten_nodes:\n",
    "            if set(node.inputs).issubset(written_nodes):\n",
    "                write_layer(model.layers[node.layer_idx],node)\n",
    "                written_nodes.append(node)\n",
    "                unwritten_nodes.remove(node)\n",
    "        \n",
    "def write_layer(layer,node):\n",
    "    print(layer.name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     2,
     3,
     12,
     61,
     70,
     74,
     76,
     84
    ]
   },
   "outputs": [],
   "source": [
    "### check and io functions\n",
    "\n",
    "def get_all_io_names(model):\n",
    "    def flatten(x):\n",
    "        if isinstance(x, list) or isinstance(x, tuple):\n",
    "            return [a for i in x for a in flatten(i)]\n",
    "        else:\n",
    "            return [x]\n",
    "    \n",
    "    a = [get_layer_io_names(layer) for layer in model.layers]\n",
    "    return list(set(flatten(a)))\n",
    "\n",
    "def get_layer_io_names(layer):\n",
    "    inputs = []\n",
    "    num_inputs = 0\n",
    "    error = False\n",
    "    while not error:\n",
    "        try:\n",
    "            layer.get_input_at(num_inputs)\n",
    "            num_inputs +=1\n",
    "        except:\n",
    "            error = True\n",
    "    \n",
    "    outputs = []\n",
    "    num_outputs = 0\n",
    "    error = False\n",
    "    while not error:\n",
    "        try:\n",
    "            layer.get_output_at(num_outputs)\n",
    "            num_outputs +=1\n",
    "        except:\n",
    "            error = True\n",
    "    # num_inputs>1 -> shared layer\n",
    "    for i in range(num_inputs):\n",
    "        # is the input a list?\n",
    "        if isinstance(layer.get_input_at(i), list):\n",
    "            temp_list = []\n",
    "            list_length = len(layer.get_input_at(i))\n",
    "            for j in range(list_length):\n",
    "                name = str(layer.get_input_at(i)[j]).split()[0].split('\"')[1].split('/')[0].split(':')[0]\n",
    "                temp_list.append(name)\n",
    "            inputs.insert(i,temp_list)\n",
    "        else:\n",
    "            name = str(layer.get_input_at(i)).split()[0].split('\"')[1].split('/')[0].split(':')[0]\n",
    "            inputs.insert(i,name)\n",
    "            \n",
    "    for i in range(num_outputs):\n",
    "        # is the output a list?\n",
    "        if isinstance(layer.get_output_at(i), list):\n",
    "            temp_list = []\n",
    "            list_length = len(layer.get_output_at(i))\n",
    "            for j in range(list_length):\n",
    "                name = str(layer.get_output_at(i)[j]).split()[0].split('\"')[1].split('/')[0].split(':')[0]\n",
    "                temp_list.append(name)\n",
    "            outputs.insert(i,temp_list)\n",
    "        else:\n",
    "            name = str(layer.get_output_at(i)).split()[0].split('\"')[1].split('/')[0].split(':')[0]\n",
    "            outputs.insert(i,name)\n",
    "\n",
    "    return (inputs, outputs)\n",
    "\n",
    "def is_valid_c_name(name):\n",
    "    allowed_chars = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ_123456789'\n",
    "    allowed_starting_chars = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ_'\n",
    "    if not set(name).issubset(allowed_chars):\n",
    "        return False\n",
    "    if not set(name[0]).issubset(allowed_starting_chars):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def name_check(model):\n",
    "    for layer in model.layers:\n",
    "        assert (is_valid_c_name(layer.name)), \"layer name '\" + layer.name + \"' is not a valid C name\"\n",
    "\n",
    "def layer_type(layer):\n",
    "    return str(layer.__class__).split('.')[-1][0:-2]\n",
    "def layers_supported_check(model):\n",
    "    supported_layers = ['Dense','LSTM','Conv1D','InputLayer','MaxPooling1D','AveragePooling1D',\\\n",
    "                        'GlobalMaxPooling1D','GlobalAveragePooling1D','Add','Multiply','Average',\\\n",
    "                        'Maximum','Minimum','LeakyReLU','ELU','ThresholdedReLU','ReLU']\n",
    "    for layer in model.layers:\n",
    "        assert(layer_type(layer) in supported_layers), \"layer type '\" + \\\n",
    "        layer_type(layer) + \"' is not supported at this time\"\n",
    "        \n",
    "def activation_supported_check(model):\n",
    "    supported_activations = ['linear', 'relu','softmax','softplus','softsign','relu','tanh',\\\n",
    "                             'sigmoid','hard_sigmoid','exponential' ]\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        if 'activation' in layer.get_config():\n",
    "            assert(layer.get_config()['activation'] in supported_activations), \\\n",
    "            \"activation type '\" + layer.get_config()['activation'] + \"' is not supported at this time\"\n",
    "        if 'recurrent_activation' in layer.get_config():\n",
    "            assert(layer.get_config()['recurrent_activation'] in supported_activations), \\\n",
    "            \"recurrent activation type '\" + layer.get_config()['recurrent_activation'] + \"' is not supported at this time\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### max pooling 2d\n",
    "\n",
    "def max_pool2d(inputs,pool_size,stride,outshp):\n",
    "    channels = inputs.shape[2]\n",
    "    fin = inputs.flatten()\n",
    "    outsize = np.prod(outshp)\n",
    "    outputs = np.zeros(outsize)\n",
    "    for i in range(channels):\n",
    "        k=0\n",
    "        for j in range(0,outshp[1]*channels,channels):\n",
    "            m=0\n",
    "            for l in range(0, outsize, channels*outshp[1]):\n",
    "                outputs[l+j+i] = fin[m+k+i]\n",
    "                for n in range(0,pool_size[1]*channels, channels):\n",
    "                    for p in range(0,pool_size[0]*channels*inputs.shape[1],channels*inputs.shape[1]):\n",
    "                        if (outputs[l+j+i] < fin[m+k+i+n+p]):\n",
    "                            outputs[l+j+i] = fin[m+k+i+n+p]\n",
    "                m+=channels*inputs.shape[1]*stride[0]\n",
    "            k+=channels*stride[1]\n",
    "    return outputs\n",
    "inshp = (5,6,7)\n",
    "pool_size = (3,3)\n",
    "stride = (3,1)\n",
    "a = keras.layers.Input(inshp)\n",
    "b = keras.layers.MaxPooling2D(pool_size=pool_size, strides=stride)(a)\n",
    "model = keras.models.Model(inputs=a,outputs=b)\n",
    "\n",
    "x = np.random.random(inshp)\n",
    "y = model.predict(x[np.newaxis,...])\n",
    "y = y[0,:]\n",
    "y1 = max_pool2d(x,pool_size,stride,y.shape)\n",
    "np.max(np.abs(y.flatten()-y1.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(8, (3, 3), padding='same',\n",
    "                                  input_shape=(32, 32, 3)))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.Conv2D(8, (3, 3)))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(keras.layers.Dropout(0.25))\n",
    "    model.add(keras.layers.Conv2D(8, (3, 3), padding='same'))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.Conv2D(8, (3, 3)))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(keras.layers.Dropout(0.25))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(20))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(10))\n",
    "    model.add(keras.layers.Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[-].output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs, model_outputs = get_model_io_names(model)\n",
    "written_io = set(model_inputs)\n",
    "unwritten_io = set(get_all_io_names(model)) - written_io\n",
    "count = 0\n",
    "while len(unwritten_io) > 0:\n",
    "    count += 1\n",
    "    if count>50:\n",
    "        break\n",
    "    for layer in model.layers:\n",
    "        layer_inputs, layer_outputs = get_layer_io_names(layer)\n",
    "        for i, (inp, outp) in enumerate(zip(layer_inputs, layer_outputs)):\n",
    "            if (set(flatten(inp)).issubset(written_io) and\n",
    "                    set(flatten(outp)).issubset(unwritten_io))or \\\n",
    "                    layer_type(layer) == 'InputLayer':\n",
    "                print('Writing layer ', outp)\n",
    "                written_io |= set(flatten(inp))\n",
    "                written_io |= set(flatten(outp))\n",
    "                unwritten_io -= set(flatten(inp))\n",
    "                unwritten_io -= set(flatten(outp))\n",
    "                print('written: ',written_io)\n",
    "                print('unwritten: ',unwritten_io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def k2c_bias_add(A,b):\n",
    "    af = A.flatten()\n",
    "    c = np.zeros(af.size)\n",
    "    for i in range(0,af.size,b.size):\n",
    "        for j in range(b.size):\n",
    "            c[i+j] = af[i+j] + b[j]\n",
    "    return c\n",
    "A = np.random.random((4,5,6,10))\n",
    "b = np.arange(10)\n",
    "c1 = A+b\n",
    "c2 = k2c_bias_add(A,b)\n",
    "np.max(np.abs(c1.flatten()-c2.flatten()))\n",
    "#print(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inshp = (4,3,10)\n",
    "a = keras.layers.Input(inshp)\n",
    "b = keras.layers.UpSampling2D((3,2))(a)\n",
    "model = keras.models.Model(a,b)\n",
    "\n",
    "x = np.arange(np.prod(inshp)).reshape(inshp)\n",
    "print(x[:,:,0])\n",
    "y = model.predict(x[np.newaxis,...])\n",
    "print(y[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[1].get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def k2c_sub2idx(sub, shape, ndim):\n",
    "  #/* converts from subscript to linear indices in row major order */\n",
    "    idx = 0\n",
    "    temp = 0;\n",
    "    for i in range(ndim):\n",
    "        temp = sub[i];\n",
    "        for j in range(ndim-1,i,-1):\n",
    "            temp *= shape[j]\n",
    "        idx += temp;\n",
    "    return int(idx)\n",
    "\n",
    "def k2c_idx2sub(idx,shape,ndim):\n",
    "    sub = np.zeros(ndim)\n",
    "    a = np.flip(np.cumprod(shape))\n",
    "    for j in range(ndim-1,-1,-1):\n",
    "        sub[j] = idx % shape[j]\n",
    "        idx = idx // shape[j]\n",
    "    return tuple(sub.astype(int))\n",
    "\n",
    "def k2c_permute(a,pdims):\n",
    "    pdims = np.array(pdims).astype(int)\n",
    "    shp = a.shape\n",
    "    print(shp)\n",
    "    newshp = np.array(shp)[pdims]\n",
    "    print(newshp)\n",
    "    numels = a.size\n",
    "    af = a.flatten()\n",
    "    b = np.zeros(numels)\n",
    "    for i in range(numels):\n",
    "        aidx = i\n",
    "        #asub = np.unravel_index(i,shp)\n",
    "        #print(asub)\n",
    "        asub = tuple(k2c_idx2sub(i,shp,a.ndim))\n",
    "        bsub = tuple(np.array(asub)[pdims])\n",
    "        #print(bsub)\n",
    "        bidx = k2c_sub2idx(bsub,newshp,a.ndim)\n",
    "        b[bidx] = af[i]\n",
    "    return b\n",
    "\n",
    "\n",
    "inshape = (10,40,30)\n",
    "permute = np.array((3,1,2))\n",
    "ndim = 3\n",
    "l1 = keras.layers.Input(inshape)\n",
    "l2 = keras.layers.Permute(permute)(l1)\n",
    "model = keras.models.Model(inputs=l1, outputs=l2)\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "xt = k2c_permute(x,permute-1)\n",
    "\n",
    "np.max(np.abs(xt.flatten()-y.flatten()))\n",
    "np.max(np.abs(xt.flatten()-x.flatten()))\n",
    "\n",
    "# sub = (0,1,2,6)\n",
    "# shp = (9,4,5,7)\n",
    "# ndim = len(shp)\n",
    "\n",
    "# idx1 = np.ravel_multi_index(sub,shp)\n",
    "# idx2 = k2c_sub2idx(sub,shp,ndim)\n",
    "# sub1 = np.unravel_index(idx1,shp)\n",
    "# sub2 = k2c_idx2sub(idx1,shp,ndim)\n",
    "# print(idx1,idx2)\n",
    "# print(sub1-np.array(sub2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inshape = (4,3,6,5)\n",
    "axes = (2,)\n",
    "flipped=False\n",
    "a = np.random.random(inshape)\n",
    "def k2c_reshape(a,axes,flipped):\n",
    "    shape_a = a.shape\n",
    "    axes = [i if i >= 0 else i + len(shape_a) for i in axes]\n",
    "    free = [i for i in range(len(shape_a)) if i not in axes]\n",
    "    free_dims = [shape_a[i] for i in free]\n",
    "    prod_free = int(np.prod([shape_a[i] for i in free]))\n",
    "    prod_axes = int(np.prod([shape_a[i] for i in axes]))\n",
    "    perm = list(axes) + free if flipped else free + list(axes)\n",
    "    new_shape = [prod_axes, prod_free] if flipped else [prod_free, prod_axes]\n",
    "    reshaped_a = np.reshape(np.transpose(a, perm), new_shape)\n",
    "    return reshaped_a, free_dims, prod_free,prod_axes\n",
    "\n",
    "def k2c_dot(a,b,a_axes,b_axes,normalize=False):\n",
    "    a_reshape, a_free_dims, free_axesA, prod_axesA = k2c_reshape(a, a_axes,False)\n",
    "    b_reshape, b_free_dims, free_axesB, prod_axesB = k2c_reshape(b, b_axes, True)\n",
    "    print(free_axesA,prod_axesA,free_axesB,prod_axesB)\n",
    "    \n",
    "#     if normalize:\n",
    "#         y = np.max(np.sum(a_reshape ** 2, a_axes, keepdims=True), a_axes, keepdims=True)\n",
    "#         print(y)\n",
    "#         print(y.shape)\n",
    "#         a_reshape = a_reshape / np.sqrt(y)\n",
    "#         y = np.max(np.sum(b_reshape ** 2, b_axes, keepdims=True), b_axes, keepdims=True)\n",
    "#         b_reshape = b_reshape / np.sqrt(y)\n",
    "#         print(y)\n",
    "#         print(y.shape)\n",
    "    if (normalize):\n",
    "        reshapeA = a_reshape.flatten()\n",
    "        reshapeB = b_reshape.flatten()\n",
    "        for i in range(free_axesA):\n",
    "            s = 0\n",
    "            for j in range(prod_axesA):\n",
    "                s += reshapeA[i*prod_axesA + j]**2\n",
    "            inorm = 1.0/np.sqrt(s);\n",
    "            for j in range(prod_axesA):\n",
    "                reshapeA[i*prod_axesA+j] *= inorm\n",
    "        for i in range(free_axesB):\n",
    "            s = 0\n",
    "            for j in range(prod_axesB):\n",
    "                s += reshapeB[i+free_axesB*j]**2\n",
    "            inorm = 1.0/np.sqrt(s);\n",
    "            for j in range(prod_axesB):\n",
    "                reshapeB[i+free_axesB*j] *= inorm \n",
    "        a_reshape = reshapeA.reshape(free_axesA,prod_axesA)\n",
    "        b_reshape = reshapeB.reshape(prod_axesB, free_axesB)\n",
    "    ab_matmul = a_reshape@b_reshape\n",
    "    return np.reshape(ab_matmul, a_free_dims + b_free_dims)\n",
    "   \n",
    "a_axes = (1,)\n",
    "b_axes = (1,)\n",
    "dotaxes = (2,2)\n",
    "inshape1 = (5,9)\n",
    "inshape2 = (9,9)\n",
    "i1 = keras.layers.Input(inshape1)\n",
    "i2 = keras.layers.Input(inshape2)\n",
    "d = keras.layers.Dot(axes=dotaxes, normalize=True)([i1,i2])\n",
    "model = keras.models.Model(inputs=[i1,i2], outputs = d)\n",
    "a = np.random.random(inshape1)\n",
    "b = np.random.random(inshape2)\n",
    "ak = a[np.newaxis,...]\n",
    "bk = b[np.newaxis,...]\n",
    "z = model.predict([ak,bk])\n",
    "x = np.tensordot(a,b,(a_axes,b_axes))\n",
    "print(x.shape)\n",
    "C = np.zeros(x.shape)\n",
    "y = k2c_dot(a,b,a_axes,b_axes,True)\n",
    "print('np vs k2c',np.max(np.abs(x-y)))\n",
    "print('k vs np', np.max(np.abs(z-x)))\n",
    "print('k vs k2c', np.max(np.abs(z-y)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inshp1 = (4,3,6)\n",
    "inshp2 = (4,3,6)\n",
    "inshp3 = (4,3,6)\n",
    "axis = 3\n",
    "a = keras.layers.Input(inshp1)\n",
    "b = keras.layers.Input(inshp2)\n",
    "c = keras.layers.Input(inshp3)\n",
    "d = keras.layers.Concatenate(axis=axis)([a,b,c])\n",
    "model = keras.models.Model([a,b,c],d)\n",
    "outshp = model.layers[3].output_shape[1:]\n",
    "\n",
    "def k2c_sub2idx(sub, shape, ndim):\n",
    "  #/* converts from subscript to linear indices in row major order */\n",
    "    idx = 0\n",
    "    temp = 0;\n",
    "    for i in range(ndim):\n",
    "        temp = sub[i];\n",
    "        for j in range(ndim-1,i,-1):\n",
    "            temp *= shape[j]\n",
    "        idx += temp;\n",
    "    return int(idx)\n",
    "\n",
    "def k2c_idx2sub(idx,shape,ndim):\n",
    "    sub = np.zeros(ndim)\n",
    "    a = np.flip(np.cumprod(shape))\n",
    "    for j in range(ndim-1,-1,-1):\n",
    "        sub[j] = idx % shape[j]\n",
    "        idx = idx // shape[j]\n",
    "    return tuple(sub.astype(int))\n",
    "\n",
    "\n",
    "def cat(inputs,axis,outshp):\n",
    "    offset=0\n",
    "    outputs = np.zeros(np.prod(outshp))\n",
    "    for i in range(len(inputs)):\n",
    "        for j in range(inputs[i].size):\n",
    "            insub = k2c_idx2sub(j,inputs[i].shape,inputs[i].ndim)\n",
    "            outsub = list(insub)\n",
    "            outsub[axis] += offset\n",
    "            outidx = k2c_sub2idx(outsub,outshp,len(outshp))\n",
    "            outputs[outidx] = inputs[i].flatten()[j]\n",
    "        offset += inputs[i].shape[axis]\n",
    "    return outputs\n",
    "\n",
    "in1 = np.random.random(inshp1)\n",
    "in2 = np.random.random(inshp2)\n",
    "in3 = np.random.random(inshp3)\n",
    "\n",
    "y = model.predict([in1[np.newaxis,...],in2[np.newaxis,...],in3[np.newaxis,...]])\n",
    "y1 = cat([in1,in2,in3],axis-1,outshp)\n",
    "\n",
    "np.max(np.abs(y.flatten()-y1.flatten()))\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inshp1 = (2, 3, 6, 3)\n",
    "inshp2 = (3, 3, 6, 3)\n",
    "inshp3 = (1, 3, 6, 3)\n",
    "axis = 1\n",
    "a = keras.layers.Input(inshp1)\n",
    "b = keras.layers.Input(inshp2)\n",
    "c = keras.layers.Input(inshp3)\n",
    "d = keras.layers.Concatenate(axis=axis)([a, b, c])\n",
    "model = keras.models.Model([a, b, c], d)\n",
    "model.inputs[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad3d(inputs,pad):\n",
    "    dim1 = inputs.shape[0]\n",
    "    dim2 = inputs.shape[1]\n",
    "    dim3 = inputs.shape[2]\n",
    "    outdim1 = dim1 + pad[0] + pad[1]\n",
    "    outdim2 = dim2 + pad[2] + pad[3]\n",
    "    outdim3 = dim3 + pad[4] + pad[5]\n",
    "    in_channels = inputs.shape[3]\n",
    "    fin = inputs.flatten()\n",
    "    outputs = np.zeros(outdim1*outdim2*outdim3*in_channels)\n",
    "    \n",
    "    offset1 = in_channels*(outdim2*outdim3)*pad[0] + in_channels*outdim3*pad[2] + in_channels*pad[4]\n",
    "    num = in_channels*dim3\n",
    "    outstep2 = num+in_channels*(pad[4]+pad[5])\n",
    "    outstep1 = outdim2*outdim3*in_channels \n",
    "    instep1 = dim2*dim3*in_channels\n",
    "    instep2 = dim3*in_channels\n",
    "\n",
    "    for i in range(dim1):\n",
    "        for j in range(dim2):\n",
    "            outputs[offset1+i*outstep1 + j*outstep2:offset1 + i*outstep1 + j*outstep2+num] = fin[i*instep1+j*instep2:i*instep1+j*instep2+num]\n",
    "    return outputs\n",
    "        \n",
    "inshp = (3,5,3,3)\n",
    "pad0 = 3\n",
    "pad1 = 2\n",
    "pad2 = 5\n",
    "pad3 = 1\n",
    "pad4 = 2\n",
    "pad5 = 3\n",
    "pad = (pad0,pad1,pad2,pad3,pad4,pad5)\n",
    "a = keras.layers.Input(inshp)\n",
    "b = keras.layers.ZeroPadding3D(((pad0,pad1),(pad2,pad3),(pad4,pad5)))(a)\n",
    "model = keras.models.Model(a,b)\n",
    "\n",
    "inputs = np.random.random(inshp)\n",
    "y = model.predict(inputs[np.newaxis,...])[0:]\n",
    "y1 = pad3d(inputs,pad)\n",
    "np.max(np.abs(y.flatten()-y1.flatten()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim1 = inputs.shape[0]\n",
    "dim2 = inputs.shape[1]\n",
    "dim3 = inputs.shape[2]\n",
    "outdim1 = dim1 + pad[0] + pad[1]\n",
    "outdim2 = dim2 + pad[2] + pad[3]\n",
    "outdim3 = dim3 + pad[4] + pad[5]\n",
    "in_channels = inputs.shape[3]\n",
    "num = in_channels*dim3\n",
    "offset1 = in_channels*(outdim2*outdim3)*pad[0] + in_channels*outdim3*pad[2] + in_channels*pad[4]\n",
    "step = outdim2*outdim3*in_channels\n",
    "offset2 = num+in_channels*(pad[4]+pad[5])\n",
    "offset3 = outdim2*outdim3*in_channels \n",
    "\n",
    "print(dim1,dim2,dim3,outdim1,outdim2,outdim3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=0\n",
    "i=0\n",
    "print(inputs.flatten()[i*dim2*dim3*in_channels+j*dim3*in_channels:i*dim2*dim3*in_channels+j*dim3*in_channels+num])\n",
    "print(y.flatten()[offset1 +i*step + j*offset2:offset1 +i*step + j*offset2 +num])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = dim1-1\n",
    "j = dim2-1\n",
    "i*dim2*dim3*in_channels+j*dim3*in_channels+num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop3d(inputs,pad):\n",
    "    dim1 = inputs.shape[0]\n",
    "    dim2 = inputs.shape[1]\n",
    "    dim3 = inputs.shape[2]\n",
    "    outdim1 = dim1 - pad[0] - pad[1]\n",
    "    outdim2 = dim2 - pad[2] - pad[3]\n",
    "    outdim3 = dim3 - pad[4] - pad[5]\n",
    "    in_channels = inputs.shape[3]\n",
    "    fin = inputs.flatten()\n",
    "    outputs = np.zeros(outdim1*outdim2*outdim3*in_channels)\n",
    "    \n",
    "    offset1 = in_channels*(dim2*dim3)*pad[0] + in_channels*dim3*pad[2] + in_channels*pad[4]\n",
    "    num = in_channels*outdim3\n",
    "    instep2 = num+in_channels*(pad[4]+pad[5])\n",
    "    instep1 = dim2*dim3*in_channels \n",
    "    outstep1 = outdim2*outdim3*in_channels\n",
    "    outstep2 = outdim3*in_channels\n",
    "\n",
    "    for i in range(outdim1):\n",
    "        for j in range(outdim2):\n",
    "            outputs[i*outstep1 + j*outstep2 : i*outstep1 + j*outstep2+num] = fin[offset1+i*instep1+j*instep2:offset1+i*instep1+j*instep2+num]\n",
    "    return outputs\n",
    "        \n",
    "inshp = (9,7,8,9)\n",
    "pad0 = 3\n",
    "pad1 = 2\n",
    "pad2 = 2\n",
    "pad3 = 1\n",
    "pad4 = 2\n",
    "pad5 = 3\n",
    "pad = (pad0,pad1,pad2,pad3,pad4,pad5)\n",
    "a = keras.layers.Input(inshp)\n",
    "b = keras.layers.Cropping3D(((pad0,pad1),(pad2,pad3),(pad4,pad5)))(a)\n",
    "model = keras.models.Model(a,b)\n",
    "\n",
    "inputs = np.random.random(inshp)\n",
    "y = model.predict(inputs[np.newaxis,...])[0:]\n",
    "y1 = crop3d(inputs,pad)\n",
    "np.max(np.abs(y.flatten()-y1.flatten()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.flatten()[offset1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[1].__class__.__name__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# # model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### model testing\n",
    "\n",
    "inshape = (13,10)\n",
    "pool_size=3\n",
    "stride=1\n",
    "dilation=1\n",
    "num_filters=10\n",
    "kernel_size=3\n",
    "pad = 'same'\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.Dense(10)(a)\n",
    "c = keras.layers.AveragePooling1D(pool_size=pool_size, strides=stride, padding=pad)(b)\n",
    "d = keras.layers.Conv1D(filters=num_filters, kernel_size=kernel_size, strides=stride, padding=pad, dilation_rate=dilation)(c)\n",
    "e = keras.layers.Input((12,10))\n",
    "f = keras.layers.Dense(15)(e)\n",
    "g = keras.layers.LSTM(10)(f)\n",
    "h = keras.layers.add([g,e])\n",
    "model = keras.models.Model(inputs=[a,e], outputs=[h])\n",
    "\n",
    "# a = keras.layers.Input(inshape)\n",
    "# b = keras.layers.Input(inshape)\n",
    "# c = keras.layers.LSTM(20)\n",
    "# d = c(a)\n",
    "# e = c(b)\n",
    "# model = keras.models.Model(inputs=[a,b], outputs=[d,e])\n",
    "\n",
    "#print(model.layers[1].input_shape)\n",
    "#print(model.layers[1].output_shape)\n",
    "#print(model.layers[1].get_weights()[0].shape)\n",
    "#model.layers[2].get_config()\n",
    "model.layers[-1].input_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### pad2d\n",
    "inshp = (3,4,2)\n",
    "a = keras.layers.Input(inshp)\n",
    "b = keras.layers.ZeroPadding2D(padding=((1,2),(3,4)))(a)\n",
    "model = keras.models.Model(inputs=a, outputs=b)\n",
    "x = np.ones(inshp)\n",
    "x = x[np.newaxis,...]\n",
    "y = model.predict(x)\n",
    "y = np.squeeze(y)\n",
    "y.shape    \n",
    "\n",
    "def pad2d(inputs,fill,pad):\n",
    "    in_height = inputs.shape[0]\n",
    "    in_width = inputs.shape[1]\n",
    "    in_channels = inputs.shape[2]\n",
    "    pad_top = pad[0]\n",
    "    pad_bottom = pad[1]\n",
    "    pad_left = pad[2]\n",
    "    pad_right = pad[3]\n",
    "    output = np.zeros((in_height+pad_top+pad_bottom)*(in_width+pad_left+pad_right)*(in_channels))\n",
    "    fin = inputs.flatten()\n",
    "    offset = in_channels*(pad_left+pad_right+in_width)*pad_top + in_channels*pad_left\n",
    "    num = in_channels*in_width;\n",
    "    for i in range(in_height):\n",
    "        for j in range(num):\n",
    "            output[offset+j] = fin[i*num+j]\n",
    "        offset += num+in_channels*(pad_left+pad_right)\n",
    "    return output\n",
    "x = np.ones(inshp)\n",
    "x1= x[np.newaxis,...]\n",
    "y1 = model.predict(x1)\n",
    "y1 = np.squeeze(y1)\n",
    "y = pad2d(x,0,[1,2,3,4])\n",
    "np.max(np.abs(y1.flatten()-y.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def k2c_sub2idx(sub, shape, ndim):\n",
    "  #/* converts from subscript to linear indices in row major order */\n",
    "    idx = 0\n",
    "    temp = 0;\n",
    "    for i in range(ndim):\n",
    "        temp = sub[i];\n",
    "        for j in range(ndim-1,i,-1):\n",
    "            temp *= shape[j]\n",
    "        idx += temp;\n",
    "    return int(idx)\n",
    "\n",
    "def conv2d(inputs,kernel,bias,stride,dilation,output):\n",
    "    out_rows = output.shape[0]\n",
    "    out_cols = output.shape[1]\n",
    "    out_channels= output.shape[2]\n",
    "    in_channels = inputs.shape[2];\n",
    "    fin = inputs.flatten()\n",
    "    fkernel = kernel.flatten()\n",
    "    foutput = np.zeros(output.size)\n",
    "   \n",
    "    for x0 in range(out_rows):\n",
    "        for x1 in range(out_cols):\n",
    "            for k in range(out_channels):\n",
    "                for z0 in range(kernel.shape[0]):\n",
    "                    for z1 in range(kernel.shape[1]):\n",
    "                        for q in range(in_channels):\n",
    "                            outsub = [x0,x1,k]\n",
    "                            inpsub = [x0*stride[0] + dilation[0]*z0, x1*stride[1] + dilation[1]*z1, q]\n",
    "                            kersub = [z0,z1,q,k]\n",
    "                            foutput[k2c_sub2idx(outsub,output.shape,output.ndim)] += \\\n",
    "                            fkernel[k2c_sub2idx(kersub,kernel.shape,kernel.ndim)]*\\\n",
    "                            fin[k2c_sub2idx(inpsub,inputs.shape,inputs.ndim)]\n",
    "    for i in range(0,output.size,bias.size):\n",
    "        for j in range(bias.size):\n",
    "            foutput[i+j] += bias[j]\n",
    "    return foutput\n",
    "inshape = (10,15,3)\n",
    "stride=(1,1)\n",
    "dilation = (2,2)\n",
    "kernel_size = (2,4)\n",
    "num_filters = 15\n",
    "padding = 'same'\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.Conv2D(filters=num_filters, dilation_rate=dilation, kernel_size=kernel_size, strides=stride, padding=padding)(a)\n",
    "model = keras.models.Model(inputs=[a], outputs=[b])\n",
    "layer = model.layers[1]\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "y = np.squeeze(y)\n",
    "if padding is 'same':\n",
    "    pad_along_height = dilation[0]*(kernel_size[0]-1)\n",
    "    pad_top = int(pad_along_height // 2)\n",
    "    pad_bottom = int(pad_along_height - pad_top)\n",
    "    pad_along_width = dilation[1]*(kernel_size[1]-1)\n",
    "    pad_left = pad_along_width//2\n",
    "    pad_right = pad_along_width - pad_left\n",
    "elif padding is 'valid':\n",
    "    pad_along_height=0\n",
    "    pad_along_width=0\n",
    "    pad_top=0\n",
    "    pad_bottom=0\n",
    "    pad_left = 0\n",
    "    pad_right = 0\n",
    "    \n",
    "padshp = (x.shape[0]+pad_along_height,x.shape[1]+pad_along_width,x.shape[2])\n",
    "pad = [pad_top,pad_bottom,pad_left,pad_right]\n",
    "kernel = model.layers[1].get_weights()[0]\n",
    "bias = model.layers[1].get_weights()[1]\n",
    "x2 = pad2d(x,0,pad).reshape(padshp)\n",
    "\n",
    "y2 = conv2d(x2,kernel,bias,stride,dilation,np.zeros(y.shape))\n",
    "print(np.max(np.abs(y.flatten()-y2.flatten())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "layer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inshp = (31,21,5)\n",
    "x = np.random.random(inshp)\n",
    "y = np.max(x,tuple(np.arange(x.ndim-1)))\n",
    "\n",
    "a = keras.layers.Input(inshp)\n",
    "b = keras.layers.GlobalMaxPooling2D()(a)\n",
    "model = keras.models.Model(inputs=a,outputs=b)\n",
    "y1 = model.predict(x[np.newaxis,...])\n",
    "\n",
    "def glomax(inputs):\n",
    "    fin = inputs.flatten()\n",
    "    chan = inputs.shape[-1]\n",
    "    outputs = np.zeros(chan)\n",
    "    for i in range(chan):\n",
    "        outputs[i] = fin[i]\n",
    "    for i in range(0,fin.size,chan):\n",
    "        for j in range(chan):\n",
    "            if outputs[j]<fin[i+j]:\n",
    "                outputs[j] = fin[i+j]\n",
    "    return outputs\n",
    "            \n",
    "y2 = glomax(x)\n",
    "print(np.max(np.abs(y-y1)))\n",
    "print(np.max(np.abs(y2-y1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shape1 = (None,5,4,2)\n",
    "shape2 = (None,5,4,1)\n",
    "output_shape = list(shape1[:-len(shape2)])\n",
    "for i, j in zip(shape1[-len(shape2):], shape2):\n",
    "    if i is None or j is None:\n",
    "        output_shape.append(None)\n",
    "    elif i == 1:\n",
    "        output_shape.append(j)\n",
    "    elif j == 1:\n",
    "        output_shape.append(i)\n",
    "    else:\n",
    "        if i != j:\n",
    "            raise ValueError('Operands could not be broadcast '\n",
    "                             'together with shapes ' +\n",
    "                             str(shape1) + ' ' + str(shape2))\n",
    "        output_shape.append(i)\n",
    "set([shape1,shape2]) # check if all inputs are the same shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### bidirectional\n",
    "\n",
    "inshape = (8,32)\n",
    "init1 = keras.initializers.Constant(.04)\n",
    "init2 = keras.initializers.Identity()\n",
    "af = keras.layers.Input(inshape)\n",
    "bf = keras.layers.LSTM(5, return_sequences=True, return_state=False, kernel_initializer=init1, recurrent_initializer=init2)(af)\n",
    "fwmodel = keras.models.Model(inputs=af, outputs=bf)\n",
    "\n",
    "ab = keras.layers.Input(inshape)\n",
    "bb = keras.layers.LSTM(5, return_sequences=True, go_backwards=True, kernel_initializer=init1, recurrent_initializer=init2)(ab)\n",
    "bwmodel = keras.models.Model(inputs=ab, outputs=bb)\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x= x[np.newaxis,...]\n",
    "yfw = fwmodel.predict(x)\n",
    "ybw = bwmodel.predict(x)\n",
    "xf = np.flip(x,axis=1)\n",
    "yffw = fwmodel.predict(xf)\n",
    "yfbw = bwmodel.predict(xf)\n",
    "print(np.max(np.abs(yfw-ybw)))\n",
    "print(np.max(np.abs(yfw-yffw)))\n",
    "print(np.max(np.abs(ybw-yffw)))\n",
    "print(np.max(np.abs(ybw-yfbw)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "story_maxlen = 15\n",
    "query_maxlen = 22\n",
    "vocab_size = 50\n",
    "input_sequence = keras.layers.Input((story_maxlen,))\n",
    "question = keras.layers.Input((query_maxlen,))\n",
    "input_encoder_m = keras.models.Sequential()\n",
    "input_encoder_m.add(keras.layers.Embedding(input_dim=vocab_size,\n",
    "                                           output_dim=64))\n",
    "input_encoder_m.add(keras.layers.Dropout(0.3))\n",
    "input_encoder_c = keras.models.Sequential()\n",
    "input_encoder_c.add(keras.layers.Embedding(input_dim=vocab_size,\n",
    "                                           output_dim=query_maxlen))\n",
    "input_encoder_c.add(keras.layers.Dropout(0.3))\n",
    "question_encoder = keras.models.Sequential()\n",
    "question_encoder.add(keras.layers.Embedding(input_dim=vocab_size,\n",
    "                                            output_dim=64,\n",
    "                                            input_length=query_maxlen))\n",
    "question_encoder.add(keras.layers.Dropout(0.3))\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)\n",
    "match = keras.layers.dot(\n",
    "    [input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = keras.layers.Activation('softmax')(match)\n",
    "response = keras.layers.add([match, input_encoded_c])\n",
    "response = keras.layers.Permute((2, 1))(response)\n",
    "answer = keras.layers.concatenate([response, question_encoded])\n",
    "answer = keras.layers.LSTM(32)(answer)\n",
    "answer = keras.layers.Dropout(0.3)(answer)\n",
    "answer = keras.layers.Dense(vocab_size)(answer)\n",
    "answer = keras.layers.Activation('softmax')(answer)\n",
    "model = keras.models.Model([input_sequence, question], answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.layers[4].input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inshape = (10,11,12)\n",
    "axis=2\n",
    "init = keras.initializers.RandomUniform(minval=.1, maxval=2.0)\n",
    "center=False\n",
    "scale=False\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.BatchNormalization(axis=axis, center=center, scale=scale, beta_initializer=init,\n",
    "                                    gamma_initializer=init,  moving_variance_initializer=init, moving_mean_initializer=init)(a)\n",
    "model = keras.models.Model(inputs=a, outputs=b)\n",
    "epsilon = .001\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y1 = model.predict(x1)\n",
    "\n",
    "def batchnorm(inputs, mean,variance, gamma,beta,epsilon,axis):\n",
    "    fin = inputs.flatten()\n",
    "    shp = inputs.shape\n",
    "    offset = 1\n",
    "    for i in range(axis+1,inputs.ndim,1):\n",
    "        offset *= shp[i]\n",
    "    step = shp[axis]\n",
    "    y = np.zeros(inputs.size)\n",
    "    stdev = np.sqrt(variance+epsilon)\n",
    "    for i in range(inputs.size):\n",
    "        y[i] = (fin[i] - mean[(i//offset)%shp[axis]]) / stdev[(i//offset)%shp[axis]] *\\\n",
    "        gamma[(i//offset)%shp[axis]] + beta[(i//offset)%shp[axis]]\n",
    "    return y\n",
    "layer = model.layers[1]\n",
    "if center and scale:\n",
    "    gamma = layer.get_weights()[0]\n",
    "    beta = layer.get_weights()[1]\n",
    "    mean = layer.get_weights()[2] \n",
    "    variance = layer.get_weights()[3]\n",
    "elif center:\n",
    "    beta = layer.get_weights()[0]\n",
    "    mean = layer.get_weights()[1]\n",
    "    variance = layer.get_weights()[2]\n",
    "    gamma = np.ones(mean.shape)\n",
    "elif scale:\n",
    "    gamma = layer.get_weights()[0]\n",
    "    mean = layer.get_weights()[1] \n",
    "    variance = layer.get_weights()[2]\n",
    "    beta = np.zeros(mean.shape)\n",
    "else:\n",
    "    mean = layer.get_weights()[0] \n",
    "    variance = layer.get_weights()[1]\n",
    "    beta = np.zeros(mean.shape)\n",
    "    gamma = np.ones(mean.shape)\n",
    "    \n",
    "    \n",
    "y = batchnorm(x,mean,variance,gamma,beta,epsilon,axis-1)\n",
    "np.max(np.abs(y.flatten()-y1.flatten()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inshp = (10,20)\n",
    "input_dim = 20\n",
    "output_dim = 30\n",
    "a = keras.layers.Input(inshp)\n",
    "b = keras.layers.Embedding(input_dim=input_dim,output_dim=output_dim)(a)\n",
    "model = keras.models.Model(inputs=a,outputs=b)\n",
    "\n",
    "\n",
    "def embed(inputs,kernel):\n",
    "    fin = inputs.flatten().astype(int)\n",
    "    output_dim = kernel.shape[1]\n",
    "    outputs = np.zeros(inputs.size*output_dim)\n",
    "    for i in range(inputs.size):\n",
    "        for j in range(output_dim):\n",
    "            outputs[i*output_dim + j] = kernel.flatten()[fin[i]*output_dim+j]\n",
    "    return outputs\n",
    "layer = model.layers[1]\n",
    "kernel = layer.get_weights()[0]\n",
    "x = 10*np.random.random(inshp).astype(int)\n",
    "x1 = x[np.newaxis,...]\n",
    "y1 = model.predict(x1)\n",
    "y = embed(x,kernel)\n",
    "\n",
    "np.max(np.abs(y.flatten()-y1.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "layer.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "','.join([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = {}\n",
    "name = 'fooo'\n",
    "bar = np.arange(5)\n",
    "a.update({name:bar,'assd':123,'sgsdf':456})\n",
    "','.join(['float* ' + key for key in a.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### types, names, io\n",
    "\n",
    "def layer_type(layer):\n",
    "    return str(layer.__class__).split('.')[-1][0:-2]\n",
    "\n",
    "def get_all_io_names(model):\n",
    "    a = [get_layer_io_names(layer) for layer in model.layers]\n",
    "    return list(set(flatten(a)))\n",
    "\n",
    "def get_layer_num_io(layer):\n",
    "    num_inputs = 0\n",
    "    error = False\n",
    "    while not error:\n",
    "        try:\n",
    "            layer.get_input_at(num_inputs)\n",
    "            num_inputs +=1\n",
    "        except ValueError:\n",
    "            error = True\n",
    "    \n",
    "    num_outputs = 0\n",
    "    error = False\n",
    "    while not error:\n",
    "        try:\n",
    "            layer.get_output_at(num_outputs)\n",
    "            num_outputs +=1\n",
    "        except ValueError:\n",
    "            error = True\n",
    "    return num_inputs, num_outputs\n",
    "\n",
    "def get_layer_io_names(layer):\n",
    "    num_inputs, num_outputs = get_layer_num_io(layer)\n",
    "    inputs = []\n",
    "    # num_inputs>1 -> shared layer\n",
    "    for i in range(num_inputs):\n",
    "        # is the input a list?\n",
    "        if isinstance(layer.get_input_at(i), list):\n",
    "            temp_list = []\n",
    "            list_length = len(layer.get_input_at(i))\n",
    "            for j in range(list_length):\n",
    "                name = str(layer.get_input_at(i)[j]).split()[0].split('\"')[1].split('/')[0].split(':')[0]\n",
    "                temp_list.append(name)\n",
    "            inputs.insert(i,temp_list)\n",
    "        else:\n",
    "            name = str(layer.get_input_at(i)).split()[0].split('\"')[1].split('/')[0].split(':')[0]\n",
    "            inputs.insert(i,name)\n",
    "    \n",
    "    outputs = []       \n",
    "    for i in range(num_outputs):\n",
    "        # is the output a list?\n",
    "        if isinstance(layer.get_output_at(i), list):\n",
    "            temp_list = []\n",
    "            list_length = len(layer.get_output_at(i))\n",
    "            for j in range(list_length):\n",
    "                name = str(layer.get_output_at(i)[j]).split()[0].split('\"')[1].split('/')[0].split(':')[0]\n",
    "                temp_list.append(name)\n",
    "            outputs.insert(i,temp_list)\n",
    "        else:\n",
    "            name = str(layer.get_output_at(i)).split()[0].split('\"')[1].split('/')[0].split(':')[0]\n",
    "            outputs.insert(i,name)\n",
    "\n",
    "    return inputs, outputs\n",
    "\n",
    "def get_model_io_names(model):\n",
    "    num_inputs = len(model.inputs)\n",
    "    num_outputs = len(model.outputs)\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for i in range(num_inputs):\n",
    "        nm = str(model.inputs[i]).split()[0].split('\"')[1].split('/')[0].split(':')[0]\n",
    "        inputs.append(nm)\n",
    "    for i in range(num_outputs):\n",
    "        nm = str(model.outputs[i]).split()[0].split('\"')[1].split('/')[0].split(':')[0]\n",
    "        outputs.append(nm)\n",
    "    return inputs, outputs\n",
    "\n",
    "def flatten(x):\n",
    "        if isinstance(x, list) or isinstance(x, tuple):\n",
    "            return [a for i in x for a in flatten(i)]\n",
    "        else:\n",
    "            return [x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(8, (3, 3), padding='same',\n",
    "                              input_shape=(32, 32, 3)))\n",
    "model.add(keras.layers.Activation('relu'))\n",
    "model.add(keras.layers.Conv2D(8, (3, 3)))\n",
    "model.add(keras.layers.Activation('relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "model.add(keras.layers.Conv2D(8, (3, 3), padding='same'))\n",
    "model.add(keras.layers.Activation('relu'))\n",
    "model.add(keras.layers.Conv2D(8, (3, 3)))\n",
    "model.add(keras.layers.Activation('relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(20))\n",
    "model.add(keras.layers.Activation('relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(10))\n",
    "model.add(keras.layers.Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "inshape = (32,32,3)\n",
    "num_tests = 10\n",
    "inp1 = [np.random.random(inshape) for i in range(num_tests)]\n",
    "inp = [inpt[np.newaxis,...] for inpt in inp1]\n",
    "t1 = time.perf_counter_ns()\n",
    "for i in range(num_tests):\n",
    "    outp = model.predict(inp[i])\n",
    "t2 = time.perf_counter_ns()\n",
    "print((t2-t1)/1000/num_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "oldtimes = 5\n",
    "profile_length = 65\n",
    "future_actuators = 3\n",
    "num_actuators = 4\n",
    "\n",
    "profile_input = keras.layers.Input((oldtimes,profile_length))\n",
    "profile_response = keras.layers.Dense(30, activation='relu')(profile_input)\n",
    "profile_response = keras.layers.Dense(30, activation='relu')(profile_response)\n",
    "profile_response = keras.layers.LSTM(30, activation='relu', recurrent_activation='hard_sigmoid', return_sequences=True)(profile_response)\n",
    "profile_response = keras.layers.Dense(30, activation='relu')(profile_response)\n",
    "\n",
    "actuator_input = keras.layers.Input((oldtimes+future_actuators,num_actuators))\n",
    "actuator_response = keras.layers.Dense(num_actuators, activation='relu')(actuator_input)\n",
    "actuator_response = keras.layers.Dense(num_actuators, activation='relu')(actuator_response)\n",
    "actuator_response = keras.layers.LSTM(num_actuators, activation='relu', recurrent_activation='hard_sigmoid', return_sequences=True)(actuator_response)\n",
    "actuator_response = keras.layers.Permute((2,1))(actuator_response)\n",
    "actuator_response = keras.layers.Dense(5, activation='relu')(actuator_response)\n",
    "actuator_response = keras.layers.Permute((2,1))(actuator_response)\n",
    "actuator_response = keras.layers.Dense(30, activation='relu')(actuator_response)\n",
    "actuator_response = keras.layers.Dense(30, activation='relu')(actuator_response)\n",
    "\n",
    "total_response = keras.layers.Multiply()([actuator_response,profile_response])\n",
    "total_response = keras.layers.LSTM(30, activation='relu', recurrent_activation='hard_sigmoid')(total_response)\n",
    "total_response = keras.layers.Dense(45, activation='relu')(total_response)\n",
    "total_response = keras.layers.Dense(65)(total_response)\n",
    "\n",
    "model1 = keras.models.Model(inputs=[actuator_input,profile_input], outputs=total_response)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "oldtimes = 5\n",
    "profile_length = 65\n",
    "future_actuators = 3\n",
    "num_actuators = 4\n",
    "\n",
    "profile_input = keras.layers.Input((oldtimes,profile_length))\n",
    "profile_response = keras.layers.Dense(30, activation='relu')(profile_input)\n",
    "profile_response = keras.layers.Dense(30, activation='relu')(profile_response)\n",
    "profile_response = keras.layers.LSTM(30, activation='relu', recurrent_activation='hard_sigmoid', return_sequences=True)(profile_response)\n",
    "profile_response = keras.layers.Dense(30, activation='relu')(profile_response)\n",
    "\n",
    "actuator_input = keras.layers.Input((oldtimes+future_actuators,num_actuators))\n",
    "actuator_response = keras.layers.Dense(oldtimes, activation='relu')(actuator_input)\n",
    "actuator_response = keras.layers.Dense(oldtimes, activation='relu')(actuator_response)\n",
    "actuator_response = keras.layers.LSTM(oldtimes, activation='relu', recurrent_activation='hard_sigmoid', return_sequences=True)(actuator_response)\n",
    "\n",
    "\n",
    "total_response = keras.layers.Dot(axes=(2,1))([actuator_response,profile_response])\n",
    "total_response = keras.layers.LSTM(30, activation='relu', recurrent_activation='hard_sigmoid')(total_response)\n",
    "total_response = keras.layers.Dense(45, activation='relu')(total_response)\n",
    "total_response = keras.layers.Dense(65)(total_response)\n",
    "\n",
    "model2 = keras.models.Model(inputs=[actuator_input,profile_input], outputs=total_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = keras.layers.Add()([model1.outputs[0],model3.outputs[0]])\n",
    "model = keras.models.Model(inputs = [model1.inputs[0], model1.inputs[1], model3.inputs[0]], outputs=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model3 = keras.models.Sequential()\n",
    "model3.add(keras.layers.Conv1D(65,3, input_shape=(3,20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "story_maxlen = 15\n",
    "query_maxlen = 22\n",
    "vocab_size = 50\n",
    "input_sequence = keras.layers.Input((story_maxlen,))\n",
    "question = keras.layers.Input((query_maxlen,))\n",
    "input_encoder_m = keras.models.Sequential()\n",
    "input_encoder_m.add(keras.layers.Embedding(input_dim=vocab_size,\n",
    "                                           output_dim=64))\n",
    "input_encoder_m.add(keras.layers.Dropout(0.3))\n",
    "input_encoder_c = keras.models.Sequential()\n",
    "input_encoder_c.add(keras.layers.Embedding(input_dim=vocab_size,\n",
    "                                           output_dim=query_maxlen))\n",
    "input_encoder_c.add(keras.layers.Dropout(0.3))\n",
    "question_encoder = keras.models.Sequential()\n",
    "question_encoder.add(keras.layers.Embedding(input_dim=vocab_size,\n",
    "                                            output_dim=64,\n",
    "                                            input_length=query_maxlen))\n",
    "question_encoder.add(keras.layers.Dropout(0.3))\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)\n",
    "match = keras.layers.dot(\n",
    "    [input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = keras.layers.Activation('softmax')(match)\n",
    "response = keras.layers.add([match, input_encoded_c])\n",
    "response = keras.layers.Permute((2, 1))(response)\n",
    "answer = keras.layers.concatenate([response, question_encoded])\n",
    "answer = keras.layers.LSTM(32)(answer)\n",
    "answer = keras.layers.Dropout(0.3)(answer)\n",
    "answer = keras.layers.Dense(vocab_size)(answer)\n",
    "answer = keras.layers.Activation('softmax')(answer)\n",
    "model = keras.models.Model([input_sequence, question], answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "convert_sequential_to_model(model).layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def convert_sequential_to_model(model):\n",
    "    \"\"\"Convert a sequential model to the underlying functional format\"\"\"\n",
    "    if type(model).__name__ == 'Sequential':\n",
    "        if hasattr(model, '_inbound_nodes'):\n",
    "            inbound_nodes = model._inbound_nodes\n",
    "        elif hasattr(model, 'inbound_nodes'):\n",
    "            inbound_nodes = model.inbound_nodes\n",
    "        else:\n",
    "            raise ValueError('can not get (_)inbound_nodes from model')\n",
    "        # Since Keras 2.2.0\n",
    "        if model.model == model:\n",
    "            input_layer = keras.layers.Input(batch_shape=model.layers[0].input_shape)\n",
    "            prev_layer = input_layer\n",
    "            for layer in model.layers:\n",
    "                prev_layer = layer(prev_layer)\n",
    "            funcmodel = keras.models.Model([input_layer], [prev_layer])\n",
    "            model = funcmodel\n",
    "        else:\n",
    "            model = model.model\n",
    "        if hasattr(model, '_inbound_nodes'):\n",
    "            model._inbound_nodes = inbound_nodes\n",
    "        elif hasattr(model, 'inbound_nodes'):\n",
    "            model.inbound_nodes = inbound_nodes\n",
    "    assert model.layers\n",
    "    for i in range(len(model.layers)):\n",
    "        if type(model.layers[i]).__name__ in ['Model', 'Sequential']:\n",
    "            model.layers[i] = convert_sequential_to_model(model.layers[i])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "oldtimes = 5\n",
    "profile_length = 30\n",
    "future_actuators = 3\n",
    "num_actuators = 4\n",
    "\n",
    "etemp_input = keras.layers.Input((oldtimes, profile_length))\n",
    "etemp_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(etemp_input)\n",
    "etemp_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(etemp_response)\n",
    "etemp_response = keras.layers.LSTM(\n",
    "    profile_length, activation='relu', recurrent_activation='hard_sigmoid',\n",
    "    return_sequences=True)(etemp_response)\n",
    "etemp_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(etemp_response)\n",
    "\n",
    "pressure_input = keras.layers.Input((oldtimes, profile_length))\n",
    "pressure_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(pressure_input)\n",
    "pressure_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(pressure_response)\n",
    "pressure_response = keras.layers.LSTM(\n",
    "    profile_length, activation='relu', recurrent_activation='hard_sigmoid',\n",
    "    return_sequences=True)(pressure_response)\n",
    "pressure_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(pressure_response)\n",
    "\n",
    "edens_input = keras.layers.Input((oldtimes, profile_length))\n",
    "edens_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(edens_input)\n",
    "edens_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(edens_response)\n",
    "edens_response = keras.layers.LSTM(\n",
    "    profile_length, activation='relu', recurrent_activation='hard_sigmoid',\n",
    "    return_sequences=True)(edens_response)\n",
    "edens_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(edens_response)\n",
    "\n",
    "itemp_input = keras.layers.Input((oldtimes, profile_length))\n",
    "itemp_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(itemp_input)\n",
    "itemp_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(itemp_response)\n",
    "itemp_response = keras.layers.LSTM(\n",
    "    profile_length, activation='relu', recurrent_activation='hard_sigmoid',\n",
    "    return_sequences=True)(itemp_response)\n",
    "itemp_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(itemp_response)\n",
    "\n",
    "rotation_input = keras.layers.Input((oldtimes, profile_length))\n",
    "rotation_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(rotation_input)\n",
    "rotation_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(rotation_response)\n",
    "rotation_response = keras.layers.LSTM(\n",
    "    profile_length, activation='relu', recurrent_activation='hard_sigmoid',\n",
    "    return_sequences=True)(rotation_response)\n",
    "rotation_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(rotation_response)\n",
    "\n",
    "ffprime_input = keras.layers.Input((oldtimes, profile_length))\n",
    "ffprime_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(ffprime_input)\n",
    "ffprime_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(ffprime_response)\n",
    "ffprime_response = keras.layers.LSTM(\n",
    "    profile_length, activation='relu', recurrent_activation='hard_sigmoid',\n",
    "    return_sequences=True)(ffprime_response)\n",
    "ffprime_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(ffprime_response)\n",
    "\n",
    "actuator_input = keras.layers.Input((oldtimes+future_actuators, num_actuators))\n",
    "actuator_response1 = keras.layers.Dense(\n",
    "    oldtimes, activation='relu')(actuator_input)\n",
    "actuator_response1 = keras.layers.Dense(\n",
    "    oldtimes, activation='relu')(actuator_response1)\n",
    "actuator_response1 = keras.layers.LSTM(\n",
    "    oldtimes, activation='relu', recurrent_activation='hard_sigmoid',\n",
    "    return_sequences=True)(actuator_response1)\n",
    "actuator_response2 = keras.layers.Dense(\n",
    "    oldtimes, activation='relu')(actuator_input)\n",
    "actuator_response2 = keras.layers.Dense(\n",
    "    oldtimes, activation='relu')(actuator_response2)\n",
    "actuator_response2 = keras.layers.LSTM(\n",
    "    oldtimes, activation='relu', recurrent_activation='hard_sigmoid',\n",
    "    return_sequences=True)(actuator_response2)\n",
    "actuator_response3 = keras.layers.Dense(\n",
    "    oldtimes, activation='relu')(actuator_input)\n",
    "actuator_response3 = keras.layers.Dense(\n",
    "    oldtimes, activation='relu')(actuator_response3)\n",
    "actuator_response3 = keras.layers.LSTM(\n",
    "    oldtimes, activation='relu', recurrent_activation='hard_sigmoid',\n",
    "    return_sequences=True)(actuator_response3)\n",
    "actuator_response4 = keras.layers.Dense(\n",
    "    oldtimes, activation='relu')(actuator_input)\n",
    "actuator_response4 = keras.layers.Dense(\n",
    "    oldtimes, activation='relu')(actuator_response4)\n",
    "actuator_response4 = keras.layers.LSTM(\n",
    "    oldtimes, activation='relu', recurrent_activation='hard_sigmoid',\n",
    "    return_sequences=True)(actuator_response4)\n",
    "actuator_response5 = keras.layers.Dense(\n",
    "    oldtimes, activation='relu')(actuator_input)\n",
    "actuator_response5 = keras.layers.Dense(\n",
    "    oldtimes, activation='relu')(actuator_response5)\n",
    "actuator_response5 = keras.layers.LSTM(\n",
    "    oldtimes, activation='relu', recurrent_activation='hard_sigmoid',\n",
    "    return_sequences=True)(actuator_response5)\n",
    "actuator_response6 = keras.layers.Dense(\n",
    "    oldtimes, activation='relu')(actuator_input)\n",
    "actuator_response6 = keras.layers.Dense(\n",
    "    oldtimes, activation='relu')(actuator_response6)\n",
    "actuator_response6 = keras.layers.LSTM(\n",
    "    oldtimes, activation='relu', recurrent_activation='hard_sigmoid',\n",
    "    return_sequences=True)(actuator_response6)\n",
    "\n",
    "etemp_actuator_response = keras.layers.Dot(axes=(2, 1))(\n",
    "    [actuator_response1, etemp_response])\n",
    "etemp_actuator_response = keras.layers.LSTM(\n",
    "    profile_length, activation='relu', recurrent_activation='hard_sigmoid',\n",
    "    return_sequences=True)(etemp_actuator_response)\n",
    "etemp_actuator_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(etemp_actuator_response)\n",
    "etemp_actuator_response = keras.layers.Dense(\n",
    "    profile_length)(etemp_actuator_response)\n",
    "\n",
    "\n",
    "itemp_actuator_response = keras.layers.Dot(axes=(2, 1))(\n",
    "    [actuator_response2, itemp_response])\n",
    "itemp_actuator_response = keras.layers.LSTM(\n",
    "    profile_length, activation='relu', recurrent_activation='hard_sigmoid',\n",
    "    return_sequences=True)(itemp_actuator_response)\n",
    "itemp_actuator_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(itemp_actuator_response)\n",
    "itemp_actuator_response = keras.layers.Dense(\n",
    "    profile_length)(itemp_actuator_response)\n",
    "\n",
    "\n",
    "edens_actuator_response = keras.layers.Dot(axes=(2, 1))(\n",
    "    [actuator_response3, edens_response])\n",
    "edens_actuator_response = keras.layers.LSTM(\n",
    "    profile_length, activation='relu', recurrent_activation='hard_sigmoid',\n",
    "    return_sequences=True)(edens_actuator_response)\n",
    "edens_actuator_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(edens_actuator_response)\n",
    "edens_actuator_response = keras.layers.Dense(\n",
    "    profile_length)(edens_actuator_response)\n",
    "\n",
    "\n",
    "pressure_actuator_response = keras.layers.Dot(axes=(2, 1))(\n",
    "    [actuator_response4, pressure_response])\n",
    "pressure_actuator_response = keras.layers.LSTM(\n",
    "    profile_length, activation='relu', recurrent_activation='hard_sigmoid',\n",
    "    return_sequences=True)(pressure_actuator_response)\n",
    "pressure_actuator_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(pressure_actuator_response)\n",
    "pressure_actuator_response = keras.layers.Dense(\n",
    "    profile_length)(pressure_actuator_response)\n",
    "\n",
    "\n",
    "ffprime_actuator_response = keras.layers.Dot(axes=(2, 1))(\n",
    "    [actuator_response5, ffprime_response])\n",
    "ffprime_actuator_response = keras.layers.LSTM(\n",
    "    profile_length, activation='relu', recurrent_activation='hard_sigmoid',\n",
    "    return_sequences=True)(ffprime_actuator_response)\n",
    "ffprime_actuator_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(ffprime_actuator_response)\n",
    "ffprime_actuator_response = keras.layers.Dense(\n",
    "    profile_length)(ffprime_actuator_response)\n",
    "\n",
    "\n",
    "rotation_actuator_response = keras.layers.Dot(axes=(2, 1))(\n",
    "    [actuator_response6, rotation_response])\n",
    "rotation_actuator_response = keras.layers.LSTM(\n",
    "    profile_length, activation='relu', recurrent_activation='hard_sigmoid',\n",
    "    return_sequences=True)(rotation_actuator_response)\n",
    "rotation_actuator_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(rotation_actuator_response)\n",
    "rotation_actuator_response = keras.layers.Dense(\n",
    "    profile_length)(rotation_actuator_response)\n",
    "\n",
    "\n",
    "etemp_etemp_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(etemp_actuator_response)\n",
    "itemp_etemp_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(itemp_actuator_response)\n",
    "edens_etemp_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(edens_actuator_response)\n",
    "ffprime_etemp_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(ffprime_actuator_response)\n",
    "pressure_etemp_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(pressure_actuator_response)\n",
    "rotation_etemp_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(rotation_actuator_response)\n",
    "\n",
    "edens_etemp_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(etemp_actuator_response)\n",
    "itemp_edens_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(itemp_actuator_response)\n",
    "edens_edens_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(edens_actuator_response)\n",
    "ffprime_edens_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(ffprime_actuator_response)\n",
    "pressure_edens_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(pressure_actuator_response)\n",
    "rotation_edens_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(rotation_actuator_response)\n",
    "\n",
    "\n",
    "etemp_total_response = keras.layers.Multiply()([etemp_etemp_response,\n",
    "                                                itemp_etemp_response,\n",
    "                                                edens_etemp_response,\n",
    "                                                pressure_etemp_response,\n",
    "                                                ffprime_etemp_response,\n",
    "                                                rotation_etemp_response])\n",
    "etemp_total_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(etemp_total_response)\n",
    "etemp_total_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(etemp_total_response)\n",
    "etemp_total_response = keras.layers.LSTM(\n",
    "    profile_length, activation='relu')(etemp_total_response)\n",
    "etemp_total_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(etemp_total_response)\n",
    "etemp_total_response = keras.layers.Dense(profile_length)(etemp_total_response)\n",
    "\n",
    "edens_total_response = keras.layers.Multiply()([edens_edens_response,\n",
    "                                                itemp_edens_response,\n",
    "                                                edens_etemp_response,\n",
    "                                                pressure_edens_response,\n",
    "                                                ffprime_edens_response,\n",
    "                                                rotation_edens_response])\n",
    "edens_total_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(edens_total_response)\n",
    "edens_total_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(edens_total_response)\n",
    "edens_total_response = keras.layers.LSTM(\n",
    "    profile_length, activation='relu')(edens_total_response)\n",
    "edens_total_response = keras.layers.Dense(\n",
    "    profile_length, activation='relu')(edens_total_response)\n",
    "edens_total_response = keras.layers.Dense(profile_length)(edens_total_response)\n",
    "\n",
    "model = keras.models.Model(\n",
    "    inputs=[actuator_input, etemp_input, edens_input,\n",
    "            itemp_input, ffprime_input, pressure_input, rotation_input],\n",
    "    outputs=[etemp_total_response, edens_total_response])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pydot\n",
    "keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pydot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation / Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = keras.layers.Input((4,3),name='input1')\n",
    "input2 = keras.layers.Input((4,3),name='input2')\n",
    "a = keras.layers.Dense(5)(input1)\n",
    "b = keras.layers.Dense(5)(input2)\n",
    "c = keras.layers.Add()([a,b])\n",
    "d = keras.layers.Dense(4,name='output1')(c)\n",
    "model = keras.models.Model([input1,input2],d)\n",
    "\n",
    "\n",
    "\n",
    "inp = {'input1': np.random.random((10,4,3)),'input2': np.random.random((10,4,3))}\n",
    "outp = {'output1':np.random.random((10,4,4))}\n",
    "    \n",
    "    \n",
    "opt = keras.optimizers.SGD()\n",
    "loss = keras.losses.mean_squared_error\n",
    "model.compile(opt,loss)\n",
    "model.test_on_batch(inp,outp)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'input1': np.random.random((4,3)),\n",
    "             'input2': np.random.random((4,3))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([array([[0.12989215, 0.31319495, 0.74369952],\n",
       "       [0.34659951, 0.14533007, 0.4863328 ],\n",
       "       [0.3613329 , 0.02800335, 0.57165791],\n",
       "       [0.80192597, 0.97902813, 0.42396623]]), array([[0.05222827, 0.21358939, 0.4242369 ],\n",
       "       [0.51737819, 0.11313898, 0.56698686],\n",
       "       [0.00643765, 0.26830582, 0.42616058],\n",
       "       [0.94325988, 0.91114682, 0.39005074]])])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "\n",
    "def normalize(data, method, uniform_over_profile=True):\n",
    "    if method == 'StandardScaler':\n",
    "        if uniform_over_profile:\n",
    "            mean = np.mean(data)\n",
    "            std = np.std(data)\n",
    "        else:\n",
    "            mean = np.mean(data, axis=0)\n",
    "            std = np.std(data, axis=0)\n",
    "        param_dict = {'method': method,\n",
    "                      'mean': mean,\n",
    "                      'std': std}\n",
    "        return (data-mean)/np.maximum(std, np.finfo(np.float32).eps), param_dict\n",
    "\n",
    "    if method == 'MinMax':\n",
    "        if uniform_over_profile:\n",
    "            armin = np.amin(data)\n",
    "            armax = np.amax(data)\n",
    "        else:\n",
    "            armin = np.amin(data, axis=0)\n",
    "            armax = np.amax(data, axis=0)\n",
    "        param_dict = {'method': method,\n",
    "                      'armin': armin,\n",
    "                      'armax': armax}\n",
    "        return (data-armin)/np.maximum((armax-armin), np.finfo(np.float32).eps), param_dict\n",
    "\n",
    "    if method == 'MaxAbs':\n",
    "        if uniform_over_profile:\n",
    "            maxabs = np.amax(np.abs(data))\n",
    "        else:\n",
    "            maxabs = np.amax(np.abs(data), axis=0)\n",
    "        param_dict = {'method': method,\n",
    "                      'maxabs': maxabs}\n",
    "        return data/np.maximum(maxabs, np.finfo(np.float32).eps), param_dict\n",
    "\n",
    "    if method == 'RobustScaler':\n",
    "        if uniform_over_profile:\n",
    "            median = np.median(data)\n",
    "            iqr = np.subtract(*np.percentile(data, [75, 25]))\n",
    "        else:\n",
    "            median = np.median(data, axis=0)\n",
    "            iqr = np.subtract(*np.percentile(data, [75, 25], axis=0))\n",
    "        param_dict = {'method': method,\n",
    "                      'median': median,\n",
    "                      'iqr': iqr}\n",
    "        return (data-median)/np.maximum(iqr, np.finfo(np.float32).eps), param_dict\n",
    "\n",
    "    if method == 'PowerTransform':\n",
    "        def yeo_johnson_transform(x, lmbda):\n",
    "            \"\"\"Return transformed input x following Yeo-Johnson transform with\n",
    "            parameter lambda.\n",
    "            \"\"\"\n",
    "\n",
    "            out = np.zeros_like(x)\n",
    "            pos = x >= 0  # binary mask\n",
    "\n",
    "            # when x >= 0\n",
    "            if abs(lmbda) < np.spacing(1.):\n",
    "                out[pos] = np.log1p(x[pos])\n",
    "            else:  # lmbda != 0\n",
    "                out[pos] = (np.power(x[pos] + 1, lmbda) - 1) / lmbda\n",
    "\n",
    "            # when x < 0\n",
    "            if abs(lmbda - 2) > np.spacing(1.):\n",
    "                out[~pos] = -(np.power(-x[~pos] + 1, 2 - lmbda) - 1) / (2 - lmbda)\n",
    "            else:  # lmbda == 2\n",
    "                out[~pos] = -np.log1p(-x[~pos])\n",
    "\n",
    "            return out\n",
    "\n",
    "        def yeo_johnson_optimize(x):\n",
    "            \"\"\"Find and return optimal lambda parameter of the Yeo-Johnson\n",
    "            transform by MLE, for observed data x.\n",
    "            Like for Box-Cox, MLE is done via the brent optimizer.\n",
    "            \"\"\"\n",
    "\n",
    "            def _neg_log_likelihood(lmbda):\n",
    "                \"\"\"Return the negative log likelihood of the observed data x as a\n",
    "                function of lambda.\"\"\"\n",
    "                x_trans = yeo_johnson_transform(x, lmbda)\n",
    "                n_samples = x.shape[0]\n",
    "\n",
    "                loglike = -n_samples / 2 * np.log(x_trans.var())\n",
    "                loglike += (lmbda - 1) * (np.sign(x) * np.log1p(np.abs(x))).sum()\n",
    "\n",
    "                return -loglike\n",
    "\n",
    "            # choosing bracket -2, 2 like for boxcox\n",
    "            return optimize.brent(_neg_log_likelihood, brack=(-2, 2))\n",
    "        if uniform_over_profile:\n",
    "            lmbda = yeo_johnson_optimize(data.flatten())\n",
    "            y = yeo_johnson_transform(\n",
    "                data.flatten(), lmbda).reshape(data.shape)\n",
    "            mean = np.mean(y)\n",
    "            std = np.std(y)\n",
    "            param_dict = {'method': method,\n",
    "                          'lambda': lmbda,\n",
    "                          'mean': mean,\n",
    "                          'std': std}\n",
    "            return (y-mean)/np.maximum(std, np.finfo(np.float32).eps), param_dict\n",
    "        else:\n",
    "            y = np.zeros_like(data)\n",
    "            lmbda = np.array([yeo_johnson_optimize(col) for col in data.T])\n",
    "            for i, l in enumerate(lmbda):\n",
    "                y[:, i] = yeo_johnson_transform(data[:, i], l)\n",
    "            mean = np.mean(y, axis=0)\n",
    "            std = np.std(y, axis=0)\n",
    "            param_dict = {'method': method,\n",
    "                          'lambda': lmbda,\n",
    "                          'mean': mean,\n",
    "                          'std': std}\n",
    "            return (y-mean)/np.maximum(std, np.finfo(np.float32).eps), param_dict\n",
    "\n",
    "\n",
    "def unnormalize(data, param_dict):\n",
    "    if param_dict['method'] == 'StandardScaler':\n",
    "        return data*np.maximum(param_dict['std'], np.finfo(np.float32).eps) \\\n",
    "            + param_dict['mean']\n",
    "    if param_dict['method'] == 'MinMax':\n",
    "        return data*np.maximum((param_dict['armax']-param_dict['armin']),\n",
    "                               np.finfo(np.float32).eps) + param_dict['armin']\n",
    "    if param_dict['method'] == 'MaxAbs':\n",
    "        return data*np.maximum(param_dict['maxabs'], np.finfo(np.float32).eps)\n",
    "    if param_dict['method'] == 'RobustScaler':\n",
    "        return data*np.maximum(param_dict['iqr'], np.finfo(np.float32).eps) \\\n",
    "            + param_dict['median']\n",
    "    if param_dict['method'] == 'PowerTransform':\n",
    "        def yeo_johnson_inverse_transform(x, lmbda):\n",
    "            \"\"\"Return inverse-transformed input x following Yeo-Johnson inverse\n",
    "            transform with parameter lambda.\n",
    "            \"\"\"\n",
    "            x_inv = np.zeros_like(x)\n",
    "            pos = x >= 0\n",
    "\n",
    "            # when x >= 0\n",
    "            if abs(lmbda) < np.spacing(1.):\n",
    "                x_inv[pos] = np.exp(x[pos]) - 1\n",
    "            else:  # lmbda != 0\n",
    "                x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1\n",
    "\n",
    "            # when x < 0\n",
    "            if abs(lmbda - 2) > np.spacing(1.):\n",
    "                x_inv[~pos] = 1 - np.power(-(2 - lmbda) * x[~pos] + 1,\n",
    "                                           1 / (2 - lmbda))\n",
    "            else:  # lmbda == 2\n",
    "                x_inv[~pos] = 1 - np.exp(-x[~pos])\n",
    "\n",
    "            return x_inv\n",
    "\n",
    "        y = data*np.maximum(param_dict['std'], np.finfo(np.float32).eps) \\\n",
    "            + param_dict['mean']\n",
    "        if param_dict['lambda'].size > 1:\n",
    "            for i, l in enumerate(param_dict['lambda']):\n",
    "                y[:, i] = yeo_johnson_inverse_transform(y[:, i], l)\n",
    "        else:\n",
    "            y = yeo_johnson_inverse_transform(\n",
    "                y.flatten(), param_dict['lambda']).reshape(y.shape)\n",
    "        return y\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random((4,4))\n",
    "method = 'PowerTransform'\n",
    "y,p = normalize(x,method,False)\n",
    "z = unnormalize(y,p)\n",
    "print(x-z)\n",
    "print(np.amin(y[:,1]))\n",
    "print(np.amax(y[:,1]))\n",
    "print(np.mean(y[:,1]))\n",
    "print(np.median(y[:,1]))\n",
    "print(np.std(y[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def load_obj(name):\n",
    "    with open(name+'.pkl', 'rb') as f:\n",
    "        return pickle.load(f,encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/fouriest/SCHOOL/Princeton/PPPL')\n",
    "name = 'final_data'\n",
    "data = load_obj(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "shots = list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shots[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fouriest/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Dense, LSTM, Conv1D, Conv2D, ConvLSTM2D\n",
    "from keras.layers import Dot, Add, Multiply, Concatenate, Reshape, Permute\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "profile_names = ['temp', 'dens', 'rot']\n",
    "actuator_names = ['pinj', 'curr']\n",
    "\n",
    "lookback = 5\n",
    "lookahead = 3\n",
    "profile_length = 32\n",
    "final_profile_channels = 10\n",
    "profile_inshape = (lookback, profile_length)\n",
    "actuator_inshape = (lookback + lookahead,)\n",
    "num_profiles = len(profile_names)\n",
    "num_actuators = len(actuator_names)\n",
    "\n",
    "profile_inputs = []\n",
    "profiles = []\n",
    "for i in range(num_profiles):\n",
    "    profile_inputs.append(\n",
    "        Input(profile_inshape, name='input_' + profile_names[i]))\n",
    "    profiles.append(Reshape((lookback, profile_length, 1))(profile_inputs[i]))\n",
    "    profiles[i] = Dense(units=5, activation='relu')(profiles[i])\n",
    "    profiles[i] = Conv2D(filters=5, kernel_size=(1, 3), strides=(1, 1), padding='same',\n",
    "                         activation='relu')(profiles[i])\n",
    "    profiles[i] = Dense(units=7, activation='relu')(profiles[i])\n",
    "    profiles[i] = Conv2D(filters=10, kernel_size=(1, 5), strides=(1, 1), padding='same',\n",
    "                         activation='relu')(profiles[i])\n",
    "    profiles[i] = Dense(units=15, activation='relu')(profiles[i])\n",
    "    profiles[i] = Conv2D(filters=20, kernel_size=(1, 7), strides=(1, 1), padding='same',\n",
    "                         activation='relu')(profiles[i])\n",
    "    profiles[i] = Reshape((lookback, profile_length, 1, 20))(profiles[i])\n",
    "    profiles[i] = ConvLSTM2D(filters=final_profile_channels, kernel_size=(1, 5),\n",
    "                             strides=(1, 1), padding='same', activation='relu',\n",
    "                             recurrent_activation='hard_sigmoid', return_sequences=True)(profiles[i])\n",
    "    profiles[i] = Reshape(\n",
    "        (lookback, profile_length, final_profile_channels))(profiles[i])\n",
    "    # shape = (5, 32, 10)\n",
    "\n",
    "merged = [[] for i in range(num_profiles)]\n",
    "for i in range(num_profiles):\n",
    "    for j in range(num_profiles):\n",
    "        merged[i].append(Dense(units=10, activation='relu')(profiles[j]))\n",
    "    merged[i] = Add()(merged[i])\n",
    "    # shape = (5, 32, 10)\n",
    "actuator_inputs = []\n",
    "actuators = []\n",
    "for i in range(num_actuators):\n",
    "    actuator_inputs.append(\n",
    "        Input(actuator_inshape, name='input_' + actuator_names[i]))\n",
    "    actuators.append(Reshape((lookback+lookahead, 1))(actuator_inputs[i]))\n",
    "    actuators[i] = Dense(units=5, activation='relu')(actuators[i])\n",
    "    actuators[i] = Conv1D(filters=7, kernel_size=3, strides=1, padding='causal',\n",
    "                          activation='relu')(actuators[i])\n",
    "    actuators[i] = LSTM(units=10, activation='relu', recurrent_activation='hard_sigmoid',\n",
    "                        return_sequences=True)(actuators[i])\n",
    "    actuators[i] = Reshape((1, lookback+lookahead, 10))(actuators[i])\n",
    "    # shape = (1, 8, channels)\n",
    "\n",
    "actuators = Concatenate(axis=1)(actuators)\n",
    "# shape = (num_actuators, lookback+lookahead, 10)\n",
    "prof_act = []\n",
    "for i in range(num_profiles):\n",
    "    prof_act.append(Dense(units=final_profile_channels,\n",
    "                          activation='relu')(actuators))\n",
    "    prof_act[i] = Conv2D(filters=final_profile_channels,\n",
    "                         kernel_size=(num_actuators, lookahead+1), strides=(1, 1),\n",
    "                         padding='valid', activation='relu')(prof_act[i])\n",
    "    # shape = (1,5,10)\n",
    "    prof_act[i] = Reshape((lookback, final_profile_channels, 1))(prof_act[i])\n",
    "    # shape = (5,10,1)\n",
    "    prof_act[i] = Dense(units=profile_length, activation='relu')(prof_act[i])\n",
    "    # shape = (5,10,32)\n",
    "    prof_act[i] = Permute((1, 3, 2))(prof_act[i])\n",
    "    # shape = (5,32,10)\n",
    "    prof_act[i] = Dense(units=final_profile_channels,\n",
    "                        activation='relu')(prof_act[i])\n",
    "\n",
    "for i in range(num_profiles):\n",
    "    profiles[i] = Multiply()([profiles[i], prof_act[i]])\n",
    "    profiles[i] = Add()([profiles[i], merged[i]])\n",
    "    # shape = (5,32,10)\n",
    "    profiles[i] = Dense(units=15, activation='relu')(profiles[i])\n",
    "    profiles[i] = Conv2D(filters=20, kernel_size=(1, 5), strides=(1, 1), padding='same',\n",
    "                         activation='relu')(profiles[i])\n",
    "    profiles[i] = Reshape((lookback, profile_length, 1, 20))(profiles[i])\n",
    "    # shape = (5,32,1 20)\n",
    "    profiles[i] = ConvLSTM2D(filters=1, kernel_size=(1, 5),\n",
    "                             strides=(1, 1), padding='same', activation='relu',\n",
    "                             recurrent_activation='hard_sigmoid')(profiles[i])\n",
    "    #shape = (32,1,1)\n",
    "    profiles[i] = Reshape((profile_length,))(profiles[i])\n",
    "    #shape = (32,)\n",
    "    profiles[i] = Dense(units=profile_length, activation=None,\n",
    "                        name='target_' + profile_names[i])(profiles[i])\n",
    "\n",
    "model = Model(inputs=profile_inputs + actuator_inputs, outputs=profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, 'model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice:0' shape=(?, 32) dtype=float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('input_temp').input[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinge(y1, y2):\n",
    "    return np.mean(np.maximum(-(y1*y2),0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1 = np.array([-1,2,3,4])\n",
    "y2 = np.array([-5,6,7,8])\n",
    "hinge(y1,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bar', 'foo', 'foobar']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ['foo','bar','bar','foobar']\n",
    "list(np.unique(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, LSTM, Conv1D, Conv2D, ConvLSTM2D, Dot, Add, Multiply, Concatenate, Reshape, Permute, ZeroPadding1D, Cropping1D\n",
    "from keras.models import Model\n",
    "\n",
    "    \n",
    "input_profile_names = ['a', 'b', 'c']\n",
    "target_profile_names = ['a', 'b']\n",
    "actuator_names = ['aa', 'bb', 'cc']\n",
    "lookbacks = {'a': 1,\n",
    "             'b': 1,\n",
    "             'c': 1,\n",
    "             'aa': 5,\n",
    "             'bb': 5,\n",
    "             'cc': 5}\n",
    "lookahead = 4\n",
    "profile_length = 33\n",
    "std_activation = 'relu'\n",
    "\n",
    "rnn_layer = layers.LSTM\n",
    "\n",
    "profile_inshape = (lookbacks[input_profile_names[0]], profile_length)\n",
    "past_actuator_inshape = (lookbacks[actuator_names[0]],)\n",
    "future_actuator_inshape = (lookahead,)\n",
    "num_profiles = len(input_profile_names)\n",
    "num_targets = len(target_profile_names)\n",
    "num_actuators = len(actuator_names)\n",
    "\n",
    "# input each profile sig one by one and then concat them together\n",
    "profile_inputs = []\n",
    "profiles = []\n",
    "for i in range(num_profiles):\n",
    "    profile_inputs.append(\n",
    "        Input(profile_inshape, name='input_' + input_profile_names[i]))\n",
    "    profiles.append(Reshape((lookbacks[input_profile_names[i]], profile_length, 1))\n",
    "                    (profile_inputs[i]))\n",
    "current_profiles = Concatenate(axis=-1)(profiles)\n",
    "model = Model(inputs=profile_inputs, outputs=current_profiles)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers[-1].get_input_at(0)[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
