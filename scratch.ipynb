{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4f5bd6cfce37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydot'"
     ]
    }
   ],
   "source": [
    "### imports\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import pydot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# layer tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5043300182898677e-08"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### average pooling test\n",
    "\n",
    "def arravg(array,numels,offset):\n",
    "    avg=0\n",
    "    ct = 0\n",
    "    for i in range(numels):\n",
    "        if array[i*offset] > -np.inf:\n",
    "            avg += array[i*offset]\n",
    "            ct += 1\n",
    "    avg = avg/ct\n",
    "    return avg\n",
    "\n",
    "def avgpool1d(inputs,pool_size,stride,out_height,in_width):\n",
    "    k=0\n",
    "    outputs = np.zeros(out_height*in_width)\n",
    "    inputs = inputs.flatten(order='C')\n",
    "    for i in range(out_height):\n",
    "        inrowidx = k*in_width;\n",
    "        outrowidx = i*in_width;\n",
    "        for j in range(in_width):\n",
    "            outputs[outrowidx+j] = arravg(inputs[inrowidx+j:],pool_size,in_width)\n",
    "        k += stride\n",
    "    return outputs\n",
    "\n",
    "inshape = (10,10)\n",
    "pool_size=3\n",
    "stride=1\n",
    "pad = 'same'\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.AveragePooling1D(pool_size=pool_size, strides=stride, padding=pad)(a)\n",
    "model = keras.models.Model(inputs=[a], outputs=[b])\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "(in_height,in_width) = model.layers[1].input_shape[1:]\n",
    "(out_height, out_width) = model.layers[1].output_shape[1:]\n",
    "\n",
    "if pad is 'same':\n",
    "    pad_along_height = max((out_height - 1) * stride +\n",
    "                        pool_size - in_height, 0)\n",
    "    pad_top = int(pad_along_height // 2)\n",
    "    pad_bottom = int(pad_along_height - pad_top)\n",
    "elif pad is 'valid':\n",
    "    pad_top=0\n",
    "    pad_bottom=0\n",
    "padded_in_height = in_height + pad_top + pad_bottom\n",
    "\n",
    "\n",
    "y1 = np.concatenate((-np.inf*np.ones((pad_top,in_width)),x,-np.inf*np.ones((pad_bottom,in_width))),0)\n",
    "y2 = avgpool1d(y1,pool_size,stride,out_height,in_width)\n",
    "np.mean(np.abs(y.flatten(order='C')-y2.flatten(order='C')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.17117913332441e-08"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### max pooling test\n",
    "def arrmax(array,numels,offset):\n",
    "    maxval=array[0];\n",
    "    for i in range(numels):\n",
    "        if array[i*offset]>maxval:\n",
    "            maxval = array[i*offset]\n",
    "    return maxval  \n",
    "\n",
    "def maxpool1d(inputs,pool_size,stride,out_height,in_width):\n",
    "    k=0\n",
    "    outputs = np.zeros(out_height*in_width)\n",
    "    inputs = inputs.flatten(order='C')\n",
    "    for i in range(out_height):\n",
    "        inrowidx = k*in_width;\n",
    "        outrowidx = i*in_width;\n",
    "        for j in range(in_width):\n",
    "            outputs[outrowidx+j] = arrmax(inputs[inrowidx+j:],pool_size,in_width)\n",
    "        k += stride\n",
    "    return outputs\n",
    "\n",
    "inshape = (8,23)\n",
    "pool_size=2\n",
    "stride=1\n",
    "pad = 'same'\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.MaxPooling1D(pool_size=pool_size, strides=stride, padding=pad)(a)\n",
    "model = keras.models.Model(inputs=[a], outputs=[b])\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "(in_height,in_width) = model.layers[1].input_shape[1:]\n",
    "(out_height, out_width) = model.layers[1].output_shape[1:]\n",
    "\n",
    "if pad is 'same':\n",
    "    pad_along_height = max((out_height - 1) * stride +\n",
    "                        pool_size - in_height, 0)\n",
    "    pad_top = int(pad_along_height // 2)\n",
    "    pad_bottom = int(pad_along_height - pad_top)\n",
    "elif pad is 'valid':\n",
    "    pad_top=0\n",
    "    pad_bottom=0\n",
    "padded_in_height = in_height + pad_top + pad_bottom\n",
    "\n",
    "y1 = np.concatenate((-np.inf*np.ones((pad_top,in_width)),x,-np.inf*np.ones((pad_bottom,in_width))),0)\n",
    "y2 = maxpool1d(y1,pool_size,stride,out_height,in_width)\n",
    "np.mean(np.abs(y.flatten(order='C')-y2.flatten(order='C')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.858679731055338e-08\n",
      "(4, 15, 9)\n",
      "(9,)\n"
     ]
    }
   ],
   "source": [
    "### conv1d test\n",
    "\n",
    "def conv1d(x,kernel,bias,out_height,out_width,kernel_size,in_width,padded_in_height,stride,dilation):\n",
    "    x = x.flatten(order='C')\n",
    "    kernel = kernel.flatten(order='C')\n",
    "    out_size = out_height*out_width\n",
    "    output = np.zeros(out_size)\n",
    "   \n",
    "    for p in range(out_height):\n",
    "        outrowidx = p*out_width\n",
    "        for k in range(out_width):\n",
    "            for z in range(kernel_size):\n",
    "                kernelidx = z*in_width*out_width\n",
    "                for q in range(in_width):\n",
    "                    inheightidx = q*out_width\n",
    "                    output[outrowidx+k] += kernel[kernelidx+ inheightidx+ k]*x[(p*stride+ z*dilation)*in_width+q];\n",
    "            output[outrowidx+k] += bias[k]\n",
    "    \n",
    "    return output\n",
    "\n",
    "inshape = (10,15)\n",
    "pool_size=3\n",
    "stride=1\n",
    "dilation = 1\n",
    "kernel_size = 4\n",
    "num_filters = 9\n",
    "pad = 'same'\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.Conv1D(filters=num_filters, dilation_rate=dilation, kernel_size=kernel_size, strides=stride, padding=pad)(a)\n",
    "model = keras.models.Model(inputs=[a], outputs=[b])\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "(in_height,in_width) = model.layers[1].input_shape[1:]\n",
    "(out_height, out_width) = model.layers[1].output_shape[1:]\n",
    "\n",
    "if pad is 'causal':\n",
    "    pad_along_height = dilation*(kernel_size-1)\n",
    "    pad_top = pad_along_height\n",
    "    pad_bottom = 0\n",
    "elif pad is 'same':\n",
    "    pad_along_height = max((out_height - 1) * stride +\n",
    "                        kernel_size - in_height, 0)\n",
    "    pad_top = int(pad_along_height // 2)\n",
    "    pad_bottom = int(pad_along_height - pad_top)\n",
    "elif pad is 'valid':\n",
    "    pad_top=0\n",
    "    pad_bottom=0\n",
    "padded_in_height = in_height + pad_top + pad_bottom\n",
    "\n",
    "kernel = model.layers[1].get_weights()[0]\n",
    "bias = model.layers[1].get_weights()[1]\n",
    "y1 = np.concatenate((np.zeros((pad_top,in_width)),x,np.zeros((pad_bottom,in_width))),0)\n",
    "y2 = conv1d(y1,kernel,bias,out_height,out_width,kernel_size,in_width,padded_in_height,stride,dilation)\n",
    "print(np.mean(np.abs(y.flatten(order='C')-y2.flatten(order='C'))))\n",
    "print(model.layers[1].get_weights()[0].shape)\n",
    "print(model.layers[1].get_weights()[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5031581013236206e-07"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### simple RNN test\n",
    "def rnn(inputs,weights,recurrent_weights,bias):\n",
    "    state = np.zeros(bias.shape[0])\n",
    "    for i in range(inputs.shape[0]):\n",
    "        state = rnncell(inputs[i,:],state,weights,recurrent_weights,bias)\n",
    "    return state\n",
    "   \n",
    "def rnncell(inputs,state,weights,recurrent_weights,bias):\n",
    "    prev = state\n",
    "    h = inputs@weights+bias\n",
    "    output = h + prev@recurrent_weights\n",
    "    output = np.tanh(output)\n",
    "    \n",
    "    return output\n",
    "\n",
    "insize = (10,33)\n",
    "a = keras.layers.Input(insize)\n",
    "b = keras.layers.SimpleRNN(12, dropout=.5, recurrent_dropout=.5)(a)\n",
    "\n",
    "model = keras.models.Model(inputs=[a], outputs=[b])\n",
    "x = np.random.random(insize)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "model.layers[1].output_shape\n",
    "\n",
    "weights = model.layers[1].get_weights()[0]\n",
    "recurrent_weights = model.layers[1].get_weights()[1]\n",
    "bias = model.layers[1].get_weights()[2]\n",
    "a = rnn(x,weights,recurrent_weights,bias)\n",
    "np.max(np.abs(a-y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.875467575857442e-07"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRU test\n",
    "\n",
    "def gru(inputs, kernel, recurrent_kernel, input_bias, recurrent_bias, reset_after, units):\n",
    "    \n",
    "    state = np.zeros(units)\n",
    "    for i in range(inputs.shape[0]):\n",
    "        state = grucell(inputs[i,:], state, kernel, recurrent_kernel, input_bias, recurrent_bias, reset_after, units)\n",
    "    return state\n",
    "    \n",
    "\n",
    "def grucell(inputs, state, kernel, recurrent_kernel, input_bias, recurrent_bias, reset_after, units):\n",
    "    kernel_z = kernel[:, :units]\n",
    "    recurrent_kernel_z = recurrent_kernel[:, :units]\n",
    "    # reset gate\n",
    "    kernel_r = kernel[:, units: units * 2]\n",
    "    recurrent_kernel_r = recurrent_kernel[:,units:units * 2]\n",
    "    # new gate\n",
    "    kernel_h = kernel[:, units * 2:]\n",
    "    recurrent_kernel_h = recurrent_kernel[:, units * 2:]\n",
    "    \n",
    "    input_bias_z = input_bias[:units]\n",
    "    input_bias_r = input_bias[units: units * 2]\n",
    "    input_bias_h = input_bias[units * 2:]\n",
    "        \n",
    "    recurrent_bias_z = recurrent_bias[:units]\n",
    "    recurrent_bias_r = recurrent_bias[units: units * 2]\n",
    "    recurrent_bias_h = recurrent_bias[units * 2:]\n",
    "    \n",
    "    \n",
    "    x_z = inputs@kernel_z + input_bias_z\n",
    "    x_r = inputs@kernel_r + input_bias_r\n",
    "    x_h = inputs@kernel_h + input_bias_h\n",
    "    \n",
    "    h_tm1 = state\n",
    "\n",
    "            \n",
    "    recurrent_z = h_tm1@recurrent_kernel_z\n",
    "    recurrent_r = h_tm1@recurrent_kernel_r\n",
    "#     if reset_after: \n",
    "    recurrent_z = recurrent_z + recurrent_bias_z\n",
    "    recurrent_r = recurrent_r + recurrent_bias_r\n",
    "\n",
    "    z = np.tanh(x_z + recurrent_z)\n",
    "    r = np.tanh(x_r + recurrent_r)\n",
    "\n",
    "    # reset gate applied after/before matrix multiplication\n",
    "    if reset_after:\n",
    "        recurrent_h = h_tm1@recurrent_kernel_h + recurrent_bias_h\n",
    "        recurrent_h = r * recurrent_h\n",
    "    else:\n",
    "        recurrent_h = (r * h_tm1)@recurrent_kernel_h\n",
    "    hh = np.tanh(x_h + recurrent_h)\n",
    "    h = z * h_tm1 + (1 - z) * hh\n",
    "    return h\n",
    "\n",
    "reset_after = True\n",
    "units=12\n",
    "insize = (10,33)\n",
    "a = keras.layers.Input(insize)\n",
    "b = keras.layers.GRU(units, reset_after=reset_after, activation='tanh', recurrent_activation='tanh',\\\n",
    "                    bias_initializer='glorot_uniform',dropout=.76, recurrent_dropout=.25)(a)\n",
    "\n",
    "model = keras.models.Model(inputs=[a], outputs=[b])\n",
    "x = np.random.random(insize)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "kernel = model.layers[1].get_weights()[0]\n",
    "recurrent_kernel = model.layers[1].get_weights()[1]\n",
    "bias = model.layers[1].get_weights()[2]\n",
    "if reset_after:\n",
    "    input_bias = bias[0,:]\n",
    "    recurrent_bias = bias[1,:]\n",
    "else:\n",
    "    recurrent_bias = np.zeros(3*units)\n",
    "    input_bias = bias\n",
    "\n",
    "a = gru(x, kernel, recurrent_kernel, input_bias, recurrent_bias, reset_after, units)\n",
    "np.max(np.abs(a-y)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6064534425506167e-07"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### dropout test\n",
    "inshape = (10,20)\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.Dense(40, use_bias=False)(a)\n",
    "c = keras.layers.Dropout(.9)(b)\n",
    "d = keras.layers.Dense(40, use_bias=False)(c)\n",
    "model = keras.models.Model(inputs=a, outputs=d)\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "y2 = (x@model.layers[1].get_weights()[0])@model.layers[3].get_weights()[0]\n",
    "\n",
    "np.max(np.abs(y2-y)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### flatten / reshape test\n",
    "x = np.array(range(12)).reshape((3,4))\n",
    "x1 = np.reshape(x, (1, -1))\n",
    "np.max(np.abs(x1.flatten() - x.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9774109622238143e-08"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### reshape test\n",
    "inshape = (20,16)\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.Reshape((8,2,2,10))(a)\n",
    "\n",
    "model = keras.models.Model(inputs=a, outputs=b)\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "\n",
    "np.max(np.abs(x.flatten()-y.flatten()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "code_folding": [
     13,
     24
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.978759128247077e-08"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### transpose testing\n",
    "def transp(a,ndim,olddim,permute):\n",
    "    a = a.flatten()\n",
    "    b = np.zeros(a.shape)\n",
    "    oldidx2d = np.array([0,0])\n",
    "    oldidx3d = np.array([0,0,0])\n",
    "    newidx2d = np.array([0,0])\n",
    "    newidx3d = np.array([0,0,0])\n",
    "\n",
    "#    b[i,j,k] = a[i * (dim2 * dim3) + (j * dim3) + k]\n",
    "#    b[i,j] = a[i*dim2 + j]\n",
    "    if ndim==1:\n",
    "        return a # no need to transpose a 1d array\n",
    "    if ndim==2:\n",
    "        oldrows = olddim[0]\n",
    "        oldcols = olddim[1]\n",
    "        newrows = olddim[permute[0]]\n",
    "        newcols = olddim[permute[1]]\n",
    "        for i in range(oldrows):\n",
    "            for j in range(oldcols):\n",
    "                oldidx2d = [i,j]\n",
    "                newidx2d = [oldidx2d[permute[0]],oldidx2d[permute[1]]]\n",
    "                b[newidx2d[0]*newcols + newidx2d[1]] = a[oldidx2d[0]*oldcols + oldidx2d[1]]\n",
    "        return b\n",
    "    if ndim==3:\n",
    "        oldrows = olddim[0]\n",
    "        oldcols = olddim[1]\n",
    "        oldchan = olddim[2]\n",
    "        newrows = olddim[permute[0]]\n",
    "        newcols = olddim[permute[1]]\n",
    "        newchan = olddim[permute[2]]\n",
    "        for i in range(oldrows):\n",
    "            for j in range(oldcols):\n",
    "                for k in range(oldchan):\n",
    "                    oldidx3d = [i,j,k]\n",
    "                    newidx3d = [oldidx3d[permute[0]],oldidx3d[permute[1]],oldidx3d[permute[2]]]\n",
    "                    b[newidx3d[0]*newcols*newchan + newidx3d[1]*newchan + newidx3d[2]] =\\\n",
    "                        a[oldidx3d[0]*oldcols*oldchan + oldidx3d[1]*oldchan + oldidx3d[2]]\n",
    "        return b\n",
    "    if ndim==4:\n",
    "        oldrows = olddim[0]\n",
    "        oldcols = olddim[1]\n",
    "        oldchan = olddim[2]\n",
    "        oldtime = olddim[3]\n",
    "        newrows = olddim[permute[0]]\n",
    "        newcols = olddim[permute[1]]\n",
    "        newchan = olddim[permute[2]]\n",
    "        newtime = olddim[permute[3]]\n",
    "        for i in range(oldrows):\n",
    "            for j in range(oldcols):\n",
    "                for k in range(oldchan):\n",
    "                    for l in range(oldtime):\n",
    "                        oldidx4d = [i,j,k,l]\n",
    "                        newidx4d = [oldidx4d[permute[0]],oldidx4d[permute[1]],oldidx4d[permute[2]],oldidx4d[permute[3]]]\n",
    "                        b[newidx4d[0]*newcols*newchan*newtime + newidx4d[1]*newchan*newtime + newidx4d[2]*newtime + newidx4d[3]] =\\\n",
    "                            a[oldidx4d[0]*oldcols*oldchan*oldtime + oldidx4d[1]*oldchan*oldtime + oldidx4d[2]*oldtime + oldidx4d[3]]\n",
    "        return b\n",
    "\n",
    "inshape = (5,7,8,12)\n",
    "permute = np.array((3,2,1,4))\n",
    "ndim = 4\n",
    "l1 = keras.layers.Input(inshape)\n",
    "l2 = keras.layers.Permute(permute)(l1)\n",
    "model = keras.models.Model(inputs=l1, outputs=l2)\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "xt = transp(x,ndim,inshape,permute-1)\n",
    "\n",
    "np.max(np.abs(xt-y.flatten()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 10)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inshape = (4,5)\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.Dense(10)(a)\n",
    "model = keras.models.Model(inputs=a, outputs=b)\n",
    "model.layers[1].get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# misc testing and notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### indexing testing\n",
    "dim0=9\n",
    "dim1=48\n",
    "dim2=19\n",
    "b = np.random.random((dim0,dim1,dim2))\n",
    "a = b.flatten(order='C')\n",
    "idx = (7,21,5)\n",
    "b[idx] - a[idx[0] * (dim1 * dim2) + (idx[1] * dim2) + idx[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### input/output sizing with filters/padding\n",
    "#out_height = ceil(float(in_height) / float(strides[1]))\n",
    "#out_width  = ceil(float(in_width) / float(strides[2]))\n",
    "\n",
    "#pad_along_height = max((out_height - 1) * strides[1] +\n",
    "#                    filter_height - in_height, 0)\n",
    "#pad_along_width = max((out_width - 1) * strides[2] +\n",
    "#                   filter_width - in_width, 0)\n",
    "#pad_top = pad_along_height // 2\n",
    "#pad_bottom = pad_along_height - pad_top\n",
    "#pad_left = pad_along_width // 2\n",
    "#pad_right = pad_along_width - pad_left\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### pydot graph testing\n",
    "#graph = pydot.graph_from_dot_data(str())\n",
    "graph = keras.utils.vis_utils.model_to_dot(model)\n",
    "nodes = graph.get_nodes()\n",
    "edges = graph.get_edges()\n",
    "# for edge in edges:\n",
    "#     print(edge)\n",
    "# for node in nodes:\n",
    "#     print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "code_folding": [
     0,
     2,
     19,
     25,
     26,
     68,
     82
    ]
   },
   "outputs": [],
   "source": [
    "### kgraph stuff\n",
    "\n",
    "class keras_node():\n",
    "    def __init__(self, pydot_node):\n",
    "        self.pydot_node = pydot_node\n",
    "        self.ID = pydot_node.to_string().split()[0]\n",
    "        self.type = pydot_node.to_string().split()[2][:-3]\n",
    "        self.name = pydot_node.to_string().split()[1][8:-1]\n",
    "        self.inputs = []\n",
    "        self.outputs = []\n",
    "    \n",
    "    def find_layer_idx(self,model):\n",
    "        \"\"\"finds the index into model.layers corresponding to the node\"\"\"\n",
    "        for i, layer in enumerate(model.layers):\n",
    "            if layer.name == self.name:\n",
    "                self.layer_idx = i\n",
    "                return\n",
    "        self.layer_idx = None\n",
    "            \n",
    "class keras_edge():\n",
    "    def __init__(self, pydot_edge):\n",
    "        self.pydot_edge = pydot_edge\n",
    "        self.start_id = pydot_edge.to_string().split()[0]\n",
    "        self.end_id = pydot_edge.to_string().split()[2][:-1]\n",
    "\n",
    "class keras_graph():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.pydot_graph = keras.utils.vis_utils.model_to_dot(model)\n",
    "        self.edges = self.parse_edges(self.pydot_graph)\n",
    "        self.nodes = self.parse_nodes(self.pydot_graph)\n",
    "        self.input_nodes = []\n",
    "        self.output_nodes = []\n",
    "        \n",
    "    def parse_edges(self,pydot_graph):\n",
    "        \"\"\"converts pydot edges to keras_graph edges\"\"\"\n",
    "        edges = []\n",
    "        for edge in pydot_graph.get_edges():\n",
    "            edges += [keras_edge(edge)]\n",
    "        return edges\n",
    "    \n",
    "    def parse_nodes(self,pydot_graph):\n",
    "        \"\"\"converts pydot nodes to keras_graph nodes\"\"\"\n",
    "        nodes = []\n",
    "        for i, node in enumerate(pydot_graph.get_nodes()[1:]):\n",
    "            nodes += [keras_node(node)]\n",
    "            nodes[i].find_layer_idx(self.model)\n",
    "        return nodes\n",
    "    \n",
    "    def parse_connections(self):\n",
    "        for edge in self.edges:\n",
    "            self.find_node_from_id(edge.start_id).outputs += [self.find_node_from_id(edge.end_id)]\n",
    "            self.find_node_from_id(edge.end_id).inputs += [self.find_node_from_id(edge.start_id)]\n",
    "\n",
    "    def find_node_from_id(self,ID):\n",
    "        \"\"\"finds the node associated with a given ID\"\"\"\n",
    "        for node in self.nodes:\n",
    "            if node.ID == ID:\n",
    "                return node\n",
    "        return None\n",
    "    \n",
    "    def find_io_nodes(self):\n",
    "        for node in self.nodes:\n",
    "            if len(node.inputs) == 0:\n",
    "                self.input_nodes += [node]\n",
    "            if len(node.outputs) == 0:\n",
    "                self.output_nodes += [node]\n",
    "            \n",
    "def write_model(model):\n",
    "    kgraph = keras_graph(model)\n",
    "    kgraph.parse_connections()\n",
    "    kgraph.find_io_nodes()\n",
    "\n",
    "    written_nodes = []\n",
    "    unwritten_nodes = copy.deepcopy(kgraph.nodes)\n",
    "    while len(unwritten_nodes)>0:\n",
    "        for node in unwritten_nodes:\n",
    "            if set(node.inputs).issubset(written_nodes):\n",
    "                write_layer(model.layers[node.layer_idx],node)\n",
    "                written_nodes.append(node)\n",
    "                unwritten_nodes.remove(node)\n",
    "        \n",
    "def write_layer(layer,node):\n",
    "    print(layer.name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0,
     2,
     3,
     12,
     61,
     70,
     74,
     76,
     84
    ]
   },
   "outputs": [],
   "source": [
    "### check and io functions\n",
    "\n",
    "def get_all_io_names(model):\n",
    "    def flatten(x):\n",
    "        if isinstance(x, list) or isinstance(x, tuple):\n",
    "            return [a for i in x for a in flatten(i)]\n",
    "        else:\n",
    "            return [x]\n",
    "    \n",
    "    a = [get_layer_io_names(layer) for layer in model.layers]\n",
    "    return list(set(flatten(a)))\n",
    "\n",
    "def get_layer_io_names(layer):\n",
    "    inputs = []\n",
    "    num_inputs = 0\n",
    "    error = False\n",
    "    while not error:\n",
    "        try:\n",
    "            layer.get_input_at(num_inputs)\n",
    "            num_inputs +=1\n",
    "        except:\n",
    "            error = True\n",
    "    \n",
    "    outputs = []\n",
    "    num_outputs = 0\n",
    "    error = False\n",
    "    while not error:\n",
    "        try:\n",
    "            layer.get_output_at(num_outputs)\n",
    "            num_outputs +=1\n",
    "        except:\n",
    "            error = True\n",
    "    # num_inputs>1 -> shared layer\n",
    "    for i in range(num_inputs):\n",
    "        # is the input a list?\n",
    "        if isinstance(layer.get_input_at(i), list):\n",
    "            temp_list = []\n",
    "            list_length = len(layer.get_input_at(i))\n",
    "            for j in range(list_length):\n",
    "                name = str(layer.get_input_at(i)[j]).split()[0].split('\"')[1].split('/')[0].split(':')[0]\n",
    "                temp_list.append(name)\n",
    "            inputs.insert(i,temp_list)\n",
    "        else:\n",
    "            name = str(layer.get_input_at(i)).split()[0].split('\"')[1].split('/')[0].split(':')[0]\n",
    "            inputs.insert(i,name)\n",
    "            \n",
    "    for i in range(num_outputs):\n",
    "        # is the output a list?\n",
    "        if isinstance(layer.get_output_at(i), list):\n",
    "            temp_list = []\n",
    "            list_length = len(layer.get_output_at(i))\n",
    "            for j in range(list_length):\n",
    "                name = str(layer.get_output_at(i)[j]).split()[0].split('\"')[1].split('/')[0].split(':')[0]\n",
    "                temp_list.append(name)\n",
    "            outputs.insert(i,temp_list)\n",
    "        else:\n",
    "            name = str(layer.get_output_at(i)).split()[0].split('\"')[1].split('/')[0].split(':')[0]\n",
    "            outputs.insert(i,name)\n",
    "\n",
    "    return (inputs, outputs)\n",
    "\n",
    "def is_valid_c_name(name):\n",
    "    allowed_chars = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ_123456789'\n",
    "    allowed_starting_chars = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ_'\n",
    "    if not set(name).issubset(allowed_chars):\n",
    "        return False\n",
    "    if not set(name[0]).issubset(allowed_starting_chars):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def name_check(model):\n",
    "    for layer in model.layers:\n",
    "        assert (is_valid_c_name(layer.name)), \"layer name '\" + layer.name + \"' is not a valid C name\"\n",
    "\n",
    "def layer_type(layer):\n",
    "    return str(layer.__class__).split('.')[-1][0:-2]\n",
    "def layers_supported_check(model):\n",
    "    supported_layers = ['Dense','LSTM','Conv1D','InputLayer','MaxPooling1D','AveragePooling1D',\\\n",
    "                        'GlobalMaxPooling1D','GlobalAveragePooling1D','Add','Multiply','Average',\\\n",
    "                        'Maximum','Minimum','LeakyReLU','ELU','ThresholdedReLU','ReLU']\n",
    "    for layer in model.layers:\n",
    "        assert(layer_type(layer) in supported_layers), \"layer type '\" + \\\n",
    "        layer_type(layer) + \"' is not supported at this time\"\n",
    "        \n",
    "def activation_supported_check(model):\n",
    "    supported_activations = ['linear', 'relu','softmax','softplus','softsign','relu','tanh',\\\n",
    "                             'sigmoid','hard_sigmoid','exponential' ]\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        if 'activation' in layer.get_config():\n",
    "            assert(layer.get_config()['activation'] in supported_activations), \\\n",
    "            \"activation type '\" + layer.get_config()['activation'] + \"' is not supported at this time\"\n",
    "        if 'recurrent_activation' in layer.get_config():\n",
    "            assert(layer.get_config()['recurrent_activation'] in supported_activations), \\\n",
    "            \"recurrent activation type '\" + layer.get_config()['recurrent_activation'] + \"' is not supported at this time\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3\n"
     ]
    }
   ],
   "source": [
    "a = 4\n",
    "b = 3\n",
    "def foo(a,b):\n",
    "    a = a-2\n",
    "    return b\n",
    "foo(a,b)\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inshape = (3,4,6,5)\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.Dense(10)(a)\n",
    "\n",
    "model = keras.models.Model(inputs=a, outputs=b)\n",
    "model.layers[1].get_weights()[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def k2c_bias_add(A,b):\n",
    "    af = A.flatten()\n",
    "    c = np.zeros(af.size)\n",
    "    for i in range(0,af.size,b.size):\n",
    "        for j in range(b.size):\n",
    "            c[i+j] = af[i+j] + b[j]\n",
    "    return c\n",
    "A = np.random.random((4,5,6,10))\n",
    "b = np.arange(10)\n",
    "c1 = A+b\n",
    "c2 = k2c_bias_add(A,b)\n",
    "np.max(np.abs(c1.flatten()-c2.flatten()))\n",
    "#print(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 7, 8, 9)\n",
      "[8 9 5 7]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.979227065047496e-08"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def k2c_sub2idx(sub, shape, ndim):\n",
    "  #/* converts from subscript to linear indices in row major order */\n",
    "    idx = 0\n",
    "    temp = 0;\n",
    "    for i in range(ndim):\n",
    "        temp = sub[i];\n",
    "        for j in range(ndim-1,i,-1):\n",
    "            temp *= shape[j]\n",
    "        idx += temp;\n",
    "    return int(idx)\n",
    "\n",
    "def k2c_idx2sub(idx,shape,ndim):\n",
    "    sub = np.zeros(ndim)\n",
    "    a = np.flip(np.cumprod(shape))\n",
    "    for j in range(ndim-1,-1,-1):\n",
    "        sub[j] = idx % shape[j]\n",
    "        idx = idx // shape[j]\n",
    "    return tuple(sub.astype(int))\n",
    "\n",
    "def k2c_permute(a,pdims):\n",
    "    pdims = np.array(pdims).astype(int)\n",
    "    shp = a.shape\n",
    "    print(shp)\n",
    "    newshp = np.array(shp)[pdims]\n",
    "    print(newshp)\n",
    "    temp = pdims[pdims]\n",
    "    numels = a.size\n",
    "    af = a.flatten()\n",
    "    b = np.zeros(numels)\n",
    "    for i in range(numels):\n",
    "        aidx = i\n",
    "        #asub = np.unravel_index(i,shp)\n",
    "        #print(asub)\n",
    "        asub = tuple(k2c_idx2sub(i,shp,a.ndim))\n",
    "        bsub = tuple(np.array(asub)[pdims])\n",
    "        #print(bsub)\n",
    "        bidx = k2c_sub2idx(bsub,newshp,a.ndim)\n",
    "        b[bidx] = af[i]\n",
    "    return b\n",
    "\n",
    "\n",
    "inshape = (5,7,8,9)\n",
    "permute = np.array((3,4,1,2))\n",
    "ndim = 3\n",
    "l1 = keras.layers.Input(inshape)\n",
    "l2 = keras.layers.Permute(permute)(l1)\n",
    "model = keras.models.Model(inputs=l1, outputs=l2)\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "xt = k2c_permute(x,permute-1)\n",
    "\n",
    "np.max(np.abs(xt.flatten()-y.flatten()))\n",
    "\n",
    "# sub = (0,1,2,6)\n",
    "# shp = (9,4,5,7)\n",
    "# ndim = len(shp)\n",
    "\n",
    "# idx1 = np.ravel_multi_index(sub,shp)\n",
    "# idx2 = k2c_sub2idx(sub,shp,ndim)\n",
    "# sub1 = np.unravel_index(idx1,shp)\n",
    "# sub2 = k2c_idx2sub(idx1,shp,ndim)\n",
    "# print(idx1,idx2)\n",
    "# print(sub1-np.array(sub2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 7, 8, 12)\n",
      "[ 8  7  5 12]\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "shp = x.shape\n",
    "newshp = np.array(shp)[permute-1]\n",
    "print(newshp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 6 7 8 9]\n",
      "[9 7 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(5,10)\n",
    "print(a)\n",
    "b = a[np.array((4,2,0,1,3))]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5)\n",
      "5 9 5 9\n",
      "np vs k2c 2.029779810366704\n",
      "k vs np 2.029779856225161\n",
      "k vs k2c 2.3475072030709754e-07\n"
     ]
    }
   ],
   "source": [
    "inshape = (4,3,6,5)\n",
    "axes = (2,)\n",
    "flipped=False\n",
    "a = np.random.random(inshape)\n",
    "def k2c_reshape(a,axes,flipped):\n",
    "    shape_a = a.shape\n",
    "    axes = [i if i >= 0 else i + len(shape_a) for i in axes]\n",
    "    free = [i for i in range(len(shape_a)) if i not in axes]\n",
    "    free_dims = [shape_a[i] for i in free]\n",
    "    prod_free = int(np.prod([shape_a[i] for i in free]))\n",
    "    prod_axes = int(np.prod([shape_a[i] for i in axes]))\n",
    "    perm = list(axes) + free if flipped else free + list(axes)\n",
    "    new_shape = [prod_axes, prod_free] if flipped else [prod_free, prod_axes]\n",
    "    reshaped_a = np.reshape(np.transpose(a, perm), new_shape)\n",
    "    return reshaped_a, free_dims, prod_free,prod_axes\n",
    "\n",
    "def k2c_dot(a,b,a_axes,b_axes,normalize=False):\n",
    "    a_reshape, a_free_dims, free_axesA, prod_axesA = k2c_reshape(a, a_axes,False)\n",
    "    b_reshape, b_free_dims, free_axesB, prod_axesB = k2c_reshape(b, b_axes, True)\n",
    "    print(free_axesA,prod_axesA,free_axesB,prod_axesB)\n",
    "    \n",
    "#     if normalize:\n",
    "#         y = np.max(np.sum(a_reshape ** 2, a_axes, keepdims=True), a_axes, keepdims=True)\n",
    "#         print(y)\n",
    "#         print(y.shape)\n",
    "#         a_reshape = a_reshape / np.sqrt(y)\n",
    "#         y = np.max(np.sum(b_reshape ** 2, b_axes, keepdims=True), b_axes, keepdims=True)\n",
    "#         b_reshape = b_reshape / np.sqrt(y)\n",
    "#         print(y)\n",
    "#         print(y.shape)\n",
    "    if (normalize):\n",
    "        reshapeA = a_reshape.flatten()\n",
    "        reshapeB = b_reshape.flatten()\n",
    "        for i in range(free_axesA):\n",
    "            s = 0\n",
    "            for j in range(prod_axesA):\n",
    "                s += reshapeA[i*prod_axesA + j]**2\n",
    "            inorm = 1.0/np.sqrt(s);\n",
    "            for j in range(prod_axesA):\n",
    "                reshapeA[i*prod_axesA+j] *= inorm\n",
    "        for i in range(free_axesB):\n",
    "            s = 0\n",
    "            for j in range(prod_axesB):\n",
    "                s += reshapeB[i+free_axesB*j]**2\n",
    "            inorm = 1.0/np.sqrt(s);\n",
    "            for j in range(prod_axesB):\n",
    "                reshapeB[i+free_axesB*j] *= inorm \n",
    "        a_reshape = reshapeA.reshape(free_axesA,prod_axesA)\n",
    "        b_reshape = reshapeB.reshape(prod_axesB, free_axesB)\n",
    "    ab_matmul = a_reshape@b_reshape\n",
    "    return np.reshape(ab_matmul, a_free_dims + b_free_dims)\n",
    "   \n",
    "a_axes = (1,)\n",
    "b_axes = (0,)\n",
    "dotaxes = (2,1)\n",
    "inshape1 = (5,9)\n",
    "inshape2 = (9,5)\n",
    "i1 = keras.layers.Input(inshape1)\n",
    "i2 = keras.layers.Input(inshape2)\n",
    "d = keras.layers.Dot(axes=dotaxes, normalize=True)([i1,i2])\n",
    "model = keras.models.Model(inputs=[i1,i2], outputs = d)\n",
    "a = np.random.random(inshape1)\n",
    "b = np.random.random(inshape2)\n",
    "ak = a[np.newaxis,...]\n",
    "bk = b[np.newaxis,...]\n",
    "z = model.predict([ak,bk])\n",
    "x = np.tensordot(a,b,(a_axes,b_axes))\n",
    "print(x.shape)\n",
    "C = np.zeros(x.shape)\n",
    "y = k2c_dot(a,b,a_axes,b_axes,True)\n",
    "print('np vs k2c',np.max(np.abs(x-y)))\n",
    "print('k vs np', np.max(np.abs(z-x)))\n",
    "print('k vs k2c', np.max(np.abs(z-y)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(model.layers[2].get_config()['axes']) -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 10), (None, 12, 10)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### model testing\n",
    "\n",
    "inshape = (13,10)\n",
    "pool_size=3\n",
    "stride=1\n",
    "dilation=1\n",
    "num_filters=10\n",
    "kernel_size=3\n",
    "pad = 'same'\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.Dense(10)(a)\n",
    "c = keras.layers.AveragePooling1D(pool_size=pool_size, strides=stride, padding=pad)(b)\n",
    "d = keras.layers.Conv1D(filters=num_filters, kernel_size=kernel_size, strides=stride, padding=pad, dilation_rate=dilation)(c)\n",
    "e = keras.layers.Input((12,10))\n",
    "f = keras.layers.Dense(15)(e)\n",
    "g = keras.layers.LSTM(10)(f)\n",
    "h = keras.layers.add([g,e])\n",
    "model = keras.models.Model(inputs=[a,e], outputs=[h])\n",
    "\n",
    "# a = keras.layers.Input(inshape)\n",
    "# b = keras.layers.Input(inshape)\n",
    "# c = keras.layers.LSTM(20)\n",
    "# d = c(a)\n",
    "# e = c(b)\n",
    "# model = keras.models.Model(inputs=[a,b], outputs=[d,e])\n",
    "\n",
    "#print(model.layers[1].input_shape)\n",
    "#print(model.layers[1].output_shape)\n",
    "#print(model.layers[1].get_weights()[0].shape)\n",
    "#model.layers[2].get_config()\n",
    "model.layers[-1].input_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (5,4,3) (4,1,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-c37bb0e852f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (5,4,3) (4,1,1) "
     ]
    }
   ],
   "source": [
    "a = np.ones((5,4,3))\n",
    "b = np.arange((4))\n",
    "b = np.expand_dims(b,1)\n",
    "b = np.expand_dims(b,1)\n",
    "\n",
    "print(b.shape)\n",
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(None, 5, 4, 1), (None, 5, 4, 2)}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape1 = (None,5,4,2)\n",
    "shape2 = (None,5,4,1)\n",
    "output_shape = list(shape1[:-len(shape2)])\n",
    "for i, j in zip(shape1[-len(shape2):], shape2):\n",
    "    if i is None or j is None:\n",
    "        output_shape.append(None)\n",
    "    elif i == 1:\n",
    "        output_shape.append(j)\n",
    "    elif j == 1:\n",
    "        output_shape.append(i)\n",
    "    else:\n",
    "        if i != j:\n",
    "            raise ValueError('Operands could not be broadcast '\n",
    "                             'together with shapes ' +\n",
    "                             str(shape1) + ' ' + str(shape2))\n",
    "        output_shape.append(i)\n",
    "set([shape1,shape2]) # check if all inputs are the same shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "inshape = (8,32)\n",
    "init1 = keras.initializers.Constant(.04)\n",
    "init2 = keras.initializers.Identity()\n",
    "af = keras.layers.Input(inshape)\n",
    "bf = keras.layers.LSTM(5, return_sequences=True, return_state=True, kernel_initializer=init1, recurrent_initializer=init2)(af)\n",
    "fwmodel = keras.models.Model(inputs=af, outputs=bf)\n",
    "\n",
    "ab = keras.layers.Input(inshape)\n",
    "bb = keras.layers.LSTM(5, return_sequences=True, go_backwards=True, kernel_initializer=init1, recurrent_initializer=init2)(ab)\n",
    "cb = keras.layers.Dense(10)(bb)\n",
    "bwmodel = keras.models.Model(inputs=ab, outputs=cb)\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x= x[np.newaxis,...]\n",
    "yfw = fwmodel.predict(x)\n",
    "ybw = bwmodel.predict(x)\n",
    "xf = np.flip(x,axis=1)\n",
    "yffw = fwmodel.predict(xf)\n",
    "yfbw = bwmodel.predict(xf)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 10)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bwmodel.layers\n",
    "bwmodel.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.117249266665794e-08"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inshape = (7,4,3)\n",
    "init = keras.initializers.RandomUniform(minval= 0.0, maxval=1.0)\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.BatchNormalization(axis=-1, center=True, scale=True, beta_initializer=init, gamma_initializer=init,  moving_variance_initializer=init, moving_mean_initializer=init)(a)\n",
    "model = keras.models.Model(inputs=a, outputs=b)\n",
    "epsilon = .001\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y1 = model.predict(x1)\n",
    "\n",
    "gamma = model.layers[1].get_weights()[0]\n",
    "beta = model.layers[1].get_weights()[1]\n",
    "mean = model.layers[1].get_weights()[2] # index 0 if no center/scale\n",
    "variance = model.layers[1].get_weights()[3] # index 1 if no center/scale\n",
    "\n",
    "y = (x - mean) / np.sqrt(variance + epsilon) * gamma + beta\n",
    "np.max(np.abs(y-y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'batch_normalization_v1_21',\n",
       " 'trainable': True,\n",
       " 'dtype': 'float32',\n",
       " 'axis': [3],\n",
       " 'momentum': 0.99,\n",
       " 'epsilon': 0.001,\n",
       " 'center': True,\n",
       " 'scale': True,\n",
       " 'beta_initializer': {'class_name': 'RandomUniform',\n",
       "  'config': {'minval': -0.05,\n",
       "   'maxval': 0.05,\n",
       "   'seed': None,\n",
       "   'dtype': 'float32'}},\n",
       " 'gamma_initializer': {'class_name': 'RandomUniform',\n",
       "  'config': {'minval': -0.05,\n",
       "   'maxval': 0.05,\n",
       "   'seed': None,\n",
       "   'dtype': 'float32'}},\n",
       " 'moving_mean_initializer': {'class_name': 'RandomUniform',\n",
       "  'config': {'minval': -0.05,\n",
       "   'maxval': 0.05,\n",
       "   'seed': None,\n",
       "   'dtype': 'float32'}},\n",
       " 'moving_variance_initializer': {'class_name': 'RandomUniform',\n",
       "  'config': {'minval': -0.05,\n",
       "   'maxval': 0.05,\n",
       "   'seed': None,\n",
       "   'dtype': 'float32'}},\n",
       " 'beta_regularizer': None,\n",
       " 'gamma_regularizer': None,\n",
       " 'beta_constraint': None,\n",
       " 'gamma_constraint': None}"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 1 2 3 4 5 6 0 1 2 3 4 5 6]\n",
      "  [0 1 2 3 4 5 6 0 1 2 3 4 5 6]\n",
      "  [0 1 2 3 4 5 6 0 1 2 3 4 5 6]\n",
      "  [0 1 2 3 4 5 6 0 1 2 3 4 5 6]]\n",
      "\n",
      " [[0 1 2 3 4 5 6 0 1 2 3 4 5 6]\n",
      "  [0 1 2 3 4 5 6 0 1 2 3 4 5 6]\n",
      "  [0 1 2 3 4 5 6 0 1 2 3 4 5 6]\n",
      "  [0 1 2 3 4 5 6 0 1 2 3 4 5 6]]\n",
      "\n",
      " [[0 1 2 3 4 5 6 0 1 2 3 4 5 6]\n",
      "  [0 1 2 3 4 5 6 0 1 2 3 4 5 6]\n",
      "  [0 1 2 3 4 5 6 0 1 2 3 4 5 6]\n",
      "  [0 1 2 3 4 5 6 0 1 2 3 4 5 6]]]\n",
      "[[[  0   3  12  27  48  75 108   0   3  12  27  48  75 108]\n",
      "  [  0   3  12  27  48  75 108   0   3  12  27  48  75 108]\n",
      "  [  0   3  12  27  48  75 108   0   3  12  27  48  75 108]\n",
      "  [  0   3  12  27  48  75 108   0   3  12  27  48  75 108]]]\n",
      "[[[  0   3  12  27  48  75 108   0   3  12  27  48  75 108]\n",
      "  [  0   3  12  27  48  75 108   0   3  12  27  48  75 108]\n",
      "  [  0   3  12  27  48  75 108   0   3  12  27  48  75 108]\n",
      "  [  0   3  12  27  48  75 108   0   3  12  27  48  75 108]]]\n"
     ]
    }
   ],
   "source": [
    " x = np.tile(np.arange(7),(3,4,2))\n",
    "print(x)\n",
    "axis=(0) \n",
    "z = np.sum(x ** 2, axis, keepdims=True)\n",
    "print(z)\n",
    "y = np.max(z, axis, keepdims=True)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
