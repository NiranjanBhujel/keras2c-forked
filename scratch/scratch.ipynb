{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "### imports\n",
    "import numpy as np\n",
    "#import tensorflow.keras as keras\n",
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "layers:  concatentate\n",
    "         bidirectional rnn\n",
    "         merge with different sizes\n",
    "         conv2d\n",
    "         pool2d \n",
    "         conv3d\n",
    "         pool3d\n",
    "         global pool 2d\n",
    "         global pool 3d\n",
    "         seperable conv\n",
    "         conv transpose\n",
    "         depthwise conv\n",
    "         crop1d\n",
    "         crop2d\n",
    "         crop3d\n",
    "         pad1d\n",
    "         pad2d\n",
    "         pad3d\n",
    "         upsampling1d\n",
    "         upsampling2d\n",
    "         upsampling3d\n",
    "         locally connected 1d\n",
    "         locally connected 2d\n",
    "         time distributed\n",
    " \n",
    " static or const?\n",
    " broadcasting sizes for merge layers\n",
    " find the common dimension and add them that way?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# layer tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0694171458668366e-08"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### average pooling 1d test\n",
    "\n",
    "def arravg(array,numels,offset):\n",
    "    avg=0\n",
    "    ct = 0\n",
    "    for i in range(numels):\n",
    "        if array[i*offset] > -np.inf:\n",
    "            avg += array[i*offset]\n",
    "            ct += 1\n",
    "    avg = avg/ct\n",
    "    return avg\n",
    "\n",
    "def avgpool1d(inputs,pool_size,stride,out_height,in_width):\n",
    "    k=0\n",
    "    outputs = np.zeros(out_height*in_width)\n",
    "    inputs = inputs.flatten(order='C')\n",
    "    for i in range(out_height):\n",
    "        inrowidx = k*in_width;\n",
    "        outrowidx = i*in_width;\n",
    "        for j in range(in_width):\n",
    "            outputs[outrowidx+j] = arravg(inputs[inrowidx+j:],pool_size,in_width)\n",
    "        k += stride\n",
    "    return outputs\n",
    "\n",
    "inshape = (10,10)\n",
    "pool_size=3\n",
    "stride=1\n",
    "pad = 'same'\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.AveragePooling1D(pool_size=pool_size, strides=stride, padding=pad)(a)\n",
    "model = keras.models.Model(inputs=[a], outputs=[b])\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "(in_height,in_width) = model.layers[1].input_shape[1:]\n",
    "(out_height, out_width) = model.layers[1].output_shape[1:]\n",
    "\n",
    "if pad is 'same':\n",
    "    pad_along_height = max((out_height - 1) * stride +\n",
    "                        pool_size - in_height, 0)\n",
    "    pad_top = int(pad_along_height // 2)\n",
    "    pad_bottom = int(pad_along_height - pad_top)\n",
    "elif pad is 'valid':\n",
    "    pad_top=0\n",
    "    pad_bottom=0\n",
    "padded_in_height = in_height + pad_top + pad_bottom\n",
    "\n",
    "\n",
    "y1 = np.concatenate((-np.inf*np.ones((pad_top,in_width)),x,-np.inf*np.ones((pad_bottom,in_width))),0)\n",
    "y2 = avgpool1d(y1,pool_size,stride,out_height,in_width)\n",
    "np.mean(np.abs(y.flatten(order='C')-y2.flatten(order='C')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1858545135591115e-08"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### max pooling 1d test\n",
    "def arrmax(array,numels,offset):\n",
    "    maxval=array[0];\n",
    "    for i in range(numels):\n",
    "        if array[i*offset]>maxval:\n",
    "            maxval = array[i*offset]\n",
    "    return maxval  \n",
    "\n",
    "def maxpool1d(inputs,pool_size,stride,out_height,in_width):\n",
    "    k=0\n",
    "    outputs = np.zeros(out_height*in_width)\n",
    "    inputs = inputs.flatten(order='C')\n",
    "    for i in range(out_height):\n",
    "        inrowidx = k*in_width;\n",
    "        outrowidx = i*in_width;\n",
    "        for j in range(in_width):\n",
    "            outputs[outrowidx+j] = arrmax(inputs[inrowidx+j:],pool_size,in_width)\n",
    "        k += stride\n",
    "    return outputs\n",
    "\n",
    "inshape = (8,23)\n",
    "pool_size=2\n",
    "stride=1\n",
    "pad = 'same'\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.MaxPooling1D(pool_size=pool_size, strides=stride, padding=pad)(a)\n",
    "model = keras.models.Model(inputs=[a], outputs=[b])\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "(in_height,in_width) = model.layers[1].input_shape[1:]\n",
    "(out_height, out_width) = model.layers[1].output_shape[1:]\n",
    "\n",
    "if pad is 'same':\n",
    "    pad_along_height = max((out_height - 1) * stride +\n",
    "                        pool_size - in_height, 0)\n",
    "    pad_top = int(pad_along_height // 2)\n",
    "    pad_bottom = int(pad_along_height - pad_top)\n",
    "elif pad is 'valid':\n",
    "    pad_top=0\n",
    "    pad_bottom=0\n",
    "padded_in_height = in_height + pad_top + pad_bottom\n",
    "\n",
    "y1 = np.concatenate((-np.inf*np.ones((pad_top,in_width)),x,-np.inf*np.ones((pad_bottom,in_width))),0)\n",
    "y2 = maxpool1d(y1,pool_size,stride,out_height,in_width)\n",
    "np.mean(np.abs(y.flatten(order='C')-y2.flatten(order='C')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fouriest/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "6.154065818762976e-08\n",
      "(4, 15, 9)\n",
      "(9,)\n"
     ]
    }
   ],
   "source": [
    "### conv1d test\n",
    "\n",
    "def conv1d(x,kernel,bias,out_height,out_width,kernel_size,in_width,padded_in_height,stride,dilation):\n",
    "    x = x.flatten(order='C')\n",
    "    kernel = kernel.flatten(order='C')\n",
    "    out_size = out_height*out_width\n",
    "    output = np.zeros(out_size)\n",
    "   \n",
    "    for p in range(out_height):\n",
    "        outrowidx = p*out_width\n",
    "        for k in range(out_width):\n",
    "            for z in range(kernel_size):\n",
    "                kernelidx = z*in_width*out_width\n",
    "                for q in range(in_width):\n",
    "                    inheightidx = q*out_width\n",
    "                    output[outrowidx+k] += kernel[kernelidx+ inheightidx+ k]*x[(p*stride+ z*dilation)*in_width+q];\n",
    "            output[outrowidx+k] += bias[k]\n",
    "    \n",
    "    return output\n",
    "\n",
    "inshape = (10,15)\n",
    "pool_size=3\n",
    "stride=1\n",
    "dilation = 1\n",
    "kernel_size = 4\n",
    "num_filters = 9\n",
    "pad = 'same'\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.Conv1D(filters=num_filters, dilation_rate=dilation, kernel_size=kernel_size, strides=stride, padding=pad)(a)\n",
    "model = keras.models.Model(inputs=[a], outputs=[b])\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "(in_height,in_width) = model.layers[1].input_shape[1:]\n",
    "(out_height, out_width) = model.layers[1].output_shape[1:]\n",
    "\n",
    "if pad is 'causal':\n",
    "    pad_along_height = dilation*(kernel_size-1)\n",
    "    pad_top = pad_along_height\n",
    "    pad_bottom = 0\n",
    "elif pad is 'same':\n",
    "    pad_along_height = max((out_height - 1) * stride +\n",
    "                        kernel_size - in_height, 0)\n",
    "    pad_top = int(pad_along_height // 2)\n",
    "    pad_bottom = int(pad_along_height - pad_top)\n",
    "elif pad is 'valid':\n",
    "    pad_top=0\n",
    "    pad_bottom=0\n",
    "padded_in_height = in_height + pad_top + pad_bottom\n",
    "\n",
    "kernel = model.layers[1].get_weights()[0]\n",
    "bias = model.layers[1].get_weights()[1]\n",
    "y1 = np.concatenate((np.zeros((pad_top,in_width)),x,np.zeros((pad_bottom,in_width))),0)\n",
    "y2 = conv1d(y1,kernel,bias,out_height,out_width,kernel_size,in_width,padded_in_height,stride,dilation)\n",
    "print(np.mean(np.abs(y.flatten(order='C')-y2.flatten(order='C'))))\n",
    "print(model.layers[1].get_weights()[0].shape)\n",
    "print(model.layers[1].get_weights()[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fouriest/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.3231411758195541e-07"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### simple RNN test\n",
    "def rnn(inputs,weights,recurrent_weights,bias):\n",
    "    state = np.zeros(bias.shape[0])\n",
    "    for i in range(inputs.shape[0]):\n",
    "        state = rnncell(inputs[i,:],state,weights,recurrent_weights,bias)\n",
    "    return state\n",
    "   \n",
    "def rnncell(inputs,state,weights,recurrent_weights,bias):\n",
    "    prev = state\n",
    "    h = inputs@weights+bias\n",
    "    output = h + prev@recurrent_weights\n",
    "    output = np.tanh(output)\n",
    "    \n",
    "    return output\n",
    "\n",
    "insize = (10,33)\n",
    "a = keras.layers.Input(insize)\n",
    "b = keras.layers.SimpleRNN(12, dropout=.5, recurrent_dropout=.5)(a)\n",
    "\n",
    "model = keras.models.Model(inputs=[a], outputs=[b])\n",
    "x = np.random.random(insize)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "model.layers[1].output_shape\n",
    "\n",
    "weights = model.layers[1].get_weights()[0]\n",
    "recurrent_weights = model.layers[1].get_weights()[1]\n",
    "bias = model.layers[1].get_weights()[2]\n",
    "a = rnn(x,weights,recurrent_weights,bias)\n",
    "np.max(np.abs(a-y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2177304026825837e-07"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRU test\n",
    "\n",
    "def gru(inputs, kernel, recurrent_kernel, input_bias, recurrent_bias, reset_after, units, go_backwards, return_sequences):\n",
    "    inp = inputs.flatten()\n",
    "    state = np.zeros(units)\n",
    "    output = np.zeros((inputs.shape[0]*units))\n",
    "    if go_backwards:\n",
    "        for i in range(inputs.shape[0]-1,-1,-1):\n",
    "            state = grucell(inp[i*inputs.shape[1]:(i+1)*inputs.shape[1]], state, kernel, recurrent_kernel, input_bias, recurrent_bias, reset_after, units)\n",
    "            if return_sequences:\n",
    "                for j in range(units):\n",
    "                    output[(inputs.shape[0]-1-i)*units+j] = state.flatten()[j]\n",
    "                \n",
    "    else:\n",
    "        for i in range(inputs.shape[0]):\n",
    "            state = grucell(inp[i*inputs.shape[1]:(i+1)*inputs.shape[1]], state, kernel, recurrent_kernel, input_bias, recurrent_bias, reset_after, units)\n",
    "            if return_sequences:\n",
    "                for j in range(units):\n",
    "                    output[i*units+j] = state.flatten()[j]\n",
    "    if return_sequences:\n",
    "        return output\n",
    "    else:\n",
    "        return output\n",
    "    \n",
    "\n",
    "def grucell(inputs, state, kernel, recurrent_kernel, input_bias, recurrent_bias, reset_after, units):\n",
    "    kernel_z = kernel[:, :units]\n",
    "    recurrent_kernel_z = recurrent_kernel[:, :units]\n",
    "    # reset gate\n",
    "    kernel_r = kernel[:, units: units * 2]\n",
    "    recurrent_kernel_r = recurrent_kernel[:,units:units * 2]\n",
    "    # new gate\n",
    "    kernel_h = kernel[:, units * 2:]\n",
    "    recurrent_kernel_h = recurrent_kernel[:, units * 2:]\n",
    "    \n",
    "    input_bias_z = input_bias[:units]\n",
    "    input_bias_r = input_bias[units: units * 2]\n",
    "    input_bias_h = input_bias[units * 2:]\n",
    "        \n",
    "    recurrent_bias_z = recurrent_bias[:units]\n",
    "    recurrent_bias_r = recurrent_bias[units: units * 2]\n",
    "    recurrent_bias_h = recurrent_bias[units * 2:]\n",
    "    \n",
    "    \n",
    "    x_z = inputs@kernel_z + input_bias_z\n",
    "    x_r = inputs@kernel_r + input_bias_r\n",
    "    x_h = inputs@kernel_h + input_bias_h\n",
    "    \n",
    "    h_tm1 = state\n",
    "\n",
    "            \n",
    "    recurrent_z = h_tm1@recurrent_kernel_z\n",
    "    recurrent_r = h_tm1@recurrent_kernel_r\n",
    "    recurrent_z = recurrent_z + recurrent_bias_z\n",
    "    recurrent_r = recurrent_r + recurrent_bias_r\n",
    "\n",
    "    recurrent_z = np.tanh(x_z + recurrent_z)\n",
    "    recurrent_r = np.tanh(x_r + recurrent_r)\n",
    "\n",
    "    # reset gate applied after/before matrix multiplication\n",
    "    if reset_after:\n",
    "        recurrent_h = h_tm1@recurrent_kernel_h + recurrent_bias_h\n",
    "        recurrent_h = recurrent_r * recurrent_h\n",
    "    else:\n",
    "        recurrent_h = (recurrent_r * h_tm1)@recurrent_kernel_h\n",
    "    hh = np.tanh(x_h + recurrent_h)\n",
    "    h = recurrent_z * h_tm1 + (1 - recurrent_z) * hh\n",
    "    return h\n",
    "\n",
    "reset_after = True\n",
    "go_backwards = True\n",
    "return_sequences = True\n",
    "units=12\n",
    "insize = (10,33)\n",
    "a = keras.layers.Input(insize)\n",
    "b = keras.layers.GRU(units, reset_after=reset_after, activation='tanh', recurrent_activation='tanh',\\\n",
    "                    bias_initializer='zeros', go_backwards=go_backwards, return_sequences=return_sequences)(a)\n",
    "\n",
    "model = keras.models.Model(inputs=[a], outputs=[b])\n",
    "x = np.random.random(insize)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "kernel = model.layers[1].get_weights()[0]\n",
    "recurrent_kernel = model.layers[1].get_weights()[1]\n",
    "bias = model.layers[1].get_weights()[2]\n",
    "if reset_after:\n",
    "    input_bias = bias[0,:]\n",
    "    recurrent_bias = bias[1,:]\n",
    "else:\n",
    "    recurrent_bias = np.zeros(3*units)\n",
    "    input_bias = bias\n",
    "\n",
    "y2 = gru(x, kernel, recurrent_kernel, input_bias, recurrent_bias, reset_after, units, go_backwards, return_sequences)\n",
    "np.max(np.abs(y2.flatten()-y.flatten())) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0230503772775705e-07"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### dropout test\n",
    "inshape = (10,20)\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.Dense(40, use_bias=False)(a)\n",
    "c = keras.layers.Dropout(.9)(b)\n",
    "d = keras.layers.Dense(40, use_bias=False)(c)\n",
    "model = keras.models.Model(inputs=a, outputs=d)\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "y2 = (x@model.layers[1].get_weights()[0])@model.layers[3].get_weights()[0]\n",
    "\n",
    "np.max(np.abs(y2-y)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### flatten / reshape test\n",
    "x = np.array(range(12)).reshape((3,4))\n",
    "x1 = np.reshape(x, (1, -1))\n",
    "np.max(np.abs(x1.flatten() - x.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.94372511921992e-08"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### reshape test\n",
    "inshape = (20,16)\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.Reshape((8,2,2,10))(a)\n",
    "\n",
    "model = keras.models.Model(inputs=a, outputs=b)\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "\n",
    "np.max(np.abs(x.flatten()-y.flatten()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     13,
     24
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9796300538009746e-08"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### transpose testing\n",
    "def transp(a,ndim,olddim,permute):\n",
    "    a = a.flatten()\n",
    "    b = np.zeros(a.shape)\n",
    "    oldidx2d = np.array([0,0])\n",
    "    oldidx3d = np.array([0,0,0])\n",
    "    newidx2d = np.array([0,0])\n",
    "    newidx3d = np.array([0,0,0])\n",
    "\n",
    "#    b[i,j,k] = a[i * (dim2 * dim3) + (j * dim3) + k]\n",
    "#    b[i,j] = a[i*dim2 + j]\n",
    "    if ndim==1:\n",
    "        return a # no need to transpose a 1d array\n",
    "    if ndim==2:\n",
    "        oldrows = olddim[0]\n",
    "        oldcols = olddim[1]\n",
    "        newrows = olddim[permute[0]]\n",
    "        newcols = olddim[permute[1]]\n",
    "        for i in range(oldrows):\n",
    "            for j in range(oldcols):\n",
    "                oldidx2d = [i,j]\n",
    "                newidx2d = [oldidx2d[permute[0]],oldidx2d[permute[1]]]\n",
    "                b[newidx2d[0]*newcols + newidx2d[1]] = a[oldidx2d[0]*oldcols + oldidx2d[1]]\n",
    "        return b\n",
    "    if ndim==3:\n",
    "        oldrows = olddim[0]\n",
    "        oldcols = olddim[1]\n",
    "        oldchan = olddim[2]\n",
    "        newrows = olddim[permute[0]]\n",
    "        newcols = olddim[permute[1]]\n",
    "        newchan = olddim[permute[2]]\n",
    "        for i in range(oldrows):\n",
    "            for j in range(oldcols):\n",
    "                for k in range(oldchan):\n",
    "                    oldidx3d = [i,j,k]\n",
    "                    newidx3d = [oldidx3d[permute[0]],oldidx3d[permute[1]],oldidx3d[permute[2]]]\n",
    "                    b[newidx3d[0]*newcols*newchan + newidx3d[1]*newchan + newidx3d[2]] =\\\n",
    "                        a[oldidx3d[0]*oldcols*oldchan + oldidx3d[1]*oldchan + oldidx3d[2]]\n",
    "        return b\n",
    "    if ndim==4:\n",
    "        oldrows = olddim[0]\n",
    "        oldcols = olddim[1]\n",
    "        oldchan = olddim[2]\n",
    "        oldtime = olddim[3]\n",
    "        newrows = olddim[permute[0]]\n",
    "        newcols = olddim[permute[1]]\n",
    "        newchan = olddim[permute[2]]\n",
    "        newtime = olddim[permute[3]]\n",
    "        for i in range(oldrows):\n",
    "            for j in range(oldcols):\n",
    "                for k in range(oldchan):\n",
    "                    for l in range(oldtime):\n",
    "                        oldidx4d = [i,j,k,l]\n",
    "                        newidx4d = [oldidx4d[permute[0]],oldidx4d[permute[1]],oldidx4d[permute[2]],oldidx4d[permute[3]]]\n",
    "                        b[newidx4d[0]*newcols*newchan*newtime + newidx4d[1]*newchan*newtime + newidx4d[2]*newtime + newidx4d[3]] =\\\n",
    "                            a[oldidx4d[0]*oldcols*oldchan*oldtime + oldidx4d[1]*oldchan*oldtime + oldidx4d[2]*oldtime + oldidx4d[3]]\n",
    "        return b\n",
    "\n",
    "inshape = (5,7,8,12)\n",
    "permute = np.array((3,2,1,4))\n",
    "ndim = 4\n",
    "l1 = keras.layers.Input(inshape)\n",
    "l2 = keras.layers.Permute(permute)(l1)\n",
    "model = keras.models.Model(inputs=l1, outputs=l2)\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "xt = transp(x,ndim,inshape,permute-1)\n",
    "\n",
    "np.max(np.abs(xt-y.flatten()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inshape = (4,5)\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.Dense(10)(a)\n",
    "model = keras.models.Model(inputs=a, outputs=b)\n",
    "model.layers[1].get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# misc testing and notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### indexing testing\n",
    "dim0=9\n",
    "dim1=48\n",
    "dim2=19\n",
    "b = np.random.random((dim0,dim1,dim2))\n",
    "a = b.flatten(order='C')\n",
    "idx = (7,21,5)\n",
    "b[idx] - a[idx[0] * (dim1 * dim2) + (idx[1] * dim2) + idx[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### input/output sizing with filters/padding\n",
    "#out_height = ceil(float(in_height) / float(strides[1]))\n",
    "#out_width  = ceil(float(in_width) / float(strides[2]))\n",
    "\n",
    "#pad_along_height = max((out_height - 1) * strides[1] +\n",
    "#                    filter_height - in_height, 0)\n",
    "#pad_along_width = max((out_width - 1) * strides[2] +\n",
    "#                   filter_width - in_width, 0)\n",
    "#pad_top = pad_along_height // 2\n",
    "#pad_bottom = pad_along_height - pad_top\n",
    "#pad_left = pad_along_width // 2\n",
    "#pad_right = pad_along_width - pad_left\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7e0d44d3e65b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### pydot graph testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#graph = pydot.graph_from_dot_data(str())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvis_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0medges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rankdir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpydot\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         raise ImportError(\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;34m'Failed to import `pydot`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;34m'Please install `pydot`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             'For example with `pip install pydot`.')\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`."
     ]
    }
   ],
   "source": [
    "### pydot graph testing\n",
    "#graph = pydot.graph_from_dot_data(str())\n",
    "graph = keras.utils.vis_utils.model_to_dot(model)\n",
    "nodes = graph.get_nodes()\n",
    "edges = graph.get_edges()\n",
    "# for edge in edges:\n",
    "#     print(edge)\n",
    "# for node in nodes:\n",
    "#     print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     0,
     2,
     19,
     25,
     26,
     68,
     82
    ]
   },
   "outputs": [],
   "source": [
    "### kgraph stuff\n",
    "\n",
    "class keras_node():\n",
    "    def __init__(self, pydot_node):\n",
    "        self.pydot_node = pydot_node\n",
    "        self.ID = pydot_node.to_string().split()[0]\n",
    "        self.type = pydot_node.to_string().split()[2][:-3]\n",
    "        self.name = pydot_node.to_string().split()[1][8:-1]\n",
    "        self.inputs = []\n",
    "        self.outputs = []\n",
    "    \n",
    "    def find_layer_idx(self,model):\n",
    "        \"\"\"finds the index into model.layers corresponding to the node\"\"\"\n",
    "        for i, layer in enumerate(model.layers):\n",
    "            if layer.name == self.name:\n",
    "                self.layer_idx = i\n",
    "                return\n",
    "        self.layer_idx = None\n",
    "            \n",
    "class keras_edge():\n",
    "    def __init__(self, pydot_edge):\n",
    "        self.pydot_edge = pydot_edge\n",
    "        self.start_id = pydot_edge.to_string().split()[0]\n",
    "        self.end_id = pydot_edge.to_string().split()[2][:-1]\n",
    "\n",
    "class keras_graph():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.pydot_graph = keras.utils.vis_utils.model_to_dot(model)\n",
    "        self.edges = self.parse_edges(self.pydot_graph)\n",
    "        self.nodes = self.parse_nodes(self.pydot_graph)\n",
    "        self.input_nodes = []\n",
    "        self.output_nodes = []\n",
    "        \n",
    "    def parse_edges(self,pydot_graph):\n",
    "        \"\"\"converts pydot edges to keras_graph edges\"\"\"\n",
    "        edges = []\n",
    "        for edge in pydot_graph.get_edges():\n",
    "            edges += [keras_edge(edge)]\n",
    "        return edges\n",
    "    \n",
    "    def parse_nodes(self,pydot_graph):\n",
    "        \"\"\"converts pydot nodes to keras_graph nodes\"\"\"\n",
    "        nodes = []\n",
    "        for i, node in enumerate(pydot_graph.get_nodes()[1:]):\n",
    "            nodes += [keras_node(node)]\n",
    "            nodes[i].find_layer_idx(self.model)\n",
    "        return nodes\n",
    "    \n",
    "    def parse_connections(self):\n",
    "        for edge in self.edges:\n",
    "            self.find_node_from_id(edge.start_id).outputs += [self.find_node_from_id(edge.end_id)]\n",
    "            self.find_node_from_id(edge.end_id).inputs += [self.find_node_from_id(edge.start_id)]\n",
    "\n",
    "    def find_node_from_id(self,ID):\n",
    "        \"\"\"finds the node associated with a given ID\"\"\"\n",
    "        for node in self.nodes:\n",
    "            if node.ID == ID:\n",
    "                return node\n",
    "        return None\n",
    "    \n",
    "    def find_io_nodes(self):\n",
    "        for node in self.nodes:\n",
    "            if len(node.inputs) == 0:\n",
    "                self.input_nodes += [node]\n",
    "            if len(node.outputs) == 0:\n",
    "                self.output_nodes += [node]\n",
    "            \n",
    "def write_model(model):\n",
    "    kgraph = keras_graph(model)\n",
    "    kgraph.parse_connections()\n",
    "    kgraph.find_io_nodes()\n",
    "\n",
    "    written_nodes = []\n",
    "    unwritten_nodes = copy.deepcopy(kgraph.nodes)\n",
    "    while len(unwritten_nodes)>0:\n",
    "        for node in unwritten_nodes:\n",
    "            if set(node.inputs).issubset(written_nodes):\n",
    "                write_layer(model.layers[node.layer_idx],node)\n",
    "                written_nodes.append(node)\n",
    "                unwritten_nodes.remove(node)\n",
    "        \n",
    "def write_layer(layer,node):\n",
    "    print(layer.name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0,
     2,
     3,
     12,
     61,
     70,
     74,
     76,
     84
    ]
   },
   "outputs": [],
   "source": [
    "### check and io functions\n",
    "\n",
    "def get_all_io_names(model):\n",
    "    def flatten(x):\n",
    "        if isinstance(x, list) or isinstance(x, tuple):\n",
    "            return [a for i in x for a in flatten(i)]\n",
    "        else:\n",
    "            return [x]\n",
    "    \n",
    "    a = [get_layer_io_names(layer) for layer in model.layers]\n",
    "    return list(set(flatten(a)))\n",
    "\n",
    "def get_layer_io_names(layer):\n",
    "    inputs = []\n",
    "    num_inputs = 0\n",
    "    error = False\n",
    "    while not error:\n",
    "        try:\n",
    "            layer.get_input_at(num_inputs)\n",
    "            num_inputs +=1\n",
    "        except:\n",
    "            error = True\n",
    "    \n",
    "    outputs = []\n",
    "    num_outputs = 0\n",
    "    error = False\n",
    "    while not error:\n",
    "        try:\n",
    "            layer.get_output_at(num_outputs)\n",
    "            num_outputs +=1\n",
    "        except:\n",
    "            error = True\n",
    "    # num_inputs>1 -> shared layer\n",
    "    for i in range(num_inputs):\n",
    "        # is the input a list?\n",
    "        if isinstance(layer.get_input_at(i), list):\n",
    "            temp_list = []\n",
    "            list_length = len(layer.get_input_at(i))\n",
    "            for j in range(list_length):\n",
    "                name = str(layer.get_input_at(i)[j]).split()[0].split('\"')[1].split('/')[0].split(':')[0]\n",
    "                temp_list.append(name)\n",
    "            inputs.insert(i,temp_list)\n",
    "        else:\n",
    "            name = str(layer.get_input_at(i)).split()[0].split('\"')[1].split('/')[0].split(':')[0]\n",
    "            inputs.insert(i,name)\n",
    "            \n",
    "    for i in range(num_outputs):\n",
    "        # is the output a list?\n",
    "        if isinstance(layer.get_output_at(i), list):\n",
    "            temp_list = []\n",
    "            list_length = len(layer.get_output_at(i))\n",
    "            for j in range(list_length):\n",
    "                name = str(layer.get_output_at(i)[j]).split()[0].split('\"')[1].split('/')[0].split(':')[0]\n",
    "                temp_list.append(name)\n",
    "            outputs.insert(i,temp_list)\n",
    "        else:\n",
    "            name = str(layer.get_output_at(i)).split()[0].split('\"')[1].split('/')[0].split(':')[0]\n",
    "            outputs.insert(i,name)\n",
    "\n",
    "    return (inputs, outputs)\n",
    "\n",
    "def is_valid_c_name(name):\n",
    "    allowed_chars = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ_123456789'\n",
    "    allowed_starting_chars = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ_'\n",
    "    if not set(name).issubset(allowed_chars):\n",
    "        return False\n",
    "    if not set(name[0]).issubset(allowed_starting_chars):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def name_check(model):\n",
    "    for layer in model.layers:\n",
    "        assert (is_valid_c_name(layer.name)), \"layer name '\" + layer.name + \"' is not a valid C name\"\n",
    "\n",
    "def layer_type(layer):\n",
    "    return str(layer.__class__).split('.')[-1][0:-2]\n",
    "def layers_supported_check(model):\n",
    "    supported_layers = ['Dense','LSTM','Conv1D','InputLayer','MaxPooling1D','AveragePooling1D',\\\n",
    "                        'GlobalMaxPooling1D','GlobalAveragePooling1D','Add','Multiply','Average',\\\n",
    "                        'Maximum','Minimum','LeakyReLU','ELU','ThresholdedReLU','ReLU']\n",
    "    for layer in model.layers:\n",
    "        assert(layer_type(layer) in supported_layers), \"layer type '\" + \\\n",
    "        layer_type(layer) + \"' is not supported at this time\"\n",
    "        \n",
    "def activation_supported_check(model):\n",
    "    supported_activations = ['linear', 'relu','softmax','softplus','softsign','relu','tanh',\\\n",
    "                             'sigmoid','hard_sigmoid','exponential' ]\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        if 'activation' in layer.get_config():\n",
    "            assert(layer.get_config()['activation'] in supported_activations), \\\n",
    "            \"activation type '\" + layer.get_config()['activation'] + \"' is not supported at this time\"\n",
    "        if 'recurrent_activation' in layer.get_config():\n",
    "            assert(layer.get_config()['recurrent_activation'] in supported_activations), \\\n",
    "            \"recurrent activation type '\" + layer.get_config()['recurrent_activation'] + \"' is not supported at this time\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7442391581367076e-08"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### max pooling 2d\n",
    "\n",
    "def max_pool2d(inputs,pool_size,stride,outshp):\n",
    "    channels = inputs.shape[2]\n",
    "    fin = inputs.flatten()\n",
    "    outsize = np.prod(outshp)\n",
    "    outputs = np.zeros(outsize)\n",
    "    for i in range(channels):\n",
    "        k=0\n",
    "        for j in range(0,outshp[1]*channels,channels):\n",
    "            m=0\n",
    "            for l in range(0, outsize, channels*outshp[1]):\n",
    "                outputs[l+j+i] = fin[m+k+i]\n",
    "                for n in range(0,pool_size[1]*channels, channels):\n",
    "                    for p in range(0,pool_size[0]*channels*inputs.shape[1],channels*inputs.shape[1]):\n",
    "                        if (outputs[l+j+i] < fin[m+k+i+n+p]):\n",
    "                            outputs[l+j+i] = fin[m+k+i+n+p]\n",
    "                m+=channels*inputs.shape[1]*stride[0]\n",
    "            k+=channels*stride[1]\n",
    "    return outputs\n",
    "inshp = (5,6,7)\n",
    "pool_size = (3,3)\n",
    "stride = (3,1)\n",
    "a = keras.layers.Input(inshp)\n",
    "b = keras.layers.MaxPooling2D(pool_size=pool_size, strides=stride)(a)\n",
    "model = keras.models.Model(inputs=a,outputs=b)\n",
    "\n",
    "x = np.random.random(inshp)\n",
    "y = model.predict(x[np.newaxis,...])\n",
    "y = y[0,:]\n",
    "y1 = max_pool2d(x,pool_size,stride,y.shape)\n",
    "np.max(np.abs(y.flatten()-y1.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(8, (3, 3), padding='same',\n",
    "                                  input_shape=(32, 32, 3)))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.Conv2D(8, (3, 3)))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(keras.layers.Dropout(0.25))\n",
    "    model.add(keras.layers.Conv2D(8, (3, 3), padding='same'))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.Conv2D(8, (3, 3)))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(keras.layers.Dropout(0.25))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(20))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(10))\n",
    "    model.add(keras.layers.Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 20)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[-].output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing layer  conv2d_1\n",
      "written:  {'conv2d_1_input', 'conv2d_1'}\n",
      "unwritten:  {'dropout_3', 'conv2d_4', 'activation_1', 'flatten_1', 'dense_5', 'activation_4', 'activation_5', 'conv2d_3', 'max_pooling2d_3', 'activation_2', 'max_pooling2d_2', 'conv2d_2', 'dense_4', 'activation_6', 'dropout_2', 'dropout_4', 'activation_3'}\n",
      "Writing layer  activation_1\n",
      "written:  {'conv2d_1_input', 'conv2d_1', 'activation_1'}\n",
      "unwritten:  {'dropout_3', 'conv2d_4', 'flatten_1', 'dense_5', 'activation_4', 'activation_5', 'conv2d_3', 'max_pooling2d_3', 'activation_2', 'max_pooling2d_2', 'conv2d_2', 'dense_4', 'activation_6', 'dropout_2', 'dropout_4', 'activation_3'}\n",
      "Writing layer  conv2d_2\n",
      "written:  {'conv2d_1_input', 'conv2d_2', 'conv2d_1', 'activation_1'}\n",
      "unwritten:  {'dropout_3', 'conv2d_4', 'flatten_1', 'dense_5', 'activation_4', 'activation_5', 'conv2d_3', 'max_pooling2d_3', 'activation_2', 'max_pooling2d_2', 'dense_4', 'activation_6', 'dropout_2', 'dropout_4', 'activation_3'}\n",
      "Writing layer  activation_2\n",
      "written:  {'conv2d_1_input', 'activation_1', 'conv2d_2', 'conv2d_1', 'activation_2'}\n",
      "unwritten:  {'dropout_3', 'conv2d_4', 'flatten_1', 'dense_5', 'activation_4', 'activation_5', 'conv2d_3', 'max_pooling2d_3', 'max_pooling2d_2', 'dense_4', 'activation_6', 'dropout_2', 'dropout_4', 'activation_3'}\n",
      "Writing layer  max_pooling2d_2\n",
      "written:  {'max_pooling2d_2', 'conv2d_1_input', 'activation_1', 'conv2d_2', 'conv2d_1', 'activation_2'}\n",
      "unwritten:  {'dropout_3', 'conv2d_4', 'flatten_1', 'dense_5', 'activation_4', 'activation_5', 'conv2d_3', 'max_pooling2d_3', 'dense_4', 'activation_6', 'dropout_2', 'dropout_4', 'activation_3'}\n",
      "Writing layer  dropout_2\n",
      "written:  {'max_pooling2d_2', 'conv2d_1_input', 'dropout_2', 'activation_1', 'conv2d_2', 'conv2d_1', 'activation_2'}\n",
      "unwritten:  {'dropout_3', 'conv2d_4', 'flatten_1', 'dense_5', 'activation_4', 'activation_5', 'conv2d_3', 'max_pooling2d_3', 'dense_4', 'activation_6', 'dropout_4', 'activation_3'}\n",
      "Writing layer  conv2d_3\n",
      "written:  {'max_pooling2d_2', 'conv2d_1_input', 'dropout_2', 'conv2d_3', 'activation_1', 'conv2d_2', 'conv2d_1', 'activation_2'}\n",
      "unwritten:  {'dropout_3', 'conv2d_4', 'flatten_1', 'dense_5', 'activation_4', 'activation_5', 'max_pooling2d_3', 'dense_4', 'activation_6', 'dropout_4', 'activation_3'}\n",
      "Writing layer  activation_3\n",
      "written:  {'max_pooling2d_2', 'activation_1', 'conv2d_2', 'conv2d_1', 'conv2d_1_input', 'dropout_2', 'conv2d_3', 'activation_3', 'activation_2'}\n",
      "unwritten:  {'dropout_3', 'conv2d_4', 'flatten_1', 'dense_5', 'activation_4', 'activation_5', 'max_pooling2d_3', 'dense_4', 'activation_6', 'dropout_4'}\n",
      "Writing layer  conv2d_4\n",
      "written:  {'max_pooling2d_2', 'conv2d_4', 'activation_1', 'conv2d_2', 'conv2d_1', 'conv2d_1_input', 'dropout_2', 'conv2d_3', 'activation_3', 'activation_2'}\n",
      "unwritten:  {'dropout_3', 'flatten_1', 'dense_5', 'activation_4', 'activation_5', 'max_pooling2d_3', 'dense_4', 'activation_6', 'dropout_4'}\n",
      "Writing layer  activation_4\n",
      "written:  {'max_pooling2d_2', 'conv2d_4', 'activation_1', 'conv2d_2', 'conv2d_1', 'activation_4', 'conv2d_1_input', 'dropout_2', 'conv2d_3', 'activation_3', 'activation_2'}\n",
      "unwritten:  {'dropout_3', 'flatten_1', 'dense_5', 'activation_5', 'max_pooling2d_3', 'dense_4', 'activation_6', 'dropout_4'}\n",
      "Writing layer  max_pooling2d_3\n",
      "written:  {'max_pooling2d_2', 'conv2d_4', 'activation_1', 'conv2d_2', 'conv2d_1', 'activation_4', 'conv2d_1_input', 'dropout_2', 'conv2d_3', 'max_pooling2d_3', 'activation_3', 'activation_2'}\n",
      "unwritten:  {'dropout_3', 'flatten_1', 'dense_5', 'activation_5', 'dense_4', 'activation_6', 'dropout_4'}\n",
      "Writing layer  dropout_3\n",
      "written:  {'max_pooling2d_2', 'dropout_3', 'conv2d_4', 'activation_1', 'conv2d_2', 'conv2d_1', 'activation_4', 'conv2d_1_input', 'dropout_2', 'conv2d_3', 'max_pooling2d_3', 'activation_3', 'activation_2'}\n",
      "unwritten:  {'flatten_1', 'dense_5', 'activation_5', 'dense_4', 'activation_6', 'dropout_4'}\n",
      "Writing layer  flatten_1\n",
      "written:  {'max_pooling2d_2', 'dropout_3', 'conv2d_4', 'activation_1', 'conv2d_2', 'conv2d_1', 'flatten_1', 'activation_4', 'conv2d_1_input', 'dropout_2', 'conv2d_3', 'max_pooling2d_3', 'activation_3', 'activation_2'}\n",
      "unwritten:  {'dense_5', 'activation_5', 'dense_4', 'activation_6', 'dropout_4'}\n",
      "Writing layer  dense_4\n",
      "written:  {'max_pooling2d_2', 'dropout_3', 'conv2d_4', 'activation_1', 'conv2d_2', 'conv2d_1', 'flatten_1', 'activation_4', 'dense_4', 'conv2d_1_input', 'dropout_2', 'conv2d_3', 'max_pooling2d_3', 'activation_3', 'activation_2'}\n",
      "unwritten:  {'dense_5', 'activation_5', 'activation_6', 'dropout_4'}\n",
      "Writing layer  activation_5\n",
      "written:  {'max_pooling2d_2', 'dropout_3', 'conv2d_4', 'activation_1', 'conv2d_2', 'conv2d_1', 'flatten_1', 'activation_4', 'dense_4', 'activation_5', 'conv2d_1_input', 'dropout_2', 'conv2d_3', 'max_pooling2d_3', 'activation_3', 'activation_2'}\n",
      "unwritten:  {'activation_6', 'dropout_4', 'dense_5'}\n",
      "Writing layer  dropout_4\n",
      "written:  {'max_pooling2d_2', 'dropout_3', 'conv2d_4', 'activation_1', 'conv2d_2', 'conv2d_1', 'flatten_1', 'activation_4', 'dense_4', 'activation_5', 'conv2d_1_input', 'dropout_2', 'conv2d_3', 'dropout_4', 'max_pooling2d_3', 'activation_3', 'activation_2'}\n",
      "unwritten:  {'activation_6', 'dense_5'}\n",
      "Writing layer  dense_5\n",
      "written:  {'max_pooling2d_2', 'dropout_3', 'conv2d_4', 'activation_1', 'conv2d_2', 'conv2d_1', 'flatten_1', 'activation_4', 'dense_4', 'activation_5', 'dense_5', 'conv2d_1_input', 'dropout_2', 'conv2d_3', 'dropout_4', 'max_pooling2d_3', 'activation_3', 'activation_2'}\n",
      "unwritten:  {'activation_6'}\n",
      "Writing layer  activation_6\n",
      "written:  {'dropout_3', 'conv2d_4', 'activation_1', 'flatten_1', 'conv2d_1', 'dense_5', 'activation_4', 'activation_5', 'conv2d_3', 'max_pooling2d_3', 'activation_2', 'max_pooling2d_2', 'conv2d_2', 'dense_4', 'activation_6', 'conv2d_1_input', 'dropout_2', 'dropout_4', 'activation_3'}\n",
      "unwritten:  set()\n"
     ]
    }
   ],
   "source": [
    "model_inputs, model_outputs = get_model_io_names(model)\n",
    "written_io = set(model_inputs)\n",
    "unwritten_io = set(get_all_io_names(model)) - written_io\n",
    "count = 0\n",
    "while len(unwritten_io) > 0:\n",
    "    count += 1\n",
    "    if count>50:\n",
    "        break\n",
    "    for layer in model.layers:\n",
    "        layer_inputs, layer_outputs = get_layer_io_names(layer)\n",
    "        for i, (inp, outp) in enumerate(zip(layer_inputs, layer_outputs)):\n",
    "            if (set(flatten(inp)).issubset(written_io) and\n",
    "                    set(flatten(outp)).issubset(unwritten_io))or \\\n",
    "                    layer_type(layer) == 'InputLayer':\n",
    "                print('Writing layer ', outp)\n",
    "                written_io |= set(flatten(inp))\n",
    "                written_io |= set(flatten(outp))\n",
    "                unwritten_io -= set(flatten(inp))\n",
    "                unwritten_io -= set(flatten(outp))\n",
    "                print('written: ',written_io)\n",
    "                print('unwritten: ',unwritten_io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def k2c_bias_add(A,b):\n",
    "    af = A.flatten()\n",
    "    c = np.zeros(af.size)\n",
    "    for i in range(0,af.size,b.size):\n",
    "        for j in range(b.size):\n",
    "            c[i+j] = af[i+j] + b[j]\n",
    "    return c\n",
    "A = np.random.random((4,5,6,10))\n",
    "b = np.arange(10)\n",
    "c1 = A+b\n",
    "c2 = k2c_bias_add(A,b)\n",
    "np.max(np.abs(c1.flatten()-c2.flatten()))\n",
    "#print(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 40, 30)\n",
      "[30 10 40]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9903031587526856"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def k2c_sub2idx(sub, shape, ndim):\n",
    "  #/* converts from subscript to linear indices in row major order */\n",
    "    idx = 0\n",
    "    temp = 0;\n",
    "    for i in range(ndim):\n",
    "        temp = sub[i];\n",
    "        for j in range(ndim-1,i,-1):\n",
    "            temp *= shape[j]\n",
    "        idx += temp;\n",
    "    return int(idx)\n",
    "\n",
    "def k2c_idx2sub(idx,shape,ndim):\n",
    "    sub = np.zeros(ndim)\n",
    "    a = np.flip(np.cumprod(shape))\n",
    "    for j in range(ndim-1,-1,-1):\n",
    "        sub[j] = idx % shape[j]\n",
    "        idx = idx // shape[j]\n",
    "    return tuple(sub.astype(int))\n",
    "\n",
    "def k2c_permute(a,pdims):\n",
    "    pdims = np.array(pdims).astype(int)\n",
    "    shp = a.shape\n",
    "    print(shp)\n",
    "    newshp = np.array(shp)[pdims]\n",
    "    print(newshp)\n",
    "    numels = a.size\n",
    "    af = a.flatten()\n",
    "    b = np.zeros(numels)\n",
    "    for i in range(numels):\n",
    "        aidx = i\n",
    "        #asub = np.unravel_index(i,shp)\n",
    "        #print(asub)\n",
    "        asub = tuple(k2c_idx2sub(i,shp,a.ndim))\n",
    "        bsub = tuple(np.array(asub)[pdims])\n",
    "        #print(bsub)\n",
    "        bidx = k2c_sub2idx(bsub,newshp,a.ndim)\n",
    "        b[bidx] = af[i]\n",
    "    return b\n",
    "\n",
    "\n",
    "inshape = (10,40,30)\n",
    "permute = np.array((3,1,2))\n",
    "ndim = 3\n",
    "l1 = keras.layers.Input(inshape)\n",
    "l2 = keras.layers.Permute(permute)(l1)\n",
    "model = keras.models.Model(inputs=l1, outputs=l2)\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "xt = k2c_permute(x,permute-1)\n",
    "\n",
    "np.max(np.abs(xt.flatten()-y.flatten()))\n",
    "np.max(np.abs(xt.flatten()-x.flatten()))\n",
    "\n",
    "# sub = (0,1,2,6)\n",
    "# shp = (9,4,5,7)\n",
    "# ndim = len(shp)\n",
    "\n",
    "# idx1 = np.ravel_multi_index(sub,shp)\n",
    "# idx2 = k2c_sub2idx(sub,shp,ndim)\n",
    "# sub1 = np.unravel_index(idx1,shp)\n",
    "# sub2 = k2c_idx2sub(idx1,shp,ndim)\n",
    "# print(idx1,idx2)\n",
    "# print(sub1-np.array(sub2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5)\n",
      "5 9 5 9\n",
      "np vs k2c 2.029779810366704\n",
      "k vs np 2.029779856225161\n",
      "k vs k2c 2.3475072030709754e-07\n"
     ]
    }
   ],
   "source": [
    "inshape = (4,3,6,5)\n",
    "axes = (2,)\n",
    "flipped=False\n",
    "a = np.random.random(inshape)\n",
    "def k2c_reshape(a,axes,flipped):\n",
    "    shape_a = a.shape\n",
    "    axes = [i if i >= 0 else i + len(shape_a) for i in axes]\n",
    "    free = [i for i in range(len(shape_a)) if i not in axes]\n",
    "    free_dims = [shape_a[i] for i in free]\n",
    "    prod_free = int(np.prod([shape_a[i] for i in free]))\n",
    "    prod_axes = int(np.prod([shape_a[i] for i in axes]))\n",
    "    perm = list(axes) + free if flipped else free + list(axes)\n",
    "    new_shape = [prod_axes, prod_free] if flipped else [prod_free, prod_axes]\n",
    "    reshaped_a = np.reshape(np.transpose(a, perm), new_shape)\n",
    "    return reshaped_a, free_dims, prod_free,prod_axes\n",
    "\n",
    "def k2c_dot(a,b,a_axes,b_axes,normalize=False):\n",
    "    a_reshape, a_free_dims, free_axesA, prod_axesA = k2c_reshape(a, a_axes,False)\n",
    "    b_reshape, b_free_dims, free_axesB, prod_axesB = k2c_reshape(b, b_axes, True)\n",
    "    print(free_axesA,prod_axesA,free_axesB,prod_axesB)\n",
    "    \n",
    "#     if normalize:\n",
    "#         y = np.max(np.sum(a_reshape ** 2, a_axes, keepdims=True), a_axes, keepdims=True)\n",
    "#         print(y)\n",
    "#         print(y.shape)\n",
    "#         a_reshape = a_reshape / np.sqrt(y)\n",
    "#         y = np.max(np.sum(b_reshape ** 2, b_axes, keepdims=True), b_axes, keepdims=True)\n",
    "#         b_reshape = b_reshape / np.sqrt(y)\n",
    "#         print(y)\n",
    "#         print(y.shape)\n",
    "    if (normalize):\n",
    "        reshapeA = a_reshape.flatten()\n",
    "        reshapeB = b_reshape.flatten()\n",
    "        for i in range(free_axesA):\n",
    "            s = 0\n",
    "            for j in range(prod_axesA):\n",
    "                s += reshapeA[i*prod_axesA + j]**2\n",
    "            inorm = 1.0/np.sqrt(s);\n",
    "            for j in range(prod_axesA):\n",
    "                reshapeA[i*prod_axesA+j] *= inorm\n",
    "        for i in range(free_axesB):\n",
    "            s = 0\n",
    "            for j in range(prod_axesB):\n",
    "                s += reshapeB[i+free_axesB*j]**2\n",
    "            inorm = 1.0/np.sqrt(s);\n",
    "            for j in range(prod_axesB):\n",
    "                reshapeB[i+free_axesB*j] *= inorm \n",
    "        a_reshape = reshapeA.reshape(free_axesA,prod_axesA)\n",
    "        b_reshape = reshapeB.reshape(prod_axesB, free_axesB)\n",
    "    ab_matmul = a_reshape@b_reshape\n",
    "    return np.reshape(ab_matmul, a_free_dims + b_free_dims)\n",
    "   \n",
    "a_axes = (1,)\n",
    "b_axes = (0,)\n",
    "dotaxes = (2,1)\n",
    "inshape1 = (5,9)\n",
    "inshape2 = (9,5)\n",
    "i1 = keras.layers.Input(inshape1)\n",
    "i2 = keras.layers.Input(inshape2)\n",
    "d = keras.layers.Dot(axes=dotaxes, normalize=True)([i1,i2])\n",
    "model = keras.models.Model(inputs=[i1,i2], outputs = d)\n",
    "a = np.random.random(inshape1)\n",
    "b = np.random.random(inshape2)\n",
    "ak = a[np.newaxis,...]\n",
    "bk = b[np.newaxis,...]\n",
    "z = model.predict([ak,bk])\n",
    "x = np.tensordot(a,b,(a_axes,b_axes))\n",
    "print(x.shape)\n",
    "C = np.zeros(x.shape)\n",
    "y = k2c_dot(a,b,a_axes,b_axes,True)\n",
    "print('np vs k2c',np.max(np.abs(x-y)))\n",
    "print('k vs np', np.max(np.abs(z-x)))\n",
    "print('k vs k2c', np.max(np.abs(z-y)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(model.layers[2].get_config()['axes']) -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 10), (None, 12, 10)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### model testing\n",
    "\n",
    "inshape = (13,10)\n",
    "pool_size=3\n",
    "stride=1\n",
    "dilation=1\n",
    "num_filters=10\n",
    "kernel_size=3\n",
    "pad = 'same'\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.Dense(10)(a)\n",
    "c = keras.layers.AveragePooling1D(pool_size=pool_size, strides=stride, padding=pad)(b)\n",
    "d = keras.layers.Conv1D(filters=num_filters, kernel_size=kernel_size, strides=stride, padding=pad, dilation_rate=dilation)(c)\n",
    "e = keras.layers.Input((12,10))\n",
    "f = keras.layers.Dense(15)(e)\n",
    "g = keras.layers.LSTM(10)(f)\n",
    "h = keras.layers.add([g,e])\n",
    "model = keras.models.Model(inputs=[a,e], outputs=[h])\n",
    "\n",
    "# a = keras.layers.Input(inshape)\n",
    "# b = keras.layers.Input(inshape)\n",
    "# c = keras.layers.LSTM(20)\n",
    "# d = c(a)\n",
    "# e = c(b)\n",
    "# model = keras.models.Model(inputs=[a,b], outputs=[d,e])\n",
    "\n",
    "#print(model.layers[1].input_shape)\n",
    "#print(model.layers[1].output_shape)\n",
    "#print(model.layers[1].get_weights()[0].shape)\n",
    "#model.layers[2].get_config()\n",
    "model.layers[-1].input_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### pad2d\n",
    "inshp = (3,4,2)\n",
    "a = keras.layers.Input(inshp)\n",
    "b = keras.layers.ZeroPadding2D(padding=((1,2),(3,4)))(a)\n",
    "model = keras.models.Model(inputs=a, outputs=b)\n",
    "x = np.ones(inshp)\n",
    "x = x[np.newaxis,...]\n",
    "y = model.predict(x)\n",
    "y = np.squeeze(y)\n",
    "y.shape    \n",
    "\n",
    "def pad2d(inputs,fill,pad):\n",
    "    in_height = inputs.shape[0]\n",
    "    in_width = inputs.shape[1]\n",
    "    in_channels = inputs.shape[2]\n",
    "    pad_top = pad[0]\n",
    "    pad_bottom = pad[1]\n",
    "    pad_left = pad[2]\n",
    "    pad_right = pad[3]\n",
    "    output = np.zeros((in_height+pad_top+pad_bottom)*(in_width+pad_left+pad_right)*(in_channels))\n",
    "    fin = inputs.flatten()\n",
    "    offset = in_channels*(pad_left+pad_right+in_width)*pad_top + in_channels*pad_left\n",
    "    num = in_channels*in_width;\n",
    "    for i in range(in_height):\n",
    "        for j in range(num):\n",
    "            output[offset+j] = fin[i*num+j]\n",
    "        offset += num+in_channels*(pad_left+pad_right)\n",
    "    return output\n",
    "x = np.ones(inshp)\n",
    "x1= x[np.newaxis,...]\n",
    "y1 = model.predict(x1)\n",
    "y1 = np.squeeze(y1)\n",
    "y = pad2d(x,0,[1,2,3,4])\n",
    "np.max(np.abs(y1.flatten()-y.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8536409873703974e-07\n"
     ]
    }
   ],
   "source": [
    "def k2c_sub2idx(sub, shape, ndim):\n",
    "  #/* converts from subscript to linear indices in row major order */\n",
    "    idx = 0\n",
    "    temp = 0;\n",
    "    for i in range(ndim):\n",
    "        temp = sub[i];\n",
    "        for j in range(ndim-1,i,-1):\n",
    "            temp *= shape[j]\n",
    "        idx += temp;\n",
    "    return int(idx)\n",
    "\n",
    "def conv2d(inputs,kernel,bias,stride,dilation,output):\n",
    "    out_rows = output.shape[0]\n",
    "    out_cols = output.shape[1]\n",
    "    out_channels= output.shape[2]\n",
    "    in_channels = inputs.shape[2];\n",
    "    fin = inputs.flatten()\n",
    "    fkernel = kernel.flatten()\n",
    "    foutput = np.zeros(output.size)\n",
    "   \n",
    "    for x0 in range(out_rows):\n",
    "        for x1 in range(out_cols):\n",
    "            for k in range(out_channels):\n",
    "                for z0 in range(kernel.shape[0]):\n",
    "                    for z1 in range(kernel.shape[1]):\n",
    "                        for q in range(in_channels):\n",
    "                            outsub = [x0,x1,k]\n",
    "                            inpsub = [x0*stride[0] + dilation[0]*z0, x1*stride[1] + dilation[1]*z1, q]\n",
    "                            kersub = [z0,z1,q,k]\n",
    "                            foutput[k2c_sub2idx(outsub,output.shape,output.ndim)] += \\\n",
    "                            fkernel[k2c_sub2idx(kersub,kernel.shape,kernel.ndim)]*\\\n",
    "                            fin[k2c_sub2idx(inpsub,inputs.shape,inputs.ndim)]\n",
    "    for i in range(0,output.size,bias.size):\n",
    "        for j in range(bias.size):\n",
    "            foutput[i+j] += bias[j]\n",
    "    return foutput\n",
    "inshape = (10,15,3)\n",
    "stride=(1,1)\n",
    "dilation = (2,2)\n",
    "kernel_size = (2,4)\n",
    "num_filters = 15\n",
    "padding = 'same'\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.Conv2D(filters=num_filters, dilation_rate=dilation, kernel_size=kernel_size, strides=stride, padding=padding)(a)\n",
    "model = keras.models.Model(inputs=[a], outputs=[b])\n",
    "layer = model.layers[1]\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "y = np.squeeze(y)\n",
    "if padding is 'same':\n",
    "    pad_along_height = dilation[0]*(kernel_size[0]-1)\n",
    "    pad_top = int(pad_along_height // 2)\n",
    "    pad_bottom = int(pad_along_height - pad_top)\n",
    "    pad_along_width = dilation[1]*(kernel_size[1]-1)\n",
    "    pad_left = pad_along_width//2\n",
    "    pad_right = pad_along_width - pad_left\n",
    "elif padding is 'valid':\n",
    "    pad_along_height=0\n",
    "    pad_along_width=0\n",
    "    pad_top=0\n",
    "    pad_bottom=0\n",
    "    pad_left = 0\n",
    "    pad_right = 0\n",
    "    \n",
    "padshp = (x.shape[0]+pad_along_height,x.shape[1]+pad_along_width,x.shape[2])\n",
    "pad = [pad_top,pad_bottom,pad_left,pad_right]\n",
    "kernel = model.layers[1].get_weights()[0]\n",
    "bias = model.layers[1].get_weights()[1]\n",
    "x2 = pad2d(x,0,pad).reshape(padshp)\n",
    "\n",
    "y2 = conv2d(x2,kernel,bias,stride,dilation,np.zeros(y.shape))\n",
    "print(np.max(np.abs(y.flatten()-y2.flatten())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'conv2d_20',\n",
       " 'trainable': True,\n",
       " 'filters': 15,\n",
       " 'kernel_size': (2, 4),\n",
       " 'strides': (1, 1),\n",
       " 'padding': 'valid',\n",
       " 'data_format': 'channels_last',\n",
       " 'dilation_rate': (2, 2),\n",
       " 'activation': 'linear',\n",
       " 'use_bias': True,\n",
       " 'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "  'config': {'scale': 1.0,\n",
       "   'mode': 'fan_avg',\n",
       "   'distribution': 'uniform',\n",
       "   'seed': None}},\n",
       " 'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       " 'kernel_regularizer': None,\n",
       " 'bias_regularizer': None,\n",
       " 'activity_regularizer': None,\n",
       " 'kernel_constraint': None,\n",
       " 'bias_constraint': None}"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.910121461001779e-08\n",
      "1.910121461001779e-08\n"
     ]
    }
   ],
   "source": [
    "inshp = (31,21,5)\n",
    "x = np.random.random(inshp)\n",
    "y = np.max(x,tuple(np.arange(x.ndim-1)))\n",
    "\n",
    "a = keras.layers.Input(inshp)\n",
    "b = keras.layers.GlobalMaxPooling2D()(a)\n",
    "model = keras.models.Model(inputs=a,outputs=b)\n",
    "y1 = model.predict(x[np.newaxis,...])\n",
    "\n",
    "def glomax(inputs):\n",
    "    fin = inputs.flatten()\n",
    "    chan = inputs.shape[-1]\n",
    "    outputs = np.zeros(chan)\n",
    "    for i in range(chan):\n",
    "        outputs[i] = fin[i]\n",
    "    for i in range(0,fin.size,chan):\n",
    "        for j in range(chan):\n",
    "            if outputs[j]<fin[i+j]:\n",
    "                outputs[j] = fin[i+j]\n",
    "    return outputs\n",
    "            \n",
    "y2 = glomax(x)\n",
    "print(np.max(np.abs(y-y1)))\n",
    "print(np.max(np.abs(y2-y1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(None, 5, 4, 1), (None, 5, 4, 2)}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape1 = (None,5,4,2)\n",
    "shape2 = (None,5,4,1)\n",
    "output_shape = list(shape1[:-len(shape2)])\n",
    "for i, j in zip(shape1[-len(shape2):], shape2):\n",
    "    if i is None or j is None:\n",
    "        output_shape.append(None)\n",
    "    elif i == 1:\n",
    "        output_shape.append(j)\n",
    "    elif j == 1:\n",
    "        output_shape.append(i)\n",
    "    else:\n",
    "        if i != j:\n",
    "            raise ValueError('Operands could not be broadcast '\n",
    "                             'together with shapes ' +\n",
    "                             str(shape1) + ' ' + str(shape2))\n",
    "        output_shape.append(i)\n",
    "set([shape1,shape2]) # check if all inputs are the same shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.065538704\n",
      "0.065538704\n",
      "0.0\n",
      "0.065538704\n"
     ]
    }
   ],
   "source": [
    "### bidirectional\n",
    "\n",
    "inshape = (8,32)\n",
    "init1 = keras.initializers.Constant(.04)\n",
    "init2 = keras.initializers.Identity()\n",
    "af = keras.layers.Input(inshape)\n",
    "bf = keras.layers.LSTM(5, return_sequences=True, return_state=False, kernel_initializer=init1, recurrent_initializer=init2)(af)\n",
    "fwmodel = keras.models.Model(inputs=af, outputs=bf)\n",
    "\n",
    "ab = keras.layers.Input(inshape)\n",
    "bb = keras.layers.LSTM(5, return_sequences=True, go_backwards=True, kernel_initializer=init1, recurrent_initializer=init2)(ab)\n",
    "bwmodel = keras.models.Model(inputs=ab, outputs=bb)\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x= x[np.newaxis,...]\n",
    "yfw = fwmodel.predict(x)\n",
    "ybw = bwmodel.predict(x)\n",
    "xf = np.flip(x,axis=1)\n",
    "yffw = fwmodel.predict(xf)\n",
    "yfbw = bwmodel.predict(xf)\n",
    "print(np.max(np.abs(yfw-ybw)))\n",
    "print(np.max(np.abs(yfw-yffw)))\n",
    "print(np.max(np.abs(ybw-yffw)))\n",
    "print(np.max(np.abs(ybw-yfbw)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.2542965 , 0.2542965 , 0.2542965 , 0.2542965 , 0.2542965 ],\n",
       "        [0.3870733 , 0.3870733 , 0.3870733 , 0.3870733 , 0.3870733 ],\n",
       "        [0.45849904, 0.45849904, 0.45849904, 0.45849904, 0.45849904],\n",
       "        [0.55371416, 0.55371416, 0.55371416, 0.55371416, 0.55371416],\n",
       "        [0.54693186, 0.54693186, 0.54693186, 0.54693186, 0.54693186],\n",
       "        [0.5663025 , 0.5663025 , 0.5663025 , 0.5663025 , 0.5663025 ],\n",
       "        [0.6190373 , 0.6190373 , 0.6190373 , 0.6190373 , 0.6190373 ],\n",
       "        [0.60740703, 0.60740703, 0.60740703, 0.60740703, 0.60740703]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yfw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.2924625232032554e-07"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inshape = (10,11,12)\n",
    "axis=2\n",
    "init = keras.initializers.RandomUniform(minval=.1, maxval=2.0)\n",
    "center=False\n",
    "scale=False\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.BatchNormalization(axis=axis, center=center, scale=scale, beta_initializer=init,\n",
    "                                    gamma_initializer=init,  moving_variance_initializer=init, moving_mean_initializer=init)(a)\n",
    "model = keras.models.Model(inputs=a, outputs=b)\n",
    "epsilon = .001\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y1 = model.predict(x1)\n",
    "\n",
    "def batchnorm(inputs, mean,variance, gamma,beta,epsilon,axis):\n",
    "    fin = inputs.flatten()\n",
    "    shp = inputs.shape\n",
    "    offset = 1\n",
    "    for i in range(axis+1,inputs.ndim,1):\n",
    "        offset *= shp[i]\n",
    "    step = shp[axis]\n",
    "    y = np.zeros(inputs.size)\n",
    "    stdev = np.sqrt(variance+epsilon)\n",
    "    for i in range(inputs.size):\n",
    "        y[i] = (fin[i] - mean[(i//offset)%shp[axis]]) / stdev[(i//offset)%shp[axis]] *\\\n",
    "        gamma[(i//offset)%shp[axis]] + beta[(i//offset)%shp[axis]]\n",
    "    return y\n",
    "layer = model.layers[1]\n",
    "if center and scale:\n",
    "    gamma = layer.get_weights()[0]\n",
    "    beta = layer.get_weights()[1]\n",
    "    mean = layer.get_weights()[2] \n",
    "    variance = layer.get_weights()[3]\n",
    "elif center:\n",
    "    beta = layer.get_weights()[0]\n",
    "    mean = layer.get_weights()[1]\n",
    "    variance = layer.get_weights()[2]\n",
    "    gamma = np.ones(mean.shape)\n",
    "elif scale:\n",
    "    gamma = layer.get_weights()[0]\n",
    "    mean = layer.get_weights()[1] \n",
    "    variance = layer.get_weights()[2]\n",
    "    beta = np.zeros(mean.shape)\n",
    "else:\n",
    "    mean = layer.get_weights()[0] \n",
    "    variance = layer.get_weights()[1]\n",
    "    beta = np.zeros(mean.shape)\n",
    "    gamma = np.ones(mean.shape)\n",
    "    \n",
    "    \n",
    "y = batchnorm(x,mean,variance,gamma,beta,epsilon,axis-1)\n",
    "np.max(np.abs(y.flatten()-y1.flatten()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inshp = (10,20)\n",
    "input_dim = 20\n",
    "output_dim = 30\n",
    "a = keras.layers.Input(inshp)\n",
    "b = keras.layers.Embedding(input_dim=input_dim,output_dim=output_dim)(a)\n",
    "model = keras.models.Model(inputs=a,outputs=b)\n",
    "\n",
    "\n",
    "def embed(inputs,kernel):\n",
    "    fin = inputs.flatten().astype(int)\n",
    "    output_dim = kernel.shape[1]\n",
    "    outputs = np.zeros(inputs.size*output_dim)\n",
    "    for i in range(inputs.size):\n",
    "        for j in range(output_dim):\n",
    "            outputs[i*output_dim + j] = kernel.flatten()[fin[i]*output_dim+j]\n",
    "    return outputs\n",
    "layer = model.layers[1]\n",
    "kernel = layer.get_weights()[0]\n",
    "x = 10*np.random.random(inshp).astype(int)\n",
    "x1 = x[np.newaxis,...]\n",
    "y1 = model.predict(x1)\n",
    "y = embed(x,kernel)\n",
    "\n",
    "np.max(np.abs(y.flatten()-y1.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10, 20, 30)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 10, 20, 30)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'batch_normalization_1',\n",
       " 'trainable': True,\n",
       " 'axis': -1,\n",
       " 'momentum': 0.99,\n",
       " 'epsilon': 0.001,\n",
       " 'center': True,\n",
       " 'scale': True,\n",
       " 'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       " 'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       " 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       " 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       " 'beta_regularizer': None,\n",
       " 'gamma_regularizer': None,\n",
       " 'beta_constraint': None,\n",
       " 'gamma_constraint': None}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = keras.layers.BatchNormalization()\n",
    "a.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "b = 4\n",
    "bool(b not in a and b is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### types, names, io\n",
    "\n",
    "def layer_type(layer):\n",
    "    return str(layer.__class__).split('.')[-1][0:-2]\n",
    "\n",
    "def get_all_io_names(model):\n",
    "    a = [get_layer_io_names(layer) for layer in model.layers]\n",
    "    return list(set(flatten(a)))\n",
    "\n",
    "def get_layer_num_io(layer):\n",
    "    num_inputs = 0\n",
    "    error = False\n",
    "    while not error:\n",
    "        try:\n",
    "            layer.get_input_at(num_inputs)\n",
    "            num_inputs +=1\n",
    "        except ValueError:\n",
    "            error = True\n",
    "    \n",
    "    num_outputs = 0\n",
    "    error = False\n",
    "    while not error:\n",
    "        try:\n",
    "            layer.get_output_at(num_outputs)\n",
    "            num_outputs +=1\n",
    "        except ValueError:\n",
    "            error = True\n",
    "    return num_inputs, num_outputs\n",
    "\n",
    "def get_layer_io_names(layer):\n",
    "    num_inputs, num_outputs = get_layer_num_io(layer)\n",
    "    inputs = []\n",
    "    # num_inputs>1 -> shared layer\n",
    "    for i in range(num_inputs):\n",
    "        # is the input a list?\n",
    "        if isinstance(layer.get_input_at(i), list):\n",
    "            temp_list = []\n",
    "            list_length = len(layer.get_input_at(i))\n",
    "            for j in range(list_length):\n",
    "                name = str(layer.get_input_at(i)[j]).split()[0].split('\"')[1].split('/')[0].split(':')[0]\n",
    "                temp_list.append(name)\n",
    "            inputs.insert(i,temp_list)\n",
    "        else:\n",
    "            name = str(layer.get_input_at(i)).split()[0].split('\"')[1].split('/')[0].split(':')[0]\n",
    "            inputs.insert(i,name)\n",
    "    \n",
    "    outputs = []       \n",
    "    for i in range(num_outputs):\n",
    "        # is the output a list?\n",
    "        if isinstance(layer.get_output_at(i), list):\n",
    "            temp_list = []\n",
    "            list_length = len(layer.get_output_at(i))\n",
    "            for j in range(list_length):\n",
    "                name = str(layer.get_output_at(i)[j]).split()[0].split('\"')[1].split('/')[0].split(':')[0]\n",
    "                temp_list.append(name)\n",
    "            outputs.insert(i,temp_list)\n",
    "        else:\n",
    "            name = str(layer.get_output_at(i)).split()[0].split('\"')[1].split('/')[0].split(':')[0]\n",
    "            outputs.insert(i,name)\n",
    "\n",
    "    return inputs, outputs\n",
    "\n",
    "def get_model_io_names(model):\n",
    "    num_inputs = len(model.inputs)\n",
    "    num_outputs = len(model.outputs)\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for i in range(num_inputs):\n",
    "        nm = str(model.inputs[i]).split()[0].split('\"')[1].split('/')[0].split(':')[0]\n",
    "        inputs.append(nm)\n",
    "    for i in range(num_outputs):\n",
    "        nm = str(model.outputs[i]).split()[0].split('\"')[1].split('/')[0].split(':')[0]\n",
    "        outputs.append(nm)\n",
    "    return inputs, outputs\n",
    "\n",
    "def flatten(x):\n",
    "        if isinstance(x, list) or isinstance(x, tuple):\n",
    "            return [a for i in x for a in flatten(i)]\n",
    "        else:\n",
    "            return [x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "inp1 = np.random.random(inshape)\n",
    "inp2 = np.random.random(inshape2)\n",
    "inp = [inp1[np.newaxis,...],inp2[np.newaxis,...]]\n",
    "num_tests = 10\n",
    "t1 = time.perf_counter_ns()\n",
    "for i in range(num_tests):\n",
    "    outp = model.predict(inp)\n",
    "t2 = time.perf_counter_ns()\n",
    "print((t2-t1)/1000/num_tests)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
